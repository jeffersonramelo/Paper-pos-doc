{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOcsQfDyKWFt/N70j05Ug6Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffersonramelo/Paper-pos-doc/blob/main/R2_dentro_e_fora_da_amostra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Caminho para o arquivo XLSX\n",
        "caminho_arquivo = '/content/Jefferson - Dados3 - Copia.xlsx'\n",
        "\n",
        "# Lê o arquivo XLSX\n",
        "dados = pd.read_excel(caminho_arquivo)"
      ],
      "metadata": {
        "id": "DOE1GbH_7pjb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Supondo que 'dados' seja o seu DataFrame\n",
        "\n",
        "# Converter a coluna 't' para o tipo de dado datetime, se ainda não estiver no formato adequado\n",
        "dados['t'] = pd.to_datetime(dados['t'], format='%Y')\n",
        "\n",
        "# Definir as datas de início e fim para o intervalo desejado\n",
        "data_inicio = pd.to_datetime('2017-01-01')\n",
        "data_fim = pd.to_datetime('2022-12-31')\n",
        "\n",
        "# Filtrar os dados para extrair apenas as linhas no intervalo de 2010 a 2013\n",
        "dados = dados.query('@data_inicio <= t <= @data_fim')\n",
        "\n",
        "# Agora, 'dados_2010_2013' contém apenas as linhas com valores de 't' no intervalo de 2010 a 2013.\n"
      ],
      "metadata": {
        "id": "YQWboq9TRV5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dados"
      ],
      "metadata": {
        "id": "CpGcZsbmRepN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "excluir setor financeiro e empresas com PL negativo, numeros faltante e transformar eventuais caracteres em números"
      ],
      "metadata": {
        "id": "kEKhC6-Wf6ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agora, vamos remover as linhas onde 'd9' seja igual a 1\n",
        "dados = dados[dados['d11'] != 1]\n",
        "# Converte a coluna 'PL2010' para números (float) e remove as linhas onde 'PL2010' seja negativo\n",
        "dados['PL2010'] = pd.to_numeric(dados['PL2010'], errors='coerce')  # 'coerce' trata strings não numéricas como NaN\n",
        "dados = dados[dados['PL2010'] > 0]\n",
        "\n",
        "# Agora, vamos remover as linhas onde 'VM30Abril11' seja igual a '-'\n",
        "dados = dados[dados['VM30Abril2011'] != '-']\n",
        "dados = dados[dados['PL2010'] != '-']\n",
        "dados = dados[dados['LL2010'] != '-']\n",
        "dados = dados[dados['AT2009'] != '-']\n",
        "dados = dados[dados['AT2009'] != '0']\n",
        "\n",
        "#transforma as variáveis em números\n",
        "dados['AT2009'] = pd.to_numeric(dados['AT2009'], errors='coerce')\n",
        "dados['LL2010'] = pd.to_numeric(dados['LL2010'], errors='coerce')\n",
        "dados['VM30Abril2011'] = pd.to_numeric(dados['VM30Abril2011'], errors='coerce')\n",
        "dados['PL2010'] = pd.to_numeric(dados['PL2010'], errors='coerce')\n",
        "\n",
        "# Lista de variáveis que você deseja escalonar\n",
        "variaveis = ['VM30Abril2011', 'PL2010', 'LL2010', 'AT2009']\n",
        "\n",
        "# Verifique o tipo de dados de cada coluna\n",
        "for coluna in variaveis:\n",
        "    print(f\"Tipo de dados da coluna {coluna}: {dados[coluna].dtype}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cQ_iqhOf9H_",
        "outputId": "6bbec020-0437-4b92-c9cd-1ba61f495d33"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tipo de dados da coluna VM30Abril2011: float64\n",
            "Tipo de dados da coluna PL2010: float64\n",
            "Tipo de dados da coluna LL2010: float64\n",
            "Tipo de dados da coluna AT2009: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-28e051817eca>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dados['PL2010'] = pd.to_numeric(dados['PL2010'], errors='coerce')  # 'coerce' trata strings não numéricas como NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ESCALONAMENTO DAS VARIÁVEIS"
      ],
      "metadata": {
        "id": "9GCa_0_0pZBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "variaveis = ['VM30Abril2011', 'PL2010', 'LL2010']\n",
        "\n",
        "for coluna in variaveis:\n",
        "    dados[coluna] = dados[coluna] / dados['AT2009']\n"
      ],
      "metadata": {
        "id": "A7MYj6i9h6LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "WINSORIZAÇÃO: tratar outliers: A winsorização ao nível de 1% envolve substituir os 1% dos valores mais extremos por valores no limite do intervalo aceitável, ou seja, os 1% menores e os 1% maiores dos valores."
      ],
      "metadata": {
        "id": "95LYGQCnbVVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import mstats\n",
        "\n",
        "# Supondo que seu DataFrame se chame \"dados\"\n",
        "\n",
        "# Lista de variáveis para winsorizar\n",
        "variaveis_winsorizar = ['VM30Abril2011', 'PL2010', 'LL2010', 'AT2009']\n",
        "\n",
        "# Converter as colunas para números, tratando não numéricos como NaN\n",
        "for coluna in variaveis_winsorizar:\n",
        "    dados[coluna] = pd.to_numeric(dados[coluna], errors='coerce')\n",
        "\n",
        "# Aplicar winsorização de 1% nas variáveis\n",
        "for coluna in variaveis_winsorizar:\n",
        "    dados[coluna] = mstats.winsorize(dados[coluna], limits=[0.01, 0.01])\n",
        "\n",
        "# Agora, as variáveis especificadas foram winsorizadas\n"
      ],
      "metadata": {
        "id": "lOpHHKqnzgzN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MQO_SIMPLES"
      ],
      "metadata": {
        "id": "9rBG78W6yny2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Certifique-se de que os tipos de dados sejam numéricos\n",
        "X = X.astype(float)\n",
        "y = y.astype(float)\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "r2_in_sample_scores = []\n",
        "r2_out_of_sample_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Crie o modelo de regressão linear\n",
        "    modelo = sm.OLS(y_train, X_train).fit()\n",
        "\n",
        "    # Calcule o R^2 dentro da amostra\n",
        "    r2_in_sample = modelo.rsquared\n",
        "    r2_in_sample_scores.append(r2_in_sample)\n",
        "\n",
        "    # Faça previsões no conjunto de teste\n",
        "    y_pred = modelo.predict(X_test)\n",
        "\n",
        "    # Calcule o R^2 fora da amostra\n",
        "    r2_out_of_sample = r2_score(y_test, y_pred)\n",
        "    r2_out_of_sample_scores.append(r2_out_of_sample)\n",
        "\n",
        "# Média dos R^2 dentro e fora da amostra\n",
        "media_r2_in_sample = np.mean(r2_in_sample_scores)\n",
        "media_r2_out_of_sample = np.mean(r2_out_of_sample_scores)\n",
        "\n",
        "print(\"Média do R^2 dentro da amostra:\", media_r2_in_sample)\n",
        "print(\"Média do R^2 fora da amostra:\", media_r2_out_of_sample)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFDRcTz2tag0",
        "outputId": "c766d5e1-b420-4f67-c83d-6e11789e0ec1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do R^2 dentro da amostra: 0.9477442691461508\n",
            "Média do R^2 fora da amostra: 0.6677571131050917\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MQP - MODELO SIMPLES"
      ],
      "metadata": {
        "id": "IXhYrWVgKtFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Certifique-se de que os tipos de dados sejam numéricos\n",
        "X = X.astype(float)\n",
        "y = y.astype(float)\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "r2_in_sample_scores = []\n",
        "r2_out_of_sample_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo robusto usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Crie o modelo de regressão robusta\n",
        "    modelo_robusto = sm.RLM(y_train, X_train, M=sm.robust.norms.HuberT()).fit()\n",
        "\n",
        "    # Calcule o R^2 dentro da amostra\n",
        "    r2_in_sample = r2_score(y_train, modelo_robusto.fittedvalues)\n",
        "    r2_in_sample_scores.append(r2_in_sample)\n",
        "\n",
        "    # Faça previsões no conjunto de teste\n",
        "    y_pred = modelo_robusto.predict(X_test)\n",
        "\n",
        "    # Calcule o R^2 fora da amostra\n",
        "    r2_out_of_sample = r2_score(y_test, y_pred)\n",
        "    r2_out_of_sample_scores.append(r2_out_of_sample)\n",
        "\n",
        "# Média dos R^2 dentro e fora da amostra\n",
        "media_r2_in_sample = np.mean(r2_in_sample_scores)\n",
        "media_r2_out_of_sample = np.mean(r2_out_of_sample_scores)\n",
        "\n",
        "print(\"Média do R^2 dentro da amostra:\", media_r2_in_sample)\n",
        "print(\"Média do R^2 fora da amostra:\", media_r2_out_of_sample)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iW_XFFBt1fM",
        "outputId": "e0ba2c0b-8cc8-4f5f-a307-4da2f859e97c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do R^2 dentro da amostra: 0.9460100113664194\n",
            "Média do R^2 fora da amostra: 0.6628894987967024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RB_Simples (LINEAR)"
      ],
      "metadata": {
        "id": "X-hPlPqnNEYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import median_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_in_sample_scores = []\n",
        "r2_out_of_sample_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo Bayesian Ridge\n",
        "    modelo_bayesiano = BayesianRidge()\n",
        "\n",
        "    modelo_bayesiano.fit(X_train, y_train)\n",
        "    y_pred = modelo_bayesiano.predict(X_test)\n",
        "\n",
        "    # Calcular o erro mediano absoluto (Median Absolute Error)\n",
        "    medae = median_absolute_error(y_test, y_pred)\n",
        "    medae_scores.append(medae)\n",
        "\n",
        "    # Calcular o R^2 dentro da amostra\n",
        "    y_train_pred = modelo_bayesiano.predict(X_train)\n",
        "    r2_in_sample = r2_score(y_train, y_train_pred)\n",
        "    r2_in_sample_scores.append(r2_in_sample)\n",
        "\n",
        "    # Calcular o R^2 fora da amostra\n",
        "    r2_out_of_sample = r2_score(y_test, y_pred)\n",
        "    r2_out_of_sample_scores.append(r2_out_of_sample)\n",
        "\n",
        "# Média das métricas de avaliação em todas as dobras\n",
        "media_medae = np.mean(medae_scores)\n",
        "media_r2_in_sample = np.mean(r2_in_sample_scores)\n",
        "media_r2_out_of_sample = np.mean(r2_out_of_sample_scores)\n",
        "\n",
        "print(\"Média do Median Absolute Error (MedAE):\", media_medae)\n",
        "print(\"Média do R^2 dentro da amostra:\", media_r2_in_sample)\n",
        "print(\"Média do R^2 fora da amostra:\", media_r2_out_of_sample)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhVHFzGruRfG",
        "outputId": "48a89cd1-1390-4e26-c192-03c6c60c45c8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do Median Absolute Error (MedAE): 1851483.3502209324\n",
            "Média do R^2 dentro da amostra: 0.9477384869911916\n",
            "Média do R^2 fora da amostra: 0.6651342673294043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVR (NÃO LINEAR)"
      ],
      "metadata": {
        "id": "NIw0ZhcK_9OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import median_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_in_sample_scores = []\n",
        "r2_out_of_sample_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo SVR com kernel RBF\n",
        "    modelo_svr = SVR(kernel='poly', degree=3, C=1.0)\n",
        "\n",
        "    modelo_svr.fit(X_train, y_train)\n",
        "    y_pred = modelo_svr.predict(X_test)\n",
        "\n",
        "    # Calcular o erro mediano absoluto (Median Absolute Error)\n",
        "    medae = median_absolute_error(y_test, y_pred)\n",
        "    medae_scores.append(medae)\n",
        "\n",
        "    # Calcular o R^2 dentro da amostra\n",
        "    y_train_pred = modelo_svr.predict(X_train)\n",
        "    r2_in_sample = r2_score(y_train, y_train_pred)\n",
        "    r2_in_sample_scores.append(r2_in_sample)\n",
        "\n",
        "    # Calcular o R^2 fora da amostra\n",
        "    r2_out_of_sample = r2_score(y_test, y_pred)\n",
        "    r2_out_of_sample_scores.append(r2_out_of_sample)\n",
        "\n",
        "# Média das métricas de avaliação em todas as dobras\n",
        "media_medae = np.mean(medae_scores)\n",
        "media_r2_in_sample = np.mean(r2_in_sample_scores)\n",
        "media_r2_out_of_sample = np.mean(r2_out_of_sample_scores)\n",
        "\n",
        "print(\"Média do Median Absolute Error (MedAE):\", media_medae)\n",
        "print(\"Média do R^2 dentro da amostra:\", media_r2_in_sample)\n",
        "print(\"Média do R^2 fora da amostra:\", media_r2_out_of_sample)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rnlls5HAuxgO",
        "outputId": "70b7b624-0843-4e3a-bf71-435c72885ac1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do Median Absolute Error (MedAE): 1855809.6678745435\n",
            "Média do R^2 dentro da amostra: -0.043430143845759515\n",
            "Média do R^2 fora da amostra: -0.22719244055868618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CART_simples (NÃO LINEAR)"
      ],
      "metadata": {
        "id": "ZYtjgE_9OP3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "mae_scores = []\n",
        "mse_scores = []\n",
        "r2_in_sample_scores = []\n",
        "r2_out_of_sample_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de árvore de decisão com os parâmetros desejados\n",
        "    modelo_arvore = DecisionTreeRegressor(min_samples_split=5, random_state=42)\n",
        "\n",
        "    # Criar o modelo Bagging com 500 árvores\n",
        "    bagging_model = BaggingRegressor(base_estimator=modelo_arvore, n_estimators=500, bootstrap=True, random_state=42)\n",
        "\n",
        "    bagging_model.fit(X_train, y_train)\n",
        "    y_pred = bagging_model.predict(X_test)\n",
        "\n",
        "    # Calcular as métricas de avaliação\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2_in_sample = bagging_model.score(X_train, y_train)\n",
        "    r2_out_of_sample = bagging_model.score(X_test, y_test)\n",
        "\n",
        "    mae_scores.append(mae)\n",
        "    mse_scores.append(mse)\n",
        "    r2_in_sample_scores.append(r2_in_sample)\n",
        "    r2_out_of_sample_scores.append(r2_out_of_sample)\n",
        "\n",
        "# Média das métricas de avaliação em todas as dobras\n",
        "media_mae = np.mean(mae_scores)\n",
        "media_mse = np.mean(mse_scores)\n",
        "media_r2_in_sample = np.mean(r2_in_sample_scores)\n",
        "media_r2_out_of_sample = np.mean(r2_out_of_sample_scores)\n",
        "\n",
        "print(\"Média do Mean Absolute Error (MAE):\", media_mae)\n",
        "print(\"Média do Mean Squared Error (MSE):\", media_mse)\n",
        "print(\"Média do R^2 dentro da amostra:\", media_r2_in_sample)\n",
        "print(\"Média do R^2 fora da amostra:\", media_r2_out_of_sample)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDPjYJvxvNBX",
        "outputId": "ccbd5726-e5fe-4cc4-de4e-13b63f1d1c54"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do Mean Absolute Error (MAE): 3831600.3528409107\n",
            "Média do Mean Squared Error (MSE): 189012557056774.53\n",
            "Média do R^2 dentro da amostra: 0.9513509764888994\n",
            "Média do R^2 fora da amostra: 0.5030578777265446\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FLORESTA ALEATÓRIA (NÃO LINEAR)"
      ],
      "metadata": {
        "id": "OZLbiycNZm26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Certifique-se de que os tipos de dados sejam numéricos\n",
        "X = X.astype(float)\n",
        "y = y.astype(float)\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de Floresta Aleatória com os parâmetros desejados\n",
        "    random_forest_model = RandomForestRegressor(n_estimators=500, random_state=42)\n",
        "    #random_forest_model = RandomForestRegressor(n_estimators=500, max_depth=10, random_state=42)\n",
        "    #random_forest_model = RandomForestRegressor(n_estimators=500, max_features=4, random_state=42)\n",
        "    #random_forest_model = RandomForestRegressor(n_estimators=500, max_features=0.3, random_state=42)\n",
        "\n",
        "\n",
        "    random_forest_model.fit(X_train, y_train)\n",
        "    y_pred = random_forest_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar a importância das variáveis\n",
        "    importancia_variaveis = random_forest_model.feature_importances_\n",
        "    print(\"Importância das Variáveis:\", importancia_variaveis)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "id": "lpAmsgS7Zph4",
        "outputId": "42237292-5243-48d7-d7e6-50c09b7e7c4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância das Variáveis: [0.85198725 0.14801275]\n",
            "Importância das Variáveis: [0.84385787 0.15614213]\n",
            "Importância das Variáveis: [0.88367251 0.11632749]\n",
            "Importância das Variáveis: [0.86212843 0.13787157]\n",
            "Importância das Variáveis: [0.83930719 0.16069281]\n",
            "Importância das Variáveis: [0.88525781 0.11474219]\n",
            "Importância das Variáveis: [0.86254208 0.13745792]\n",
            "Importância das Variáveis: [0.8366682 0.1633318]\n",
            "Importância das Variáveis: [0.84572728 0.15427272]\n",
            "Importância das Variáveis: [0.85194658 0.14805342]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 14.43210797407156\n",
            "Média do R²: 0.542486201674424\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRADIENT BOOSTING (NÃO LINEAR)"
      ],
      "metadata": {
        "id": "gReIxsDPa_9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de Regressão Gradient Boosting com os parâmetros desejados\n",
        "    gradient_boosting_model = GradientBoostingRegressor(n_estimators=500, random_state=42)\n",
        "\n",
        "    gradient_boosting_model.fit(X_train, y_train)\n",
        "    y_pred = gradient_boosting_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar a importância das variáveis\n",
        "    importancia_variaveis = gradient_boosting_model.feature_importances_\n",
        "    print(\"Importância das Variáveis:\", importancia_variaveis)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "id": "NvfZ3qUAbCf5",
        "outputId": "f9cf1bfb-e093-41c6-bfd4-8710de9ad693",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância das Variáveis: [0.85935704 0.14064296]\n",
            "Importância das Variáveis: [0.81805766 0.18194234]\n",
            "Importância das Variáveis: [0.8754046 0.1245954]\n",
            "Importância das Variáveis: [0.85055114 0.14944886]\n",
            "Importância das Variáveis: [0.83842492 0.16157508]\n",
            "Importância das Variáveis: [0.89175798 0.10824202]\n",
            "Importância das Variáveis: [0.86364624 0.13635376]\n",
            "Importância das Variáveis: [0.83163422 0.16836578]\n",
            "Importância das Variáveis: [0.84431224 0.15568776]\n",
            "Importância das Variáveis: [0.84499112 0.15500888]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 12.699941787318881\n",
            "Média do R²: 0.351145473964532\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REDES NEURAIS (NÃO LINEAR)"
      ],
      "metadata": {
        "id": "Gy8Aqujjc2rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de regressão de rede neural com os parâmetros desejados\n",
        "    modelo_rede_neural = MLPRegressor(hidden_layer_sizes=(30), max_iter=1000, random_state=42)\n",
        "\n",
        "    modelo_rede_neural.fit(X_train, y_train)\n",
        "    y_pred = modelo_rede_neural.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "id": "yygOLB39c4OY",
        "outputId": "840bf438-2246-426a-d514-75584846e965",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 11.691986211955475\n",
            "Média do R²: 0.6298537572510516\n"
          ]
        }
      ]
    }
  ]
}