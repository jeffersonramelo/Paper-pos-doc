{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM425TThJ/JyXURoX/2432W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffersonramelo/Paper-pos-doc/blob/main/R2_dentro_e_fora_da_amostra.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Caminho para o arquivo XLSX\n",
        "caminho_arquivo = '/content/Jefferson - Dados3 - Copia.xlsx'\n",
        "\n",
        "# Lê o arquivo XLSX\n",
        "dados = pd.read_excel(caminho_arquivo)"
      ],
      "metadata": {
        "id": "DOE1GbH_7pjb"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Supondo que 'dados' seja o seu DataFrame\n",
        "\n",
        "# Converter a coluna 't' para o tipo de dado datetime, se ainda não estiver no formato adequado\n",
        "#dados['t'] = pd.to_datetime(dados['t'], format='%Y')\n",
        "\n",
        "# Definir as datas de início e fim para o intervalo desejado\n",
        "#data_inicio = pd.to_datetime('2019-01-01')\n",
        "#data_fim = pd.to_datetime('2019-12-31')\n",
        "\n",
        "# Filtrar os dados para extrair apenas as linhas no intervalo de 2018 a 2019\n",
        "#dados = dados.query('@data_inicio <= t <= @data_fim')\n",
        "\n",
        "# Agora, 'dados_2018_2019' contém apenas as linhas com valores de 't' no intervalo de 2018 a 2019.\n"
      ],
      "metadata": {
        "id": "YQWboq9TRV5K"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dados"
      ],
      "metadata": {
        "id": "CpGcZsbmRepN"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "excluir setor financeiro e empresas com PL negativo, numeros faltante e transformar eventuais caracteres em números"
      ],
      "metadata": {
        "id": "kEKhC6-Wf6ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agora, vamos remover as linhas onde 'd9' seja igual a 1\n",
        "dados = dados[dados['d11'] != 1]\n",
        "# Converte a coluna 'PL2018' para números (float) e remove as linhas onde 'PL2018' seja negativo\n",
        "dados['PL2018'] = pd.to_numeric(dados['PL2018'], errors='coerce')  # 'coerce' trata strings não numéricas como NaN\n",
        "dados = dados[dados['PL2018'] > 0]\n",
        "\n",
        "# Agora, vamos remover as linhas onde 'VM30Abril11' seja igual a '-'\n",
        "dados = dados[dados['VM30Abril2019'] != '-']\n",
        "dados = dados[dados['PL2018'] != '-']\n",
        "dados = dados[dados['LL2018'] != '-']\n",
        "dados = dados[dados['AT2017'] != '-']\n",
        "dados = dados[dados['AT2017'] != '0']\n",
        "\n",
        "#transforma as variáveis em números\n",
        "dados['AT2017'] = pd.to_numeric(dados['AT2017'], errors='coerce')\n",
        "dados['LL2018'] = pd.to_numeric(dados['LL2018'], errors='coerce')\n",
        "dados['VM30Abril2019'] = pd.to_numeric(dados['VM30Abril2019'], errors='coerce')\n",
        "dados['PL2018'] = pd.to_numeric(dados['PL2018'], errors='coerce')\n",
        "\n",
        "# Lista de variáveis que você deseja escalonar\n",
        "variaveis = ['VM30Abril2019', 'PL2018', 'LL2018', 'AT2017']\n",
        "\n",
        "# Verifique o tipo de dados de cada coluna\n",
        "for coluna in variaveis:\n",
        "    print(f\"Tipo de dados da coluna {coluna}: {dados[coluna].dtype}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cQ_iqhOf9H_",
        "outputId": "2f55b8db-a5f7-4cf6-be45-c57cf004f518"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tipo de dados da coluna VM30Abril2019: float64\n",
            "Tipo de dados da coluna PL2018: float64\n",
            "Tipo de dados da coluna LL2018: float64\n",
            "Tipo de dados da coluna AT2017: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-230-b41bcbf667a4>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dados['PL2018'] = pd.to_numeric(dados['PL2018'], errors='coerce')  # 'coerce' trata strings não numéricas como NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ESCALONAMENTO DAS VARIÁVEIS"
      ],
      "metadata": {
        "id": "9GCa_0_0pZBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#variaveis = ['VM30Abril2019', 'PL2018', 'LL2018']\n",
        "\n",
        "#for coluna in variaveis:\n",
        " #   dados[coluna] = dados[coluna] / dados['AT2017']\n"
      ],
      "metadata": {
        "id": "A7MYj6i9h6LO"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "WINSORIZAÇÃO: tratar outliers: A winsorização ao nível de 1% envolve substituir os 1% dos valores mais extremos por valores no limite do intervalo aceitável, ou seja, os 1% menores e os 1% maiores dos valores."
      ],
      "metadata": {
        "id": "95LYGQCnbVVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import mstats\n",
        "\n",
        "# Supondo que seu DataFrame se chame \"dados\"\n",
        "\n",
        "# Lista de variáveis para winsorizar\n",
        "variaveis_winsorizar = ['VM30Abril2019', 'PL2018', 'LL2018', 'AT2017']\n",
        "\n",
        "# Converter as colunas para números, tratando não numéricos como NaN\n",
        "for coluna in variaveis_winsorizar:\n",
        "    dados[coluna] = pd.to_numeric(dados[coluna], errors='coerce')\n",
        "\n",
        "# Aplicar winsorização de 1% nas variáveis\n",
        "for coluna in variaveis_winsorizar:\n",
        "    dados[coluna] = mstats.winsorize(dados[coluna], limits=[0.01, 0.01])\n",
        "\n",
        "# Agora, as variáveis especificadas foram winsorizadas\n"
      ],
      "metadata": {
        "id": "lOpHHKqnzgzN"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MQO_SIMPLES"
      ],
      "metadata": {
        "id": "9rBG78W6yny2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2018', 'LL2018']]\n",
        "y = dados['VM30Abril2019']\n",
        "\n",
        "# Certifique-se de que os tipos de dados sejam numéricos\n",
        "X = X.astype(float)\n",
        "y = y.astype(float)\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "r2_in_sample_scores = []\n",
        "r2_out_of_sample_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Crie o modelo de regressão linear\n",
        "    modelo = sm.OLS(y_train, X_train).fit()\n",
        "\n",
        "    # Calcule o R^2 dentro da amostra\n",
        "    r2_in_sample = modelo.rsquared\n",
        "    r2_in_sample_scores.append(r2_in_sample)\n",
        "\n",
        "    # Faça previsões no conjunto de teste\n",
        "    y_pred = modelo.predict(X_test)\n",
        "\n",
        "    # Calcule o R^2 fora da amostra\n",
        "    r2_out_of_sample = r2_score(y_test, y_pred)\n",
        "    r2_out_of_sample_scores.append(r2_out_of_sample)\n",
        "\n",
        "# Média dos R^2 dentro e fora da amostra\n",
        "media_r2_in_sample = np.mean(r2_in_sample_scores)\n",
        "media_r2_out_of_sample = np.mean(r2_out_of_sample_scores)\n",
        "\n",
        "print(\"Média do R^2 dentro da amostra:\", media_r2_in_sample)\n",
        "print(\"Média do R^2 fora da amostra:\", media_r2_out_of_sample)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFDRcTz2tag0",
        "outputId": "d5d5eebe-0c52-491e-f089-7e640bb44a39"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do R^2 dentro da amostra: 0.7836754169804203\n",
            "Média do R^2 fora da amostra: -1.3567686388579645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MQP - MODELO SIMPLES"
      ],
      "metadata": {
        "id": "IXhYrWVgKtFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2018', 'LL2018']]\n",
        "y = dados['VM30Abril2019']\n",
        "\n",
        "# Certifique-se de que os tipos de dados sejam numéricos\n",
        "X = X.astype(float)\n",
        "y = y.astype(float)\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "r2_in_sample_scores = []\n",
        "r2_out_of_sample_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo robusto usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Crie o modelo de regressão robusta\n",
        "    modelo_robusto = sm.RLM(y_train, X_train, M=sm.robust.norms.HuberT()).fit()\n",
        "\n",
        "    # Calcule o R^2 dentro da amostra\n",
        "    r2_in_sample = r2_score(y_train, modelo_robusto.fittedvalues)\n",
        "    r2_in_sample_scores.append(r2_in_sample)\n",
        "\n",
        "    # Faça previsões no conjunto de teste\n",
        "    y_pred = modelo_robusto.predict(X_test)\n",
        "\n",
        "    # Calcule o R^2 fora da amostra\n",
        "    r2_out_of_sample = r2_score(y_test, y_pred)\n",
        "    r2_out_of_sample_scores.append(r2_out_of_sample)\n",
        "\n",
        "# Média dos R^2 dentro e fora da amostra\n",
        "media_r2_in_sample = np.mean(r2_in_sample_scores)\n",
        "media_r2_out_of_sample = np.mean(r2_out_of_sample_scores)\n",
        "\n",
        "print(\"Média do R^2 dentro da amostra:\", media_r2_in_sample)\n",
        "print(\"Média do R^2 fora da amostra:\", media_r2_out_of_sample)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iW_XFFBt1fM",
        "outputId": "218492cc-6ab1-4203-90f8-7738d5c2a412"
      },
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do R^2 dentro da amostra: 0.7810714970524769\n",
            "Média do R^2 fora da amostra: -0.676999769665482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RB_Simples (LINEAR)"
      ],
      "metadata": {
        "id": "X-hPlPqnNEYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import median_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2018', 'LL2018']]\n",
        "y = dados['VM30Abril2019']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_in_sample_scores = []\n",
        "r2_out_of_sample_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo Bayesian Ridge\n",
        "    modelo_bayesiano = BayesianRidge()\n",
        "\n",
        "    modelo_bayesiano.fit(X_train, y_train)\n",
        "    y_pred = modelo_bayesiano.predict(X_test)\n",
        "\n",
        "    # Calcular o erro mediano absoluto (Median Absolute Error)\n",
        "    medae = median_absolute_error(y_test, y_pred)\n",
        "    medae_scores.append(medae)\n",
        "\n",
        "    # Calcular o R^2 dentro da amostra\n",
        "    y_train_pred = modelo_bayesiano.predict(X_train)\n",
        "    r2_in_sample = r2_score(y_train, y_train_pred)\n",
        "    r2_in_sample_scores.append(r2_in_sample)\n",
        "\n",
        "    # Calcular o R^2 fora da amostra\n",
        "    r2_out_of_sample = r2_score(y_test, y_pred)\n",
        "    r2_out_of_sample_scores.append(r2_out_of_sample)\n",
        "\n",
        "# Média das métricas de avaliação em todas as dobras\n",
        "media_medae = np.mean(medae_scores)\n",
        "media_r2_in_sample = np.mean(r2_in_sample_scores)\n",
        "media_r2_out_of_sample = np.mean(r2_out_of_sample_scores)\n",
        "\n",
        "print(\"Média do Median Absolute Error (MedAE):\", media_medae)\n",
        "print(\"Média do R^2 dentro da amostra:\", media_r2_in_sample)\n",
        "print(\"Média do R^2 fora da amostra:\", media_r2_out_of_sample)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhVHFzGruRfG",
        "outputId": "84adfcdd-b516-46f4-d9e8-b33458e88fe6"
      },
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do Median Absolute Error (MedAE): 2876236.8322504363\n",
            "Média do R^2 dentro da amostra: 0.7835645636170074\n",
            "Média do R^2 fora da amostra: -0.7041867620440502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVR (NÃO LINEAR)"
      ],
      "metadata": {
        "id": "NIw0ZhcK_9OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import median_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2018', 'LL2018']]\n",
        "y = dados['VM30Abril2019']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_in_sample_scores = []\n",
        "r2_out_of_sample_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo SVR com kernel RBF\n",
        "    modelo_svr = SVR(kernel='poly', degree=3, C=1.0)\n",
        "\n",
        "    modelo_svr.fit(X_train, y_train)\n",
        "    y_pred = modelo_svr.predict(X_test)\n",
        "\n",
        "    # Calcular o erro mediano absoluto (Median Absolute Error)\n",
        "    medae = median_absolute_error(y_test, y_pred)\n",
        "    medae_scores.append(medae)\n",
        "\n",
        "    # Calcular o R^2 dentro da amostra\n",
        "    y_train_pred = modelo_svr.predict(X_train)\n",
        "    r2_in_sample = r2_score(y_train, y_train_pred)\n",
        "    r2_in_sample_scores.append(r2_in_sample)\n",
        "\n",
        "    # Calcular o R^2 fora da amostra\n",
        "    r2_out_of_sample = r2_score(y_test, y_pred)\n",
        "    r2_out_of_sample_scores.append(r2_out_of_sample)\n",
        "\n",
        "# Média das métricas de avaliação em todas as dobras\n",
        "media_medae = np.mean(medae_scores)\n",
        "media_r2_in_sample = np.mean(r2_in_sample_scores)\n",
        "media_r2_out_of_sample = np.mean(r2_out_of_sample_scores)\n",
        "\n",
        "print(\"Média do Median Absolute Error (MedAE):\", media_medae)\n",
        "print(\"Média do R^2 dentro da amostra:\", media_r2_in_sample)\n",
        "print(\"Média do R^2 fora da amostra:\", media_r2_out_of_sample)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rnlls5HAuxgO",
        "outputId": "2bcc27b1-4bba-49ab-ae12-e841e0d4b8ca"
      },
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do Median Absolute Error (MedAE): 2888649.09465528\n",
            "Média do R^2 dentro da amostra: -0.06538757175268173\n",
            "Média do R^2 fora da amostra: -0.166838706874563\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CART_simples (NÃO LINEAR)"
      ],
      "metadata": {
        "id": "ZYtjgE_9OP3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2018', 'LL2018']]\n",
        "y = dados['VM30Abril2019']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "mae_scores = []\n",
        "mse_scores = []\n",
        "r2_in_sample_scores = []\n",
        "r2_out_of_sample_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de árvore de decisão com os parâmetros desejados\n",
        "    modelo_arvore = DecisionTreeRegressor(min_samples_split=5, random_state=42)\n",
        "\n",
        "    # Criar o modelo Bagging com 500 árvores\n",
        "    bagging_model = BaggingRegressor(base_estimator=modelo_arvore, n_estimators=500, bootstrap=True, random_state=42)\n",
        "\n",
        "    bagging_model.fit(X_train, y_train)\n",
        "    y_pred = bagging_model.predict(X_test)\n",
        "\n",
        "    # Calcular as métricas de avaliação\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2_in_sample = bagging_model.score(X_train, y_train)\n",
        "    r2_out_of_sample = bagging_model.score(X_test, y_test)\n",
        "\n",
        "    mae_scores.append(mae)\n",
        "    mse_scores.append(mse)\n",
        "    r2_in_sample_scores.append(r2_in_sample)\n",
        "    r2_out_of_sample_scores.append(r2_out_of_sample)\n",
        "\n",
        "# Média das métricas de avaliação em todas as dobras\n",
        "media_mae = np.mean(mae_scores)\n",
        "media_mse = np.mean(mse_scores)\n",
        "media_r2_in_sample = np.mean(r2_in_sample_scores)\n",
        "media_r2_out_of_sample = np.mean(r2_out_of_sample_scores)\n",
        "\n",
        "print(\"Média do Mean Absolute Error (MAE):\", media_mae)\n",
        "print(\"Média do Mean Squared Error (MSE):\", media_mse)\n",
        "print(\"Média do R^2 dentro da amostra:\", media_r2_in_sample)\n",
        "print(\"Média do R^2 fora da amostra:\", media_r2_out_of_sample)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDPjYJvxvNBX",
        "outputId": "10399aff-b117-4fa8-9514-677a485f3e1e"
      },
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do Mean Absolute Error (MAE): 7826413.201682327\n",
            "Média do Mean Squared Error (MSE): 629756265195674.2\n",
            "Média do R^2 dentro da amostra: 0.8869310526766316\n",
            "Média do R^2 fora da amostra: -1.2749660652455943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FLORESTA ALEATÓRIA (NÃO LINEAR)"
      ],
      "metadata": {
        "id": "OZLbiycNZm26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2018', 'LL2018']]\n",
        "y = dados['VM30Abril2019']\n",
        "\n",
        "# Certifique-se de que os tipos de dados sejam numéricos\n",
        "X = X.astype(float)\n",
        "y = y.astype(float)\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores_insample = []\n",
        "r2_scores_outsample = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro e fora da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de Floresta Aleatória com os parâmetros desejados\n",
        "    random_forest_model = RandomForestRegressor(n_estimators=500, random_state=42)\n",
        "    random_forest_model.fit(X_train, y_train)\n",
        "\n",
        "    # Previsões dentro da amostra\n",
        "    y_pred_insample = random_forest_model.predict(X_train)\n",
        "    r2_insample = r2_score(y_train, y_pred_insample)\n",
        "    r2_scores_insample.append(r2_insample)\n",
        "\n",
        "    # Previsões fora da amostra\n",
        "    y_pred_outsample = random_forest_model.predict(X_test)\n",
        "    r2_outsample = r2_score(y_test, y_pred_outsample)\n",
        "    r2_scores_outsample.append(r2_outsample)\n",
        "\n",
        "# Calcular as médias das métricas\n",
        "avg_medae = np.mean(medae_scores)\n",
        "avg_r2_insample = np.mean(r2_scores_insample)\n",
        "avg_r2_outsample = np.mean(r2_scores_outsample)\n",
        "\n",
        "print(f'Média MAE: {avg_medae}')\n",
        "print(f'Média R² dentro da amostra: {avg_r2_insample}')\n",
        "print(f'Média R² fora da amostra: {avg_r2_outsample}')\n"
      ],
      "metadata": {
        "id": "s-974AgLcd84",
        "outputId": "39402569-89ff-4ab8-ab84-7f23dc4ee0b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média MAE: nan\n",
            "Média R² dentro da amostra: 0.9332211453662854\n",
            "Média R² fora da amostra: -1.4456210469216697\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRADIENT BOOSTING (NÃO LINEAR)"
      ],
      "metadata": {
        "id": "gReIxsDPa_9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2018', 'LL2018']]\n",
        "y = dados['VM30Abril2019']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores_insample = []\n",
        "r2_scores_outsample = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro e fora da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de Regressão Gradient Boosting com os parâmetros desejados\n",
        "    gradient_boosting_model = GradientBoostingRegressor(n_estimators=500, random_state=42)\n",
        "\n",
        "    gradient_boosting_model.fit(X_train, y_train)\n",
        "\n",
        "    # Previsões dentro da amostra\n",
        "    y_pred_insample = gradient_boosting_model.predict(X_train)\n",
        "    r2_insample = r2_score(y_train, y_pred_insample)\n",
        "    r2_scores_insample.append(r2_insample)\n",
        "\n",
        "    # Previsões fora da amostra\n",
        "    y_pred_outsample = gradient_boosting_model.predict(X_test)\n",
        "    r2_outsample = r2_score(y_test, y_pred_outsample)\n",
        "    r2_scores_outsample.append(r2_outsample)\n",
        "\n",
        "# Calcular as médias das métricas\n",
        "avg_medae = np.mean(medae_scores)\n",
        "avg_r2_insample = np.mean(r2_scores_insample)\n",
        "avg_r2_outsample = np.mean(r2_scores_outsample)\n",
        "\n",
        "print(f'Média MAE: {avg_medae}')\n",
        "print(f'Média R² dentro da amostra: {avg_r2_insample}')\n",
        "print(f'Média R² fora da amostra: {avg_r2_outsample}')\n"
      ],
      "metadata": {
        "id": "qKjzwMc7dA2W",
        "outputId": "33162ccd-3b59-4b99-8a26-6cbdf770c5b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média MAE: nan\n",
            "Média R² dentro da amostra: 0.9980030735343097\n",
            "Média R² fora da amostra: -2.9591137566025045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REDES NEURAIS (NÃO LINEAR)"
      ],
      "metadata": {
        "id": "Gy8Aqujjc2rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2018', 'LL2018']]\n",
        "y = dados['VM30Abril2019']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "r2_out_of_sample_scores = []  # Para armazenar R² fora da amostra\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de regressão de rede neural com os parâmetros desejados\n",
        "    modelo_rede_neural = MLPRegressor(hidden_layer_sizes=(30), max_iter=1000, random_state=42)\n",
        "\n",
        "    modelo_rede_neural.fit(X_train, y_train)\n",
        "    y_pred_train = modelo_rede_neural.predict(X_train)\n",
        "    y_pred_test = modelo_rede_neural.predict(X_test)\n",
        "\n",
        "    r2_train = r2_score(y_train, y_pred_train)  # R² dentro da amostra\n",
        "    r2_test = r2_score(y_test, y_pred_test)    # R² fora da amostra\n",
        "\n",
        "    r2_scores.append(r2_train)\n",
        "    r2_out_of_sample_scores.append(r2_test)\n",
        "\n",
        "# Média dos R² dentro da amostra e fora da amostra\n",
        "mean_r2_within_sample = np.mean(r2_scores)\n",
        "mean_r2_out_of_sample = np.mean(r2_out_of_sample_scores)\n",
        "\n",
        "print(f'Média R² dentro da amostra: {mean_r2_within_sample}')\n",
        "print(f'Média R² fora da amostra: {mean_r2_out_of_sample}')\n"
      ],
      "metadata": {
        "id": "8DWJFQP1gcFc",
        "outputId": "4ab2390b-4eff-4279-af5e-4097a9c19485",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 240,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média R² dentro da amostra: 0.7853287811277428\n",
            "Média R² fora da amostra: -0.32817818768690116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}