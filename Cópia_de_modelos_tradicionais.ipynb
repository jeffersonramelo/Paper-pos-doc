{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOepmF5pQs6t37RZpdstsdL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffersonramelo/Paper-pos-doc/blob/main/C%C3%B3pia_de_modelos_tradicionais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Caminho para o arquivo XLSX\n",
        "caminho_arquivo = '/content/Jefferson - Dados3 - Copia.xlsx'\n",
        "\n",
        "# Lê o arquivo XLSX\n",
        "dados = pd.read_excel(caminho_arquivo)\n",
        "\n",
        "# Agora, 'dados' contém os dados do arquivo XLSX\n",
        "# Visualizar o conteúdo do DataFrame \"dados\"\n",
        "print(dados)\n"
      ],
      "metadata": {
        "id": "DOE1GbH_7pjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f23bcb8e-b1f8-473e-a931-ff8301c4f50d"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id     COD                           SETOR  d1  d2  d3  d4  d5  d6  d7  \\\n",
            "0      1   RRRP3  Petróleo gás e biocombustíveis   0   0   0   0   0   1   0   \n",
            "1      2   TTEN3             Consumo não cíclico   0   0   1   0   0   0   0   \n",
            "2      3  QVQP3B                          Outros   0   0   0   0   0   0   0   \n",
            "3      4   ABCB4                      Financeiro   0   0   0   0   0   0   0   \n",
            "4      5   EALT4                Bens industriais   1   0   0   0   0   0   0   \n",
            "..   ...     ...                             ...  ..  ..  ..  ..  ..  ..  ..   \n",
            "389  391   WIZC3                      Financeiro   0   0   0   0   0   0   0   \n",
            "390  392   WLMM4                Bens industriais   1   0   0   0   0   0   0   \n",
            "391  393   YBRA3                          Outros   0   0   0   0   0   0   0   \n",
            "392  394   YDUQ3                 Consumo cíclico   0   1   0   0   0   0   0   \n",
            "393  395   ZAMP3                 Consumo cíclico   0   1   0   0   0   0   0   \n",
            "\n",
            "     ...  ORA2013  ORA2014  ORA2015  ORA2016 ORA2017 ORA2018 ORA2019 ORA2020  \\\n",
            "0    ...        -        -        -        -       0       0       0       0   \n",
            "1    ...        -        -        -        -       -       -       -       0   \n",
            "2    ...        0        0        0        0       0       0       0       0   \n",
            "3    ...        -        -        -        -       -       -       -       -   \n",
            "4    ...        0        0        0        0       0       0       0       0   \n",
            "..   ...      ...      ...      ...      ...     ...     ...     ...     ...   \n",
            "389  ...        -        0        0        0       0       0       0       0   \n",
            "390  ...        0        0        0        0       0       0       0  102837   \n",
            "391  ...        0        0        0        0       0       0       0       0   \n",
            "392  ...        0        0        0        0       0       0       0       0   \n",
            "393  ...        -        0        0        0       0      -2      17     300   \n",
            "\n",
            "    ORA2021 ORA2022  \n",
            "0         0       0  \n",
            "1         0       0  \n",
            "2         0       0  \n",
            "3         -       -  \n",
            "4         0       0  \n",
            "..      ...     ...  \n",
            "389       0       0  \n",
            "390   99077   98279  \n",
            "391       0       0  \n",
            "392       0       0  \n",
            "393     147       0  \n",
            "\n",
            "[394 rows x 152 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "excluir setor financeiro e empresas com PL negativo"
      ],
      "metadata": {
        "id": "kEKhC6-Wf6ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agora, vamos remover as linhas onde 'd9' seja igual a 1\n",
        "dados = dados[dados['d11'] != 1]\n",
        "\n",
        "# A partir deste ponto, 'dados' conterá apenas as linhas onde 'd9' não é igual a 1\n",
        "print(dados)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cQ_iqhOf9H_",
        "outputId": "c24260bc-1222-44fe-bc4c-13945a0f8292"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id     COD                           SETOR  d1  d2  d3  d4  d5  d6  d7  \\\n",
            "0      1   RRRP3  Petróleo gás e biocombustíveis   0   0   0   0   0   1   0   \n",
            "1      2   TTEN3             Consumo não cíclico   0   0   1   0   0   0   0   \n",
            "2      3  QVQP3B                          Outros   0   0   0   0   0   0   0   \n",
            "4      5   EALT4                Bens industriais   1   0   0   0   0   0   0   \n",
            "5      6   AERI3                Bens industriais   1   0   0   0   0   0   0   \n",
            "..   ...     ...                             ...  ..  ..  ..  ..  ..  ..  ..   \n",
            "388  390   PORT3                Bens industriais   1   0   0   0   0   0   0   \n",
            "390  392   WLMM4                Bens industriais   1   0   0   0   0   0   0   \n",
            "391  393   YBRA3                          Outros   0   0   0   0   0   0   0   \n",
            "392  394   YDUQ3                 Consumo cíclico   0   1   0   0   0   0   0   \n",
            "393  395   ZAMP3                 Consumo cíclico   0   1   0   0   0   0   0   \n",
            "\n",
            "     ...  ORA2013  ORA2014  ORA2015  ORA2016 ORA2017 ORA2018 ORA2019 ORA2020  \\\n",
            "0    ...        -        -        -        -       0       0       0       0   \n",
            "1    ...        -        -        -        -       -       -       -       0   \n",
            "2    ...        0        0        0        0       0       0       0       0   \n",
            "4    ...        0        0        0        0       0       0       0       0   \n",
            "5    ...        -        -        -        -       0       0       0       0   \n",
            "..   ...      ...      ...      ...      ...     ...     ...     ...     ...   \n",
            "388  ...        0        0        0        0       0       0       0       0   \n",
            "390  ...        0        0        0        0       0       0       0  102837   \n",
            "391  ...        0        0        0        0       0       0       0       0   \n",
            "392  ...        0        0        0        0       0       0       0       0   \n",
            "393  ...        -        0        0        0       0      -2      17     300   \n",
            "\n",
            "    ORA2021 ORA2022  \n",
            "0         0       0  \n",
            "1         0       0  \n",
            "2         0       0  \n",
            "4         0       0  \n",
            "5         0       0  \n",
            "..      ...     ...  \n",
            "388       0  723446  \n",
            "390   99077   98279  \n",
            "391       0       0  \n",
            "392       0       0  \n",
            "393     147       0  \n",
            "\n",
            "[336 rows x 152 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converte a coluna 'PL2010' para números (float) e remove as linhas onde 'PL2010' seja negativo\n",
        "dados['PL2010'] = pd.to_numeric(dados['PL2010'], errors='coerce')  # 'coerce' trata strings não numéricas como NaN\n",
        "dados = dados[dados['PL2010'] >= 0]\n",
        "\n",
        "\n",
        "print(dados)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3PUXYCZ78ba",
        "outputId": "61baaab8-94c6-4e64-bf05-dc06de073b06"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id     COD                SETOR  d1  d2  d3  d4  d5  d6  d7  ...  \\\n",
            "2      3  QVQP3B               Outros   0   0   0   0   0   0   0  ...   \n",
            "4      5   EALT4     Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "6      7   AESB3    Utilidade pública   0   0   0   1   0   0   0  ...   \n",
            "8      9   AFLT3    Utilidade pública   0   0   0   1   0   0   0  ...   \n",
            "16    17   APTI4  Consumo não cíclico   0   0   1   0   0   0   0  ...   \n",
            "..   ...     ...                  ...  ..  ..  ..  ..  ..  ..  ..  ...   \n",
            "387  389   WHRL4      Consumo cíclico   0   1   0   0   0   0   0  ...   \n",
            "388  390   PORT3     Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "390  392   WLMM4     Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "391  393   YBRA3               Outros   0   0   0   0   0   0   0  ...   \n",
            "392  394   YDUQ3      Consumo cíclico   0   1   0   0   0   0   0  ...   \n",
            "\n",
            "     ORA2013  ORA2014  ORA2015  ORA2016 ORA2017 ORA2018 ORA2019 ORA2020  \\\n",
            "2          0        0        0        0       0       0       0       0   \n",
            "4          0        0        0        0       0       0       0       0   \n",
            "6     489138   388514   923107    -3289    1394  -14697  -59906  532895   \n",
            "8          0        0        0        0       0       0       0       0   \n",
            "16         0        0        0        0       0       0       0       0   \n",
            "..       ...      ...      ...      ...     ...     ...     ...     ...   \n",
            "387        0        0        0        0       0       0       0       0   \n",
            "388        0        0        0        0       0       0       0       0   \n",
            "390        0        0        0        0       0       0       0  102837   \n",
            "391        0        0        0        0       0       0       0       0   \n",
            "392        0        0        0        0       0       0       0       0   \n",
            "\n",
            "     ORA2021  ORA2022  \n",
            "2          0        0  \n",
            "4          0        0  \n",
            "6    -153563  -155638  \n",
            "8          0        0  \n",
            "16         0        0  \n",
            "..       ...      ...  \n",
            "387        0        0  \n",
            "388        0   723446  \n",
            "390    99077    98279  \n",
            "391        0        0  \n",
            "392        0        0  \n",
            "\n",
            "[209 rows x 152 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "excluir valores ausentes na variável dependente"
      ],
      "metadata": {
        "id": "HPTV8NDAhkT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agora, vamos remover as linhas onde 'VM30Abril11' seja igual a '-'\n",
        "dados = dados[dados['VM30Abril2011'] != '-']\n",
        "dados = dados[dados['PL2010'] != '-']\n",
        "dados = dados[dados['LL2010'] != '-']\n",
        "# A partir deste ponto, 'dados' conterá apenas as linhas onde 'VM30Abril11' não é igual a '-'\n",
        "print(dados)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPddSXYKho22",
        "outputId": "8250e727-e08c-4cc2-93de-55c70f94df75"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id    COD                SETOR  d1  d2  d3  d4  d5  d6  d7  ...  \\\n",
            "4      5  EALT4     Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "8      9  AFLT3    Utilidade pública   0   0   0   1   0   0   0  ...   \n",
            "20    21  ALPA4      Consumo cíclico   0   1   0   0   0   0   0  ...   \n",
            "25    26  ABEV3  Consumo não cíclico   0   0   1   0   0   0   0  ...   \n",
            "27    28  AMER3      Consumo cíclico   0   1   0   0   0   0   0  ...   \n",
            "..   ...    ...                  ...  ..  ..  ..  ..  ..  ..  ..  ...   \n",
            "386  388  MWET4     Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "387  389  WHRL4      Consumo cíclico   0   1   0   0   0   0   0  ...   \n",
            "388  390  PORT3     Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "390  392  WLMM4     Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "392  394  YDUQ3      Consumo cíclico   0   1   0   0   0   0   0  ...   \n",
            "\n",
            "     ORA2013  ORA2014  ORA2015  ORA2016 ORA2017 ORA2018 ORA2019 ORA2020  \\\n",
            "4          0        0        0        0       0       0       0       0   \n",
            "8          0        0        0        0       0       0       0       0   \n",
            "20     -1760     2802     2287     -428       0   56226   36684     235   \n",
            "25         0        0        0        0       0       0       0       0   \n",
            "27         0        0        0        0       0       0       0  -97688   \n",
            "..       ...      ...      ...      ...     ...     ...     ...     ...   \n",
            "386        0        0        0        0       0       0       0       0   \n",
            "387        0        0        0        0       0       0       0       0   \n",
            "388        0        0        0        0       0       0       0       0   \n",
            "390        0        0        0        0       0       0       0  102837   \n",
            "392        0        0        0        0       0       0       0       0   \n",
            "\n",
            "     ORA2021 ORA2022  \n",
            "4          0       0  \n",
            "8          0       0  \n",
            "20      2915    5362  \n",
            "25         0       0  \n",
            "27   -219440       -  \n",
            "..       ...     ...  \n",
            "386        0       0  \n",
            "387        0       0  \n",
            "388        0  723446  \n",
            "390    99077   98279  \n",
            "392        0       0  \n",
            "\n",
            "[175 rows x 152 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dados = dados[dados['AT2009'] != '-']\n",
        "dados = dados[dados['AT2009'] != '0']\n",
        "\n",
        "# A partir deste ponto, 'dados' conterá apenas as linhas onde 'VM30Abril11' não é igual a '-'\n",
        "print(dados)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BACHtW9Yxb1m",
        "outputId": "229c1f8b-e337-43a1-bb8c-c2a8ca0fcd30"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id    COD                SETOR  d1  d2  d3  d4  d5  d6  d7  ...  \\\n",
            "4      5  EALT4     Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "20    21  ALPA4      Consumo cíclico   0   1   0   0   0   0   0  ...   \n",
            "25    26  ABEV3  Consumo não cíclico   0   0   1   0   0   0   0  ...   \n",
            "27    28  AMER3      Consumo cíclico   0   1   0   0   0   0   0  ...   \n",
            "28    29  CBEE3    Utilidade pública   0   0   0   1   0   0   0  ...   \n",
            "..   ...    ...                  ...  ..  ..  ..  ..  ..  ..  ..  ...   \n",
            "386  388  MWET4     Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "387  389  WHRL4      Consumo cíclico   0   1   0   0   0   0   0  ...   \n",
            "388  390  PORT3     Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "390  392  WLMM4     Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "392  394  YDUQ3      Consumo cíclico   0   1   0   0   0   0   0  ...   \n",
            "\n",
            "     ORA2013  ORA2014  ORA2015  ORA2016 ORA2017 ORA2018 ORA2019 ORA2020  \\\n",
            "4          0        0        0        0       0       0       0       0   \n",
            "20     -1760     2802     2287     -428       0   56226   36684     235   \n",
            "25         0        0        0        0       0       0       0       0   \n",
            "27         0        0        0        0       0       0       0  -97688   \n",
            "28      8811     7023     4592      459    8564   -2807     697    1411   \n",
            "..       ...      ...      ...      ...     ...     ...     ...     ...   \n",
            "386        0        0        0        0       0       0       0       0   \n",
            "387        0        0        0        0       0       0       0       0   \n",
            "388        0        0        0        0       0       0       0       0   \n",
            "390        0        0        0        0       0       0       0  102837   \n",
            "392        0        0        0        0       0       0       0       0   \n",
            "\n",
            "     ORA2021 ORA2022  \n",
            "4          0       0  \n",
            "20      2915    5362  \n",
            "25         0       0  \n",
            "27   -219440       -  \n",
            "28    -27230  -56797  \n",
            "..       ...     ...  \n",
            "386        0       0  \n",
            "387        0       0  \n",
            "388        0  723446  \n",
            "390    99077   98279  \n",
            "392        0       0  \n",
            "\n",
            "[171 rows x 152 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ESCALONAMENTO DAS VARIÁVEIS"
      ],
      "metadata": {
        "id": "9GCa_0_0pZBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes escalonadas\n",
        "variaveis_independentes = ['PL2010', 'LL2010']\n",
        "\n",
        "# Escalone as variáveis independentes pelo valor AT2009\n",
        "dados[variaveis_independentes] = dados[variaveis_independentes].divide(dados['AT2009'], axis=0)\n",
        "\n",
        "# Escalone a variável dependente VM30Abril2011 pelo valor AT2009\n",
        "dados['VM30Abril2011'] = dados['VM30Abril2011'] / dados['AT2009']\n"
      ],
      "metadata": {
        "id": "O4rQ3G_QsFjn"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tratar outliers: A winsorização ao nível de 1% envolve substituir os 1% dos valores mais extremos por valores no limite do intervalo aceitável, ou seja, os 1% menores e os 1% maiores dos valores."
      ],
      "metadata": {
        "id": "95LYGQCnbVVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import mstats\n",
        "\n",
        "# Supondo que seu DataFrame se chame \"dados\"\n",
        "\n",
        "# Lista de variáveis para winsorizar\n",
        "variaveis_winsorizar = ['VM30Abril2011', 'PL2010', 'LL2010', 'AT2009']\n",
        "\n",
        "# Converter as colunas para números, tratando não numéricos como NaN\n",
        "for coluna in variaveis_winsorizar:\n",
        "    dados[coluna] = pd.to_numeric(dados[coluna], errors='coerce')\n",
        "\n",
        "# Aplicar winsorização de 1% nas variáveis\n",
        "for coluna in variaveis_winsorizar:\n",
        "    dados[coluna] = mstats.winsorize(dados[coluna], limits=[0.01, 0.01])\n",
        "\n",
        "# Agora, as variáveis especificadas foram winsorizadas\n"
      ],
      "metadata": {
        "id": "lOpHHKqnzgzN"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MQO_SIMPLES"
      ],
      "metadata": {
        "id": "9rBG78W6yny2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from statsmodels.stats.diagnostic import het_white\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Certifique-se de que os tipos de dados sejam numéricos\n",
        "X = X.astype(float)\n",
        "y = y.astype(float)\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão linear\n",
        "modelo = sm.OLS(y, X).fit()\n",
        "\n",
        "# Visualize os resultados do modelo\n",
        "print(modelo.summary())\n",
        "\n",
        "# Calcule o MedAE\n",
        "y_pred = modelo.predict(X)\n",
        "medae = np.median(np.abs(y - y_pred))\n",
        "\n",
        "# Calcule o valor médio da variável de resposta\n",
        "valor_medio_y = np.mean(y)\n",
        "\n",
        "# Calcule o MedAE escalado pelo valor (ou preço)\n",
        "medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "print(\"Median Absolute Error (MedAE):\", medae)\n",
        "print(\"MedAE escalado pelo valor (ou preço) em percentagem:\", medae_scaled)\n",
        "\n",
        "# Calcular os VIFs (Fator de Inflação da Variância)\n",
        "def calculate_vif(dataframe):\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"Variável\"] = dataframe.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(dataframe.values, i) for i in range(dataframe.shape[1])]\n",
        "    return vif_data\n",
        "\n",
        "vif_result = calculate_vif(X.drop(columns=['const']))\n",
        "print(\"\\nFator de Inflação da Variância (VIF):\")\n",
        "print(vif_result)\n",
        "\n",
        "# Realizar o teste de heterocedasticidade de White\n",
        "white_test_result = het_white(modelo.resid, X)\n",
        "print(\"\\nResultado do teste de heterocedasticidade de White:\")\n",
        "print(\"LM Statistic:\", white_test_result[0])\n",
        "print(\"LM p-value:\", white_test_result[1])\n",
        "print(\"F Statistic:\", white_test_result[2])\n",
        "print(\"F p-value:\", white_test_result[3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-8twO8YyD_l",
        "outputId": "d445a38c-4c2b-4d05-8fb6-47e0bd8cfe8c"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:          VM30Abril2011   R-squared:                       0.579\n",
            "Model:                            OLS   Adj. R-squared:                  0.574\n",
            "Method:                 Least Squares   F-statistic:                     115.4\n",
            "Date:                Tue, 26 Sep 2023   Prob (F-statistic):           2.88e-32\n",
            "Time:                        23:14:46   Log-Likelihood:                -290.25\n",
            "No. Observations:                 171   AIC:                             586.5\n",
            "Df Residuals:                     168   BIC:                             595.9\n",
            "Df Model:                           2                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         -0.4020      0.176     -2.282      0.024      -0.750      -0.054\n",
            "PL2010         2.7901      0.184     15.168      0.000       2.427       3.153\n",
            "LL2010         1.4278      1.022      1.398      0.164      -0.589       3.445\n",
            "==============================================================================\n",
            "Omnibus:                       96.661   Durbin-Watson:                   1.938\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              575.993\n",
            "Skew:                           2.066   Prob(JB):                    8.41e-126\n",
            "Kurtosis:                      10.985   Cond. No.                         12.3\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "Median Absolute Error (MedAE): 0.5554458000294278\n",
            "MedAE escalado pelo valor (ou preço) em percentagem: 39.138701637153275\n",
            "\n",
            "Fator de Inflação da Variância (VIF):\n",
            "  Variável       VIF\n",
            "0   PL2010  1.134901\n",
            "1   LL2010  1.134901\n",
            "\n",
            "Resultado do teste de heterocedasticidade de White:\n",
            "LM Statistic: 25.219187346877973\n",
            "LM p-value: 0.00012639030517189382\n",
            "F Statistic: 5.708797799249681\n",
            "F p-value: 6.93903393001165e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MQP - MODELO SIMPLES"
      ],
      "metadata": {
        "id": "IXhYrWVgKtFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from statsmodels.stats.diagnostic import het_white\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Certifique-se de que os tipos de dados sejam numéricos\n",
        "X = X.astype(float)\n",
        "y = y.astype(float)\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão linear\n",
        "modelo = sm.OLS(y, X).fit()\n",
        "\n",
        "# Calcule os resíduos (erros)\n",
        "residuos = modelo.resid\n",
        "\n",
        "# Calcule a variância dos resíduos\n",
        "variancia_residuos = np.var(residuos)\n",
        "\n",
        "# Calcule os pesos com base na variância dos resíduos (inverso da variância)\n",
        "pesos = 1 / variancia_residuos\n",
        "\n",
        "# Crie o modelo de regressão linear ponderada (WLS) com os pesos calculados\n",
        "modelo_wls = sm.WLS(y, X, weights=pesos).fit()\n",
        "\n",
        "# Visualize os resultados do modelo ponderado\n",
        "print(modelo_wls.summary())\n",
        "\n",
        "# Calcule os resíduos ponderados (erros ponderados)\n",
        "y_pred_wls = modelo_wls.predict(X)\n",
        "residuos_wls = y - y_pred_wls\n",
        "\n",
        "# Calcule o MedAE ponderado\n",
        "medae_wls = np.median(np.abs(residuos_wls))\n",
        "\n",
        "# Calcule o valor médio da variável de resposta\n",
        "valor_medio_y = np.mean(y)\n",
        "\n",
        "# Calcule o MedAE ponderado escalado pelo valor (ou preço) em percentagem\n",
        "medae_scaled_wls = (medae_wls / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "print(\"Median Absolute Error (MedAE) ponderado:\", medae_wls)\n",
        "print(\"MedAE ponderado escalado pelo valor (ou preço) em percentagem:\", medae_scaled_wls)\n",
        "\n",
        "# Calcular os VIFs (Fator de Inflação da Variância)\n",
        "def calculate_vif(dataframe):\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"Variável\"] = dataframe.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(dataframe.values, i) for i in range(dataframe.shape[1])]\n",
        "    return vif_data\n",
        "\n",
        "vif_result = calculate_vif(X.drop(columns=['const']))\n",
        "print(\"\\nFator de Inflação da Variância (VIF):\")\n",
        "print(vif_result)\n",
        "\n",
        "# Realizar o teste de heterocedasticidade de White\n",
        "white_test_result = het_white(modelo_wls.resid, X)\n",
        "print(\"\\nResultado do teste de heterocedasticidade de White:\")\n",
        "print(\"LM Statistic:\", white_test_result[0])\n",
        "print(\"LM p-value:\", white_test_result[1])\n",
        "print(\"F Statistic:\", white_test_result[2])\n",
        "print(\"F p-value:\", white_test_result[3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPJjvuLXwnTN",
        "outputId": "801a3bf8-3b19-48fa-ef4b-60b4c1192909"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            WLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:          VM30Abril2011   R-squared:                       0.579\n",
            "Model:                            WLS   Adj. R-squared:                  0.574\n",
            "Method:                 Least Squares   F-statistic:                     115.4\n",
            "Date:                Tue, 26 Sep 2023   Prob (F-statistic):           2.88e-32\n",
            "Time:                        23:17:02   Log-Likelihood:                -290.25\n",
            "No. Observations:                 171   AIC:                             586.5\n",
            "Df Residuals:                     168   BIC:                             595.9\n",
            "Df Model:                           2                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         -0.4020      0.176     -2.282      0.024      -0.750      -0.054\n",
            "PL2010         2.7901      0.184     15.168      0.000       2.427       3.153\n",
            "LL2010         1.4278      1.022      1.398      0.164      -0.589       3.445\n",
            "==============================================================================\n",
            "Omnibus:                       96.661   Durbin-Watson:                   1.938\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              575.993\n",
            "Skew:                           2.066   Prob(JB):                    8.41e-126\n",
            "Kurtosis:                      10.985   Cond. No.                         12.3\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "Median Absolute Error (MedAE) ponderado: 0.5554458000294287\n",
            "MedAE ponderado escalado pelo valor (ou preço) em percentagem: 39.13870163715334\n",
            "\n",
            "Fator de Inflação da Variância (VIF):\n",
            "  Variável       VIF\n",
            "0   PL2010  1.134901\n",
            "1   LL2010  1.134901\n",
            "\n",
            "Resultado do teste de heterocedasticidade de White:\n",
            "LM Statistic: 25.219187346877916\n",
            "LM p-value: 0.000126390305171897\n",
            "F Statistic: 5.708797799249667\n",
            "F p-value: 6.939033930011791e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REGRESSÃO QUANTÍLICA_SIMPLES"
      ],
      "metadata": {
        "id": "fUZVJwTv19EF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Certifique-se de que os tipos de dados sejam numéricos\n",
        "X = X.astype(float)\n",
        "y = y.astype(float)\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão quantílica\n",
        "modelo = sm.QuantReg(y, X).fit(q=0.5)  # q=0.5 representa a mediana, ajuste conforme necessário\n",
        "\n",
        "# Visualize os resultados do modelo\n",
        "print(modelo.summary())\n",
        "# Faça previsões com o modelo quantílico\n",
        "y_pred_quantreg = modelo.predict(X)\n",
        "\n",
        "# Calcule o MedAE para o modelo quantílico\n",
        "medae_quantreg = np.median(np.abs(y - y_pred_quantreg))\n",
        "\n",
        "# Calcule o valor médio da variável de resposta\n",
        "valor_medio_y = np.mean(y)\n",
        "\n",
        "# Calcule o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "medae_scaled_quantreg = (medae_quantreg / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "print(\"Median Absolute Error (MedAE) quantílico:\", medae_quantreg)\n",
        "print(\"MedAE quantílico escalado pelo valor (ou preço) em percentagem:\", medae_scaled_quantreg)\n"
      ],
      "metadata": {
        "id": "dgpuCY5p1_I5",
        "outputId": "9999788a-b92a-45e2-ffc1-729813f6dfc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         QuantReg Regression Results                          \n",
            "==============================================================================\n",
            "Dep. Variable:          VM30Abril2011   Pseudo R-squared:               0.1690\n",
            "Model:                       QuantReg   Bandwidth:                      0.5559\n",
            "Method:                 Least Squares   Sparsity:                        1.560\n",
            "Date:                Tue, 26 Sep 2023   No. Observations:                  171\n",
            "Time:                        23:17:44   Df Residuals:                      168\n",
            "                                        Df Model:                            2\n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         -0.1353      0.103     -1.313      0.191      -0.339       0.068\n",
            "PL2010         1.5357      0.108     14.263      0.000       1.323       1.748\n",
            "LL2010         3.4919      0.598      5.839      0.000       2.311       4.672\n",
            "==============================================================================\n",
            "Median Absolute Error (MedAE) quantílico: 0.3854166995452897\n",
            "MedAE quantílico escalado pelo valor (ou preço) em percentagem: 27.15784187886603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RB_Simples"
      ],
      "metadata": {
        "id": "X-hPlPqnNEYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import median_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo Bayesian Ridge\n",
        "    modelo_bayesiano = BayesianRidge()\n",
        "\n",
        "    modelo_bayesiano.fit(X_train, y_train)\n",
        "    y_pred = modelo_bayesiano.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = median_absolute_error(y_test, y_pred)\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar os coeficientes do modelo (coeficientes Bayesianos)\n",
        "    coeficientes = modelo_bayesiano.coef_\n",
        "    print(\"Coeficientes do Modelo:\", coeficientes)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b7fcb61-8f44-40bf-bdde-7b6760f69f2b",
        "id": "zj4mQ3zrNLrh"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coeficientes do Modelo: [2.82474811 1.04588916]\n",
            "Coeficientes do Modelo: [1.56384952 2.74109887]\n",
            "Coeficientes do Modelo: [2.73575194 0.97441068]\n",
            "Coeficientes do Modelo: [2.82542439 0.79046095]\n",
            "Coeficientes do Modelo: [2.74119735 0.92287285]\n",
            "Coeficientes do Modelo: [2.74921716 0.97254189]\n",
            "Coeficientes do Modelo: [2.84297443 0.84034845]\n",
            "Coeficientes do Modelo: [2.77469745 1.2517257 ]\n",
            "Coeficientes do Modelo: [2.76416953 1.02884602]\n",
            "Coeficientes do Modelo: [2.79939413 1.02102852]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 45.2998787945073\n",
            "Média do R²: -0.6416351638656181\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVR"
      ],
      "metadata": {
        "id": "NIw0ZhcK_9OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import median_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo SVR com kernel RBF\n",
        "    modelo_svr = SVR(kernel='rbf', C=1.0)\n",
        "\n",
        "    modelo_svr.fit(X_train, y_train)\n",
        "    y_pred = modelo_svr.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = median_absolute_error(y_test, y_pred)\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPXr6W3_Hh_z",
        "outputId": "7f3b17cb-9292-479f-88c5-1db984c7fa4b"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 27.03254996151665\n",
            "Média do R²: 0.06691492864308335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CART_simples"
      ],
      "metadata": {
        "id": "ZYtjgE_9OP3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de árvore de decisão com os parâmetros desejados\n",
        "    modelo_arvore = DecisionTreeRegressor(min_samples_split=5, random_state=42)\n",
        "\n",
        "    # Criar o modelo Bagging com 500 árvores\n",
        "    bagging_model = BaggingRegressor(base_estimator=modelo_arvore, n_estimators=500, bootstrap=True, random_state=42)\n",
        "\n",
        "    bagging_model.fit(X_train, y_train)\n",
        "    y_pred = bagging_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar a importância dos coeficientes (importância das variáveis)\n",
        "    importancia_coeficientes = np.mean([tree.feature_importances_ for tree in bagging_model.estimators_], axis=0)\n",
        "    print(\"Importância dos Coeficientes:\", importancia_coeficientes)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "463b5524-2e8e-4a1d-a932-b0ed5e11a5db",
        "id": "c3TdDSmhOYKa"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.42041231 0.57958769]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.362848 0.637152]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.36154547 0.63845453]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.43396428 0.56603572]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.39232503 0.60767497]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.35959616 0.64040384]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.34287376 0.65712624]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.34906547 0.65093453]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.37561098 0.62438902]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.36939291 0.63060709]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 36.776025069970615\n",
            "Média do R²: -1.7023953781476997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FLORESTA ALEATÓRIA"
      ],
      "metadata": {
        "id": "OZLbiycNZm26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Certifique-se de que os tipos de dados sejam numéricos\n",
        "X = X.astype(float)\n",
        "y = y.astype(float)\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de Floresta Aleatória com os parâmetros desejados\n",
        "    random_forest_model = RandomForestRegressor(n_estimators=500, random_state=42)\n",
        "\n",
        "    random_forest_model.fit(X_train, y_train)\n",
        "    y_pred = random_forest_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar a importância das variáveis\n",
        "    importancia_variaveis = random_forest_model.feature_importances_\n",
        "    print(\"Importância das Variáveis:\", importancia_variaveis)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "id": "lpAmsgS7Zph4",
        "outputId": "14c2f291-a610-44f9-9dfa-bda789e6d4b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância das Variáveis: [0.31288347 0.68711653]\n",
            "Importância das Variáveis: [0.39860621 0.60139379]\n",
            "Importância das Variáveis: [0.40281555 0.59718445]\n",
            "Importância das Variáveis: [0.4132134 0.5867866]\n",
            "Importância das Variáveis: [0.32293532 0.67706468]\n",
            "Importância das Variáveis: [0.38313455 0.61686545]\n",
            "Importância das Variáveis: [0.42001416 0.57998584]\n",
            "Importância das Variáveis: [0.41205439 0.58794561]\n",
            "Importância das Variáveis: [0.39982152 0.60017848]\n",
            "Importância das Variáveis: [0.47232105 0.52767895]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 31.432793256876515\n",
            "Média do R²: -5.250013250817288\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRADIENT BOOSTING"
      ],
      "metadata": {
        "id": "gReIxsDPa_9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de Regressão Gradient Boosting com os parâmetros desejados\n",
        "    gradient_boosting_model = GradientBoostingRegressor(n_estimators=500, random_state=42)\n",
        "\n",
        "    gradient_boosting_model.fit(X_train, y_train)\n",
        "    y_pred = gradient_boosting_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar a importância das variáveis\n",
        "    importancia_variaveis = gradient_boosting_model.feature_importances_\n",
        "    print(\"Importância das Variáveis:\", importancia_variaveis)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "id": "NvfZ3qUAbCf5",
        "outputId": "86b421b8-cb7a-4b66-d856-d0aafede7cb7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância das Variáveis: [0.53561193 0.46438807]\n",
            "Importância das Variáveis: [0.37874477 0.62125523]\n",
            "Importância das Variáveis: [0.4654923 0.5345077]\n",
            "Importância das Variáveis: [0.45342691 0.54657309]\n",
            "Importância das Variáveis: [0.44779253 0.55220747]\n",
            "Importância das Variáveis: [0.51240566 0.48759434]\n",
            "Importância das Variáveis: [0.36261426 0.63738574]\n",
            "Importância das Variáveis: [0.37471478 0.62528522]\n",
            "Importância das Variáveis: [0.51139629 0.48860371]\n",
            "Importância das Variáveis: [0.50121259 0.49878741]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 37.38929176348158\n",
            "Média do R²: -1.87449945816413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REDES NEURAIS"
      ],
      "metadata": {
        "id": "Gy8Aqujjc2rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de regressão de rede neural com os parâmetros desejados\n",
        "    modelo_rede_neural = MLPRegressor(hidden_layer_sizes=(30), max_iter=1000, random_state=42)\n",
        "\n",
        "    modelo_rede_neural.fit(X_train, y_train)\n",
        "    y_pred = modelo_rede_neural.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "id": "yygOLB39c4OY",
        "outputId": "6d7d11bf-0396-4dbc-8824-73dde0d355b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 42.01543468298843\n",
            "Média do R²: -0.23654257294774003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}