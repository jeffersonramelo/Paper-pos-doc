{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYB+ntSpNFJ/RUAfWErZU7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffersonramelo/Paper-pos-doc/blob/main/C%C3%B3pia_de_modelos_tradicionais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Caminho para o arquivo XLSX\n",
        "caminho_arquivo = '/content/dados todos sem escala.xlsx'\n",
        "\n",
        "# Lê o arquivo XLSX\n",
        "dados = pd.read_excel(caminho_arquivo)\n",
        "\n",
        "# Agora, 'dados' contém os dados do arquivo XLSX\n",
        "# Visualizar o conteúdo do DataFrame \"dados\"\n",
        "print(dados)\n"
      ],
      "metadata": {
        "id": "DOE1GbH_7pjb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be838b45-9325-4437-c838-c17b49d85482"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        COD     t  VM30Abril2011      PL2010     LL2010      AT2009\n",
            "0     EALT4  2010   6.072750e+04     45809.0     5927.0    143196.0\n",
            "1     ALPA4  2010   3.893923e+06   1310475.0   306341.0   1748959.0\n",
            "2     ABEV3  2010   1.422082e+08  24361863.0  7561383.0  40101017.0\n",
            "3     AMER3  2010   2.382110e+06    225945.0    33587.0   2324320.0\n",
            "4     CBEE3  2010   4.773374e+06   1583469.0   216092.0   4589050.0\n",
            "...     ...   ...            ...         ...        ...         ...\n",
            "2849  WHRL4  2022   6.630416e+06   2176471.0   416715.0   9164610.0\n",
            "2850  PORT3  2022   4.390289e+06   2345826.0   327064.0   5724443.0\n",
            "2851  WLMM4  2022   7.129722e+05    622011.0   117298.0    668104.0\n",
            "2852  YDUQ3  2022   2.358681e+06   2946247.0   -58244.0   9897795.0\n",
            "2853  ZAMP3  2022   1.120447e+06   1485188.0   -55786.0   3813408.0\n",
            "\n",
            "[2854 rows x 6 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "excluir setor financeiro e empresas com PL negativo"
      ],
      "metadata": {
        "id": "kEKhC6-Wf6ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agora, vamos remover as linhas onde 'd9' seja igual a 1\n",
        "dados = dados[dados['d11'] != 1]\n",
        "\n",
        "# A partir deste ponto, 'dados' conterá apenas as linhas onde 'd9' não é igual a 1\n",
        "print(dados)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cQ_iqhOf9H_",
        "outputId": "4cc7218c-3e9a-46f9-9913-2012fbcf838d"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id     COD                           SETOR  d1  d2  d3  d4  d5  d6  d7  \\\n",
            "0      1   RRRP3  Petróleo gás e biocombustíveis   0   0   0   0   0   1   0   \n",
            "1      2   TTEN3             Consumo não cíclico   0   0   1   0   0   0   0   \n",
            "2      3  QVQP3B                          Outros   0   0   0   0   0   0   0   \n",
            "4      5   EALT4                Bens industriais   1   0   0   0   0   0   0   \n",
            "5      6   AERI3                Bens industriais   1   0   0   0   0   0   0   \n",
            "..   ...     ...                             ...  ..  ..  ..  ..  ..  ..  ..   \n",
            "388  390   PORT3                Bens industriais   1   0   0   0   0   0   0   \n",
            "390  392   WLMM4                Bens industriais   1   0   0   0   0   0   0   \n",
            "391  393   YBRA3                          Outros   0   0   0   0   0   0   0   \n",
            "392  394   YDUQ3                 Consumo cíclico   0   1   0   0   0   0   0   \n",
            "393  395   ZAMP3                 Consumo cíclico   0   1   0   0   0   0   0   \n",
            "\n",
            "     ...  ORA2013  ORA2014  ORA2015  ORA2016 ORA2017 ORA2018 ORA2019 ORA2020  \\\n",
            "0    ...        -        -        -        -       0       0       0       0   \n",
            "1    ...        -        -        -        -       -       -       -       0   \n",
            "2    ...        0        0        0        0       0       0       0       0   \n",
            "4    ...        0        0        0        0       0       0       0       0   \n",
            "5    ...        -        -        -        -       0       0       0       0   \n",
            "..   ...      ...      ...      ...      ...     ...     ...     ...     ...   \n",
            "388  ...        0        0        0        0       0       0       0       0   \n",
            "390  ...        0        0        0        0       0       0       0  102837   \n",
            "391  ...        0        0        0        0       0       0       0       0   \n",
            "392  ...        0        0        0        0       0       0       0       0   \n",
            "393  ...        -        0        0        0       0      -2      17     300   \n",
            "\n",
            "    ORA2021 ORA2022  \n",
            "0         0       0  \n",
            "1         0       0  \n",
            "2         0       0  \n",
            "4         0       0  \n",
            "5         0       0  \n",
            "..      ...     ...  \n",
            "388       0  723446  \n",
            "390   99077   98279  \n",
            "391       0       0  \n",
            "392       0       0  \n",
            "393     147       0  \n",
            "\n",
            "[336 rows x 152 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converte a coluna 'PL2010' para números (float) e remove as linhas onde 'PL2010' seja negativo\n",
        "dados['PL2010'] = pd.to_numeric(dados['PL2010'], errors='coerce')  # 'coerce' trata strings não numéricas como NaN\n",
        "dados = dados[dados['PL2010'] > 0]\n",
        "\n",
        "\n",
        "print(dados)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3PUXYCZ78ba",
        "outputId": "386bd0b0-5626-47e3-9450-96d2b0652c10"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id     COD              SETOR  d1  d2  d3  d4  d5  d6  d7  ...  ORA2013  \\\n",
            "3      4   ABCB4         Financeiro   0   0   0   0   0   0   0  ...        -   \n",
            "4      5   EALT4   Bens industriais   1   0   0   0   0   0   0  ...        0   \n",
            "8      9   AFLT3  Utilidade pública   0   0   0   1   0   0   0  ...        0   \n",
            "11    12  BRGE12         Financeiro   0   0   0   0   0   0   0  ...        0   \n",
            "12    13   CRIV4         Financeiro   0   0   0   0   0   0   0  ...        0   \n",
            "..   ...     ...                ...  ..  ..  ..  ..  ..  ..  ..  ...      ...   \n",
            "386  388   MWET4   Bens industriais   1   0   0   0   0   0   0  ...        0   \n",
            "387  389   WHRL4    Consumo cíclico   0   1   0   0   0   0   0  ...        0   \n",
            "388  390   PORT3   Bens industriais   1   0   0   0   0   0   0  ...        0   \n",
            "390  392   WLMM4   Bens industriais   1   0   0   0   0   0   0  ...        0   \n",
            "392  394   YDUQ3    Consumo cíclico   0   1   0   0   0   0   0  ...        0   \n",
            "\n",
            "     ORA2014  ORA2015  ORA2016 ORA2017 ORA2018 ORA2019 ORA2020 ORA2021 ORA2022  \n",
            "3          -        -        -       -       -       -       -       -       -  \n",
            "4          0        0        0       0       0       0       0       0       0  \n",
            "8          0        0        0       0       0       0       0       0       0  \n",
            "11         0        0        0       0       0       0       0       0       0  \n",
            "12         0        0        0       0       0       0       0       0       0  \n",
            "..       ...      ...      ...     ...     ...     ...     ...     ...     ...  \n",
            "386        0        0        0       0       0       0       0       0       0  \n",
            "387        0        0        0       0       0       0       0       0       0  \n",
            "388        0        0        0       0       0       0       0       0  723446  \n",
            "390        0        0        0       0       0       0  102837   99077   98279  \n",
            "392        0        0        0       0       0       0       0       0       0  \n",
            "\n",
            "[216 rows x 152 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "excluir valores ausentes na variável dependente"
      ],
      "metadata": {
        "id": "HPTV8NDAhkT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agora, vamos remover as linhas onde 'VM30Abril11' seja igual a '-'\n",
        "dados = dados[dados['VM30Abril2011'] != '-']\n",
        "dados = dados[dados['PL2010'] != '-']\n",
        "dados = dados[dados['LL2010'] != '-']\n",
        "# A partir deste ponto, 'dados' conterá apenas as linhas onde 'VM30Abril11' não é igual a '-'\n",
        "print(dados)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPddSXYKho22",
        "outputId": "62b50d72-d3ff-4f74-943e-faa334c36231"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id     COD              SETOR  d1  d2  d3  d4  d5  d6  d7  ...  ORA2013  \\\n",
            "3      4   ABCB4         Financeiro   0   0   0   0   0   0   0  ...        -   \n",
            "4      5   EALT4   Bens industriais   1   0   0   0   0   0   0  ...        0   \n",
            "8      9   AFLT3  Utilidade pública   0   0   0   1   0   0   0  ...        0   \n",
            "11    12  BRGE12         Financeiro   0   0   0   0   0   0   0  ...        0   \n",
            "12    13   CRIV4         Financeiro   0   0   0   0   0   0   0  ...        0   \n",
            "..   ...     ...                ...  ..  ..  ..  ..  ..  ..  ..  ...      ...   \n",
            "386  388   MWET4   Bens industriais   1   0   0   0   0   0   0  ...        0   \n",
            "387  389   WHRL4    Consumo cíclico   0   1   0   0   0   0   0  ...        0   \n",
            "388  390   PORT3   Bens industriais   1   0   0   0   0   0   0  ...        0   \n",
            "390  392   WLMM4   Bens industriais   1   0   0   0   0   0   0  ...        0   \n",
            "392  394   YDUQ3    Consumo cíclico   0   1   0   0   0   0   0  ...        0   \n",
            "\n",
            "     ORA2014  ORA2015  ORA2016 ORA2017 ORA2018 ORA2019 ORA2020 ORA2021 ORA2022  \n",
            "3          -        -        -       -       -       -       -       -       -  \n",
            "4          0        0        0       0       0       0       0       0       0  \n",
            "8          0        0        0       0       0       0       0       0       0  \n",
            "11         0        0        0       0       0       0       0       0       0  \n",
            "12         0        0        0       0       0       0       0       0       0  \n",
            "..       ...      ...      ...     ...     ...     ...     ...     ...     ...  \n",
            "386        0        0        0       0       0       0       0       0       0  \n",
            "387        0        0        0       0       0       0       0       0       0  \n",
            "388        0        0        0       0       0       0       0       0  723446  \n",
            "390        0        0        0       0       0       0  102837   99077   98279  \n",
            "392        0        0        0       0       0       0       0       0       0  \n",
            "\n",
            "[233 rows x 152 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dados = dados[dados['AT2009'] != '-']\n",
        "dados = dados[dados['AT2009'] != '0']\n",
        "\n",
        "# A partir deste ponto, 'dados' conterá apenas as linhas onde 'VM30Abril11' não é igual a '-'\n",
        "print(dados)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BACHtW9Yxb1m",
        "outputId": "f0f7153a-f5fa-4f96-aa95-4cd25b8f0e85"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id     COD             SETOR  d1  d2  d3  d4  d5  d6  d7  ...  ORA2013  \\\n",
            "3      4   ABCB4        Financeiro   0   0   0   0   0   0   0  ...        -   \n",
            "4      5   EALT4  Bens industriais   1   0   0   0   0   0   0  ...        0   \n",
            "11    12  BRGE12        Financeiro   0   0   0   0   0   0   0  ...        0   \n",
            "12    13   CRIV4        Financeiro   0   0   0   0   0   0   0  ...        0   \n",
            "13    14   RPAD3        Financeiro   0   0   0   0   0   0   0  ...        0   \n",
            "..   ...     ...               ...  ..  ..  ..  ..  ..  ..  ..  ...      ...   \n",
            "386  388   MWET4  Bens industriais   1   0   0   0   0   0   0  ...        0   \n",
            "387  389   WHRL4   Consumo cíclico   0   1   0   0   0   0   0  ...        0   \n",
            "388  390   PORT3  Bens industriais   1   0   0   0   0   0   0  ...        0   \n",
            "390  392   WLMM4  Bens industriais   1   0   0   0   0   0   0  ...        0   \n",
            "392  394   YDUQ3   Consumo cíclico   0   1   0   0   0   0   0  ...        0   \n",
            "\n",
            "     ORA2014  ORA2015  ORA2016 ORA2017 ORA2018 ORA2019 ORA2020 ORA2021 ORA2022  \n",
            "3          -        -        -       -       -       -       -       -       -  \n",
            "4          0        0        0       0       0       0       0       0       0  \n",
            "11         0        0        0       0       0       0       0       0       0  \n",
            "12         0        0        0       0       0       0       0       0       0  \n",
            "13         0        0        0       0       0       0       0       0       0  \n",
            "..       ...      ...      ...     ...     ...     ...     ...     ...     ...  \n",
            "386        0        0        0       0       0       0       0       0       0  \n",
            "387        0        0        0       0       0       0       0       0       0  \n",
            "388        0        0        0       0       0       0       0       0  723446  \n",
            "390        0        0        0       0       0       0  102837   99077   98279  \n",
            "392        0        0        0       0       0       0       0       0       0  \n",
            "\n",
            "[211 rows x 152 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ESCALONAMENTO DAS VARIÁVEIS"
      ],
      "metadata": {
        "id": "9GCa_0_0pZBs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dados['AT2009'] = pd.to_numeric(dados['AT2009'], errors='coerce')\n",
        "dados['LL2010'] = pd.to_numeric(dados['LL2010'], errors='coerce')\n",
        "dados['VM30Abril2011'] = pd.to_numeric(dados['VM30Abril2011'], errors='coerce')\n",
        "dados['PL2010'] = pd.to_numeric(dados['PL2010'], errors='coerce')\n"
      ],
      "metadata": {
        "id": "S4be4jZSgtUc"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de variáveis que você deseja escalonar\n",
        "variaveis = ['VM30Abril2011', 'PL2010', 'LL2010', 'AT2009']\n",
        "\n",
        "# Verifique o tipo de dados de cada coluna\n",
        "for coluna in variaveis:\n",
        "    print(f\"Tipo de dados da coluna {coluna}: {dados[coluna].dtype}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM9N-qiafCbe",
        "outputId": "6c322f9e-8674-4e29-9993-06793797004e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tipo de dados da coluna VM30Abril2011: float64\n",
            "Tipo de dados da coluna PL2010: float64\n",
            "Tipo de dados da coluna LL2010: float64\n",
            "Tipo de dados da coluna AT2009: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Suponha que 'dados' seja o seu DataFrame\n",
        "\n",
        "# Use o método dropna() para remover as linhas com NaN em 'AT2009'\n",
        "dados = dados.dropna(subset=['AT2009'])\n",
        "\n",
        "# Agora, 'dados' não conterá mais as linhas com NaN em 'AT2009'\n"
      ],
      "metadata": {
        "id": "GPChA9athcyW"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "variaveis = ['VM30Abril2011', 'PL2010', 'LL2010']\n",
        "\n",
        "for coluna in variaveis:\n",
        "    dados[coluna] = dados[coluna] / dados['AT2009']\n"
      ],
      "metadata": {
        "id": "A7MYj6i9h6LO"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tratar outliers: A winsorização ao nível de 1% envolve substituir os 1% dos valores mais extremos por valores no limite do intervalo aceitável, ou seja, os 1% menores e os 1% maiores dos valores."
      ],
      "metadata": {
        "id": "95LYGQCnbVVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import mstats\n",
        "\n",
        "# Supondo que seu DataFrame se chame \"dados\"\n",
        "\n",
        "# Lista de variáveis para winsorizar\n",
        "variaveis_winsorizar = ['VM30Abril2011', 'PL2010', 'LL2010', 'AT2009']\n",
        "\n",
        "# Converter as colunas para números, tratando não numéricos como NaN\n",
        "for coluna in variaveis_winsorizar:\n",
        "    dados[coluna] = pd.to_numeric(dados[coluna], errors='coerce')\n",
        "\n",
        "# Aplicar winsorização de 1% nas variáveis\n",
        "for coluna in variaveis_winsorizar:\n",
        "    dados[coluna] = mstats.winsorize(dados[coluna], limits=[0.01, 0.01])\n",
        "\n",
        "# Agora, as variáveis especificadas foram winsorizadas\n"
      ],
      "metadata": {
        "id": "lOpHHKqnzgzN"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MQO_SIMPLES"
      ],
      "metadata": {
        "id": "9rBG78W6yny2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from statsmodels.stats.diagnostic import het_white\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Certifique-se de que os tipos de dados sejam numéricos\n",
        "X = X.astype(float)\n",
        "y = y.astype(float)\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão linear\n",
        "modelo = sm.OLS(y, X).fit()\n",
        "\n",
        "# Visualize os resultados do modelo\n",
        "print(modelo.summary())\n",
        "\n",
        "# Calcule o MedAE\n",
        "y_pred = modelo.predict(X)\n",
        "medae = np.median(np.abs(y - y_pred))\n",
        "\n",
        "# Calcule o valor médio da variável de resposta\n",
        "valor_medio_y = np.mean(y)\n",
        "\n",
        "# Calcule o MedAE escalado pelo valor (ou preço)\n",
        "medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "print(\"Median Absolute Error (MedAE):\", medae)\n",
        "print(\"MedAE escalado pelo valor (ou preço) em percentagem:\", medae_scaled)\n",
        "\n",
        "# Calcular os VIFs (Fator de Inflação da Variância)\n",
        "def calculate_vif(dataframe):\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"Variável\"] = dataframe.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(dataframe.values, i) for i in range(dataframe.shape[1])]\n",
        "    return vif_data\n",
        "\n",
        "vif_result = calculate_vif(X.drop(columns=['const']))\n",
        "print(\"\\nFator de Inflação da Variância (VIF):\")\n",
        "print(vif_result)\n",
        "\n",
        "# Realizar o teste de heterocedasticidade de White\n",
        "white_test_result = het_white(modelo.resid, X)\n",
        "print(\"\\nResultado do teste de heterocedasticidade de White:\")\n",
        "print(\"LM Statistic:\", white_test_result[0])\n",
        "print(\"LM p-value:\", white_test_result[1])\n",
        "print(\"F Statistic:\", white_test_result[2])\n",
        "print(\"F p-value:\", white_test_result[3])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-8twO8YyD_l",
        "outputId": "37e5c9a2-e30b-4928-ba03-9a202eaf73b3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:          VM30Abril2011   R-squared:                       0.992\n",
            "Model:                            OLS   Adj. R-squared:                  0.992\n",
            "Method:                 Least Squares   F-statistic:                 1.789e+05\n",
            "Date:                Thu, 28 Sep 2023   Prob (F-statistic):               0.00\n",
            "Time:                        17:36:59   Log-Likelihood:                -15420.\n",
            "No. Observations:                2854   AIC:                         3.085e+04\n",
            "Df Residuals:                    2851   BIC:                         3.086e+04\n",
            "Df Model:                           2                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         -0.1962      1.007     -0.195      0.845      -2.170       1.778\n",
            "PL2010        -0.7047      0.273     -2.578      0.010      -1.241      -0.169\n",
            "LL2010        84.2685      0.174    485.512      0.000      83.928      84.609\n",
            "==============================================================================\n",
            "Omnibus:                     4258.986   Durbin-Watson:                   2.007\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):         45958855.904\n",
            "Skew:                          -7.724   Prob(JB):                         0.00\n",
            "Kurtosis:                     624.483   Cond. No.                         7.79\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "Median Absolute Error (MedAE): 4.437074014010317\n",
            "MedAE escalado pelo valor (ou preço) em percentagem: 35.00711519101121\n",
            "\n",
            "Fator de Inflação da Variância (VIF):\n",
            "  Variável       VIF\n",
            "0   PL2010  1.527847\n",
            "1   LL2010  1.527847\n",
            "\n",
            "Resultado do teste de heterocedasticidade de White:\n",
            "LM Statistic: 896.8920079260382\n",
            "LM p-value: 1.2524371417170991e-191\n",
            "F Statistic: 261.03295770270654\n",
            "F p-value: 3.524819177663552e-230\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MQP - MODELO SIMPLES"
      ],
      "metadata": {
        "id": "IXhYrWVgKtFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Certifique-se de que os tipos de dados sejam numéricos\n",
        "X = X.astype(float)\n",
        "y = y.astype(float)\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão linear robusta usando o método WLS com pesos robustos\n",
        "modelo_robusto = sm.RLM(y, X, M=sm.robust.norms.HuberT()).fit()\n",
        "\n",
        "# Visualize os resultados do modelo robusto\n",
        "print(modelo_robusto.summary())\n",
        "\n",
        "# Calcule o MedAE\n",
        "y_pred_robusto = modelo_robusto.predict(X)\n",
        "medae_robusto = np.median(np.abs(y - y_pred_robusto))\n",
        "\n",
        "# Calcule o valor médio da variável de resposta\n",
        "valor_medio_y = np.mean(y)\n",
        "\n",
        "# Calcule o MedAE escalado pelo valor (ou preço)\n",
        "medae_scaled_robusto = (medae_robusto / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "print(\"Median Absolute Error (MedAE) robusto:\", medae_robusto)\n",
        "print(\"MedAE robusto escalado pelo valor (ou preço) em percentagem:\", medae_scaled_robusto)\n",
        "\n",
        "# Calcular os VIFs (Fator de Inflação da Variância)\n",
        "def calculate_vif(dataframe):\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"Variável\"] = dataframe.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(dataframe.values, i) for i in range(dataframe.shape[1])]\n",
        "    return vif_data\n",
        "\n",
        "vif_result = calculate_vif(X)\n",
        "print(\"\\nFator de Inflação da Variância (VIF):\")\n",
        "print(vif_result)\n",
        "\n",
        "# Calcular o coeficiente de determinação (R-squared)\n",
        "sst_robusto = ((y - y.mean())**2).sum()\n",
        "ssr_robusto = ((y - y_pred_robusto)**2).sum()\n",
        "r_squared_robusto = 1 - (ssr_robusto / sst_robusto)\n",
        "\n",
        "print(\"Coeficiente de Determinação (R-squared) do modelo robusto:\", r_squared_robusto)\n",
        "\n",
        "# Realizar o teste de heterocedasticidade de White\n",
        "white_test_result_robusto = het_white(modelo_robusto.resid, X)\n",
        "print(\"\\nResultado do teste de heterocedasticidade de White para o modelo robusto:\")\n",
        "print(\"LM Statistic:\", white_test_result_robusto[0])\n",
        "print(\"LM p-value:\", white_test_result_robusto[1])\n",
        "print(\"F Statistic:\", white_test_result_robusto[2])\n",
        "print(\"F p-value:\", white_test_result_robusto[3])\n"
      ],
      "metadata": {
        "id": "I8ELT4MqgBwZ",
        "outputId": "d5896e31-aa1f-4cc1-b03a-e9284d70e139",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    Robust linear Model Regression Results                    \n",
            "==============================================================================\n",
            "Dep. Variable:          VM30Abril2011   No. Observations:                 2854\n",
            "Model:                            RLM   Df Residuals:                     2851\n",
            "Method:                          IRLS   Df Model:                            2\n",
            "Norm:                          HuberT                                         \n",
            "Scale Est.:                       mad                                         \n",
            "Cov Type:                          H1                                         \n",
            "Date:                Thu, 28 Sep 2023                                         \n",
            "Time:                        17:38:06                                         \n",
            "No. Iterations:                    27                                         \n",
            "==============================================================================\n",
            "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         -0.5114      0.123     -4.169      0.000      -0.752      -0.271\n",
            "PL2010        -3.9875      0.033   -119.710      0.000      -4.053      -3.922\n",
            "LL2010        86.1373      0.021   4073.100      0.000      86.096      86.179\n",
            "==============================================================================\n",
            "\n",
            "If the model instance has been used for another fit with different fit parameters, then the fit options might not be the correct ones anymore .\n",
            "Median Absolute Error (MedAE) robusto: 3.740560792944561\n",
            "MedAE robusto escalado pelo valor (ou preço) em percentagem: 29.511845451331254\n",
            "\n",
            "Fator de Inflação da Variância (VIF):\n",
            "  Variável       VIF\n",
            "0    const  1.000523\n",
            "1   PL2010  1.527389\n",
            "2   LL2010  1.527389\n",
            "Coeficiente de Determinação (R-squared) do modelo robusto: 0.9916365005632497\n",
            "\n",
            "Resultado do teste de heterocedasticidade de White para o modelo robusto:\n",
            "LM Statistic: 1230.0937910578878\n",
            "LM p-value: 8.89840256185152e-264\n",
            "F Statistic: 431.4666817137278\n",
            "F p-value: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REGRESSÃO QUANTÍLICA_SIMPLES"
      ],
      "metadata": {
        "id": "fUZVJwTv19EF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Certifique-se de que os tipos de dados sejam numéricos\n",
        "X = X.astype(float)\n",
        "y = y.astype(float)\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão quantílica\n",
        "modelo = sm.QuantReg(y, X).fit(q=0.5)  # q=0.5 representa a mediana, ajuste conforme necessário\n",
        "\n",
        "# Visualize os resultados do modelo\n",
        "print(modelo.summary())\n",
        "# Faça previsões com o modelo quantílico\n",
        "y_pred_quantreg = modelo.predict(X)\n",
        "\n",
        "# Calcule o MedAE para o modelo quantílico\n",
        "medae_quantreg = np.median(np.abs(y - y_pred_quantreg))\n",
        "\n",
        "# Calcule o valor médio da variável de resposta\n",
        "valor_medio_y = np.mean(y)\n",
        "\n",
        "# Calcule o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "medae_scaled_quantreg = (medae_quantreg / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "print(\"Median Absolute Error (MedAE) quantílico:\", medae_quantreg)\n",
        "print(\"MedAE quantílico escalado pelo valor (ou preço) em percentagem:\", medae_scaled_quantreg)\n"
      ],
      "metadata": {
        "id": "dgpuCY5p1_I5",
        "outputId": "38d71bc8-9c34-46f0-e276-b53cdfbcc53f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         QuantReg Regression Results                          \n",
            "==============================================================================\n",
            "Dep. Variable:          VM30Abril2011   Pseudo R-squared:               0.2213\n",
            "Model:                       QuantReg   Bandwidth:                       1.900\n",
            "Method:                 Least Squares   Sparsity:                        12.79\n",
            "Date:                Thu, 28 Sep 2023   No. Observations:                 2854\n",
            "Time:                        17:38:56   Df Residuals:                     2851\n",
            "                                        Df Model:                            2\n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         -0.6497      0.120     -5.426      0.000      -0.884      -0.415\n",
            "PL2010        -4.1613      0.033   -127.968      0.000      -4.225      -4.098\n",
            "LL2010        86.2173      0.021   4176.119      0.000      86.177      86.258\n",
            "==============================================================================\n",
            "Median Absolute Error (MedAE) quantílico: 3.662392462411339\n",
            "MedAE quantílico escalado pelo valor (ou preço) em percentagem: 28.895121965848464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RB_Simples"
      ],
      "metadata": {
        "id": "X-hPlPqnNEYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import median_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo Bayesian Ridge\n",
        "    modelo_bayesiano = BayesianRidge()\n",
        "\n",
        "    modelo_bayesiano.fit(X_train, y_train)\n",
        "    y_pred = modelo_bayesiano.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = median_absolute_error(y_test, y_pred)\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar os coeficientes do modelo (coeficientes Bayesianos)\n",
        "    coeficientes = modelo_bayesiano.coef_\n",
        "    print(\"Coeficientes do Modelo:\", coeficientes)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2033206-29f9-4342-d8f2-3faf30378a2d",
        "id": "zj4mQ3zrNLrh"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coeficientes do Modelo: [6.13358679e-02 8.40095873e+01]\n",
            "Coeficientes do Modelo: [-2.50294848 85.18945756]\n",
            "Coeficientes do Modelo: [-0.24788553  0.09086939]\n",
            "Coeficientes do Modelo: [-0.24905099 84.10917689]\n",
            "Coeficientes do Modelo: [-0.57409011 84.22924474]\n",
            "Coeficientes do Modelo: [-1.15313792 84.45679341]\n",
            "Coeficientes do Modelo: [-0.7222234  84.30183278]\n",
            "Coeficientes do Modelo: [-0.57310243 84.5028158 ]\n",
            "Coeficientes do Modelo: [-0.72534697 84.28154519]\n",
            "Coeficientes do Modelo: [-0.39241051 84.16494578]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 295.3799002355528\n",
            "Média do R²: -437.6524421245064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVR"
      ],
      "metadata": {
        "id": "NIw0ZhcK_9OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import median_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo SVR com kernel RBF\n",
        "    #modelo_svr = SVR(kernel='linear', C=1.0)\n",
        "    modelo_svr_poly = SVR(kernel='poly', degree=3, C=1.0)\n",
        "    #modelo_svr_sigmoid = SVR(kernel='sigmoid', C=1.0)\n",
        "    #modelo_svr = SVR(kernel='rbf', C=1.0)\n",
        "\n",
        "    modelo_svr.fit(X_train, y_train)\n",
        "    y_pred = modelo_svr.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = median_absolute_error(y_test, y_pred)\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPXr6W3_Hh_z",
        "outputId": "7fa8a551-9a06-4b83-ada8-bde317da58a5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 20.648807588157723\n",
            "Média do R²: 0.06437404503188407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CART_simples"
      ],
      "metadata": {
        "id": "ZYtjgE_9OP3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de árvore de decisão com os parâmetros desejados\n",
        "    modelo_arvore = DecisionTreeRegressor(min_samples_split=5, random_state=42)\n",
        "    #modelo_arvore = DecisionTreeRegressor(max_depth=5, min_samples_split=5, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "    # Criar o modelo Bagging com 500 árvores\n",
        "    bagging_model = BaggingRegressor(base_estimator=modelo_arvore, n_estimators=500, bootstrap=True, random_state=42)\n",
        "    #bagging_model = BaggingRegressor(base_estimator=modelo_arvore, n_estimators=100, bootstrap=True, random_state=42)\n",
        "\n",
        "\n",
        "    bagging_model.fit(X_train, y_train)\n",
        "    y_pred = bagging_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar a importância dos coeficientes (importância das variáveis)\n",
        "    importancia_coeficientes = np.mean([tree.feature_importances_ for tree in bagging_model.estimators_], axis=0)\n",
        "    print(\"Importância dos Coeficientes:\", importancia_coeficientes)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3efe67c-0c05-436c-bbfb-c0b0730808a9",
        "id": "c3TdDSmhOYKa"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.57346635 0.42653365]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.53530047 0.46469953]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.84641333 0.15358667]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.59032207 0.40967793]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.58367855 0.41632145]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.55982836 0.44017164]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.58714303 0.41285697]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.48065595 0.51934405]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.56039685 0.43960315]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.56042906 0.43957094]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 24.43742917034532\n",
            "Média do R²: -0.04062784000752866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FLORESTA ALEATÓRIA"
      ],
      "metadata": {
        "id": "OZLbiycNZm26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Certifique-se de que os tipos de dados sejam numéricos\n",
        "X = X.astype(float)\n",
        "y = y.astype(float)\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de Floresta Aleatória com os parâmetros desejados\n",
        "    random_forest_model = RandomForestRegressor(n_estimators=500, random_state=42)\n",
        "\n",
        "    random_forest_model.fit(X_train, y_train)\n",
        "    y_pred = random_forest_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar a importância das variáveis\n",
        "    importancia_variaveis = random_forest_model.feature_importances_\n",
        "    print(\"Importância das Variáveis:\", importancia_variaveis)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "id": "lpAmsgS7Zph4",
        "outputId": "148848a3-f039-4750-f680-803a572631b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância das Variáveis: [0.56185798 0.43814202]\n",
            "Importância das Variáveis: [0.53047154 0.46952846]\n",
            "Importância das Variáveis: [0.8192922 0.1807078]\n",
            "Importância das Variáveis: [0.57903599 0.42096401]\n",
            "Importância das Variáveis: [0.56767831 0.43232169]\n",
            "Importância das Variáveis: [0.56449312 0.43550688]\n",
            "Importância das Variáveis: [0.55091441 0.44908559]\n",
            "Importância das Variáveis: [0.46803497 0.53196503]\n",
            "Importância das Variáveis: [0.53972672 0.46027328]\n",
            "Importância das Variáveis: [0.54246289 0.45753711]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 24.292887422787878\n",
            "Média do R²: 0.12443309815947487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRADIENT BOOSTING"
      ],
      "metadata": {
        "id": "gReIxsDPa_9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de Regressão Gradient Boosting com os parâmetros desejados\n",
        "    gradient_boosting_model = GradientBoostingRegressor(n_estimators=500, random_state=42)\n",
        "\n",
        "    gradient_boosting_model.fit(X_train, y_train)\n",
        "    y_pred = gradient_boosting_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar a importância das variáveis\n",
        "    importancia_variaveis = gradient_boosting_model.feature_importances_\n",
        "    print(\"Importância das Variáveis:\", importancia_variaveis)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "id": "NvfZ3qUAbCf5",
        "outputId": "4f4878f1-4bfd-429c-ae80-88c1d44a71a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância das Variáveis: [0.53021235 0.46978765]\n",
            "Importância das Variáveis: [0.2999017 0.7000983]\n",
            "Importância das Variáveis: [0.87356684 0.12643316]\n",
            "Importância das Variáveis: [0.60737988 0.39262012]\n",
            "Importância das Variáveis: [0.66354726 0.33645274]\n",
            "Importância das Variáveis: [0.73688429 0.26311571]\n",
            "Importância das Variáveis: [0.41843811 0.58156189]\n",
            "Importância das Variáveis: [0.47366227 0.52633773]\n",
            "Importância das Variáveis: [0.54139305 0.45860695]\n",
            "Importância das Variáveis: [0.50287125 0.49712875]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 22.528519710431098\n",
            "Média do R²: 0.04060974637599167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REDES NEURAIS"
      ],
      "metadata": {
        "id": "Gy8Aqujjc2rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de regressão de rede neural com os parâmetros desejados\n",
        "    modelo_rede_neural = MLPRegressor(hidden_layer_sizes=(30), max_iter=1000, random_state=42)\n",
        "\n",
        "    modelo_rede_neural.fit(X_train, y_train)\n",
        "    y_pred = modelo_rede_neural.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "id": "yygOLB39c4OY",
        "outputId": "b117127c-b91d-4b55-edaa-71ff58c1dd75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 142.00650461855747\n",
            "Média do R²: -35.19998436870351\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}