{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOA8ZGzi8gXdWPTXN+TrceS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffersonramelo/Paper-pos-doc/blob/main/modelos_tradicionais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Caminho para o arquivo XLSX\n",
        "caminho_arquivo = '/content/Jefferson - Dados3 - Copia.xlsx'\n",
        "\n",
        "# Lê o arquivo XLSX\n",
        "dados = pd.read_excel(caminho_arquivo)\n",
        "\n",
        "# Agora, 'dados' contém os dados do arquivo XLSX\n"
      ],
      "metadata": {
        "id": "DOE1GbH_7pjb"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar o conteúdo do DataFrame \"dados\"\n",
        "print(dados)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5DK3CKBghzv",
        "outputId": "71a7e9d2-6a09-4f5d-f04d-efc10db74aa7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id     COD                           SETOR  d1  d2  d3  d4  d5  d6  d7  \\\n",
            "0      1   RRRP3  Petróleo gás e biocombustíveis   0   0   0   0   0   1   0   \n",
            "1      2   TTEN3             Consumo não cíclico   0   0   1   0   0   0   0   \n",
            "2      3  QVQP3B                          Outros   0   0   0   0   0   0   0   \n",
            "3      4   ABCB4                      Financeiro   0   0   0   0   0   0   0   \n",
            "4      5   EALT4                Bens industriais   1   0   0   0   0   0   0   \n",
            "..   ...     ...                             ...  ..  ..  ..  ..  ..  ..  ..   \n",
            "389  391   WIZC3                      Financeiro   0   0   0   0   0   0   0   \n",
            "390  392   WLMM4                Bens industriais   1   0   0   0   0   0   0   \n",
            "391  393   YBRA3                          Outros   0   0   0   0   0   0   0   \n",
            "392  394   YDUQ3                 Consumo cíclico   0   1   0   0   0   0   0   \n",
            "393  395   ZAMP3                 Consumo cíclico   0   1   0   0   0   0   0   \n",
            "\n",
            "     ...  ORA2013  ORA2014  ORA2015 ORA2016 ORA2017 ORA2018 ORA2019 ORA2020  \\\n",
            "0    ...        -        -        -       -       0       0       0       0   \n",
            "1    ...        -        -        -       -       -       -       -       0   \n",
            "2    ...        0        0        0       0       0       0       0       0   \n",
            "3    ...        -        -        -       -       -       -       -       -   \n",
            "4    ...        0        0        0       0       0       0       0       0   \n",
            "..   ...      ...      ...      ...     ...     ...     ...     ...     ...   \n",
            "389  ...        -        0        0       0       0       0       0       0   \n",
            "390  ...        0        0        0       0       0       0       0  102837   \n",
            "391  ...        0        0        0       0       0       0       0       0   \n",
            "392  ...        0        0        0       0       0       0       0       0   \n",
            "393  ...        -        0        0       0       0      -2      17     300   \n",
            "\n",
            "    ORA2021 ORA2022  \n",
            "0         0       0  \n",
            "1         0       0  \n",
            "2         0       0  \n",
            "3         -       -  \n",
            "4         0       0  \n",
            "..      ...     ...  \n",
            "389       0       0  \n",
            "390   99077   98279  \n",
            "391       0       0  \n",
            "392       0       0  \n",
            "393     147       0  \n",
            "\n",
            "[394 rows x 151 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "excluir setor financeiro e empresas com PL negativo"
      ],
      "metadata": {
        "id": "kEKhC6-Wf6ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agora, vamos remover as linhas onde 'd9' seja igual a 1\n",
        "dados = dados[dados['d11'] != 1]\n",
        "\n",
        "# A partir deste ponto, 'dados' conterá apenas as linhas onde 'd9' não é igual a 1\n",
        "print(dados)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cQ_iqhOf9H_",
        "outputId": "36a22bea-5627-4318-9377-55b8b86ab964"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id     COD                           SETOR  d1  d2  d3  d4  d5  d6  d7  \\\n",
            "0      1   RRRP3  Petróleo gás e biocombustíveis   0   0   0   0   0   1   0   \n",
            "1      2   TTEN3             Consumo não cíclico   0   0   1   0   0   0   0   \n",
            "2      3  QVQP3B                          Outros   0   0   0   0   0   0   0   \n",
            "4      5   EALT4                Bens industriais   1   0   0   0   0   0   0   \n",
            "5      6   AERI3                Bens industriais   1   0   0   0   0   0   0   \n",
            "..   ...     ...                             ...  ..  ..  ..  ..  ..  ..  ..   \n",
            "388  390   PORT3                Bens industriais   1   0   0   0   0   0   0   \n",
            "390  392   WLMM4                Bens industriais   1   0   0   0   0   0   0   \n",
            "391  393   YBRA3                          Outros   0   0   0   0   0   0   0   \n",
            "392  394   YDUQ3                 Consumo cíclico   0   1   0   0   0   0   0   \n",
            "393  395   ZAMP3                 Consumo cíclico   0   1   0   0   0   0   0   \n",
            "\n",
            "     ...  ORA2013  ORA2014  ORA2015  ORA2016 ORA2017 ORA2018 ORA2019 ORA2020  \\\n",
            "0    ...        -        -        -        -       0       0       0       0   \n",
            "1    ...        -        -        -        -       -       -       -       0   \n",
            "2    ...        0        0        0        0       0       0       0       0   \n",
            "4    ...        0        0        0        0       0       0       0       0   \n",
            "5    ...        -        -        -        -       0       0       0       0   \n",
            "..   ...      ...      ...      ...      ...     ...     ...     ...     ...   \n",
            "388  ...        0        0        0        0       0       0       0       0   \n",
            "390  ...        0        0        0        0       0       0       0  102837   \n",
            "391  ...        0        0        0        0       0       0       0       0   \n",
            "392  ...        0        0        0        0       0       0       0       0   \n",
            "393  ...        -        0        0        0       0      -2      17     300   \n",
            "\n",
            "    ORA2021 ORA2022  \n",
            "0         0       0  \n",
            "1         0       0  \n",
            "2         0       0  \n",
            "4         0       0  \n",
            "5         0       0  \n",
            "..      ...     ...  \n",
            "388       0  723446  \n",
            "390   99077   98279  \n",
            "391       0       0  \n",
            "392       0       0  \n",
            "393     147       0  \n",
            "\n",
            "[336 rows x 152 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converte a coluna 'PL2010' para números (float) e remove as linhas onde 'PL2010' seja negativo\n",
        "dados['PL2010'] = pd.to_numeric(dados['PL2010'], errors='coerce')  # 'coerce' trata strings não numéricas como NaN\n",
        "dados = dados[dados['PL2010'] >= 0]\n",
        "\n",
        "\n",
        "print(dados)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3PUXYCZ78ba",
        "outputId": "f7f33315-6a01-4d32-c735-70422b523ef1"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id     COD                SETOR  d1  d2  d3  d4  d5  d6  d7  ...  \\\n",
            "2      3  QVQP3B               Outros   0   0   0   0   0   0   0  ...   \n",
            "4      5   EALT4     Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "6      7   AESB3    Utilidade pública   0   0   0   1   0   0   0  ...   \n",
            "8      9   AFLT3    Utilidade pública   0   0   0   1   0   0   0  ...   \n",
            "16    17   APTI4  Consumo não cíclico   0   0   1   0   0   0   0  ...   \n",
            "..   ...     ...                  ...  ..  ..  ..  ..  ..  ..  ..  ...   \n",
            "387  389   WHRL4      Consumo cíclico   0   1   0   0   0   0   0  ...   \n",
            "388  390   PORT3     Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "390  392   WLMM4     Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "391  393   YBRA3               Outros   0   0   0   0   0   0   0  ...   \n",
            "392  394   YDUQ3      Consumo cíclico   0   1   0   0   0   0   0  ...   \n",
            "\n",
            "     ORA2013  ORA2014  ORA2015  ORA2016 ORA2017 ORA2018 ORA2019 ORA2020  \\\n",
            "2          0        0        0        0       0       0       0       0   \n",
            "4          0        0        0        0       0       0       0       0   \n",
            "6     489138   388514   923107    -3289    1394  -14697  -59906  532895   \n",
            "8          0        0        0        0       0       0       0       0   \n",
            "16         0        0        0        0       0       0       0       0   \n",
            "..       ...      ...      ...      ...     ...     ...     ...     ...   \n",
            "387        0        0        0        0       0       0       0       0   \n",
            "388        0        0        0        0       0       0       0       0   \n",
            "390        0        0        0        0       0       0       0  102837   \n",
            "391        0        0        0        0       0       0       0       0   \n",
            "392        0        0        0        0       0       0       0       0   \n",
            "\n",
            "     ORA2021  ORA2022  \n",
            "2          0        0  \n",
            "4          0        0  \n",
            "6    -153563  -155638  \n",
            "8          0        0  \n",
            "16         0        0  \n",
            "..       ...      ...  \n",
            "387        0        0  \n",
            "388        0   723446  \n",
            "390    99077    98279  \n",
            "391        0        0  \n",
            "392        0        0  \n",
            "\n",
            "[209 rows x 152 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "excluir valores ausentes na variável dependente"
      ],
      "metadata": {
        "id": "HPTV8NDAhkT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agora, vamos remover as linhas onde 'VM30Abril11' seja igual a '-'\n",
        "dados = dados[dados['VM30Abril2011'] != '-']\n",
        "\n",
        "# A partir deste ponto, 'dados' conterá apenas as linhas onde 'VM30Abril11' não é igual a '-'\n",
        "print(dados)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPddSXYKho22",
        "outputId": "22ad90f5-ce2c-40b9-9db5-eea9bb9eb72d"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id    COD                SETOR  d1  d2  d3  d4  d5  d6  d7  ...  \\\n",
            "4      5  EALT4     Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "8      9  AFLT3    Utilidade pública   0   0   0   1   0   0   0  ...   \n",
            "20    21  ALPA4      Consumo cíclico   0   1   0   0   0   0   0  ...   \n",
            "25    26  ABEV3  Consumo não cíclico   0   0   1   0   0   0   0  ...   \n",
            "27    28  AMER3      Consumo cíclico   0   1   0   0   0   0   0  ...   \n",
            "..   ...    ...                  ...  ..  ..  ..  ..  ..  ..  ..  ...   \n",
            "386  388  MWET4     Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "387  389  WHRL4      Consumo cíclico   0   1   0   0   0   0   0  ...   \n",
            "388  390  PORT3     Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "390  392  WLMM4     Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "392  394  YDUQ3      Consumo cíclico   0   1   0   0   0   0   0  ...   \n",
            "\n",
            "     ORA2013  ORA2014  ORA2015  ORA2016 ORA2017 ORA2018 ORA2019 ORA2020  \\\n",
            "4          0        0        0        0       0       0       0       0   \n",
            "8          0        0        0        0       0       0       0       0   \n",
            "20     -1760     2802     2287     -428       0   56226   36684     235   \n",
            "25         0        0        0        0       0       0       0       0   \n",
            "27         0        0        0        0       0       0       0  -97688   \n",
            "..       ...      ...      ...      ...     ...     ...     ...     ...   \n",
            "386        0        0        0        0       0       0       0       0   \n",
            "387        0        0        0        0       0       0       0       0   \n",
            "388        0        0        0        0       0       0       0       0   \n",
            "390        0        0        0        0       0       0       0  102837   \n",
            "392        0        0        0        0       0       0       0       0   \n",
            "\n",
            "     ORA2021 ORA2022  \n",
            "4          0       0  \n",
            "8          0       0  \n",
            "20      2915    5362  \n",
            "25         0       0  \n",
            "27   -219440       -  \n",
            "..       ...     ...  \n",
            "386        0       0  \n",
            "387        0       0  \n",
            "388        0  723446  \n",
            "390    99077   98279  \n",
            "392        0       0  \n",
            "\n",
            "[175 rows x 152 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tratar valores ausentes substituindo pela média da coluna"
      ],
      "metadata": {
        "id": "tSBa2W135L_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que seu DataFrame se chame \"dados\"\n",
        "\n",
        "# Substituir apenas traços (\"-\") e valores em branco por NaN\n",
        "dados = dados.replace(['-',''], np.nan)\n",
        "\n",
        "# Calcular a média de todas as colunas, ignorando os valores NaN\n",
        "media_por_coluna = dados.mean(numeric_only=True)\n",
        "\n",
        "# Preencher os valores ausentes em todas as colunas com a média de cada coluna\n",
        "dados.fillna(media_por_coluna, inplace=True)\n"
      ],
      "metadata": {
        "id": "jlrJKMff7WNL"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tratar outliers: A winsorização ao nível de 1% envolve substituir os 1% dos valores mais extremos por valores no limite do intervalo aceitável, ou seja, os 1% menores e os 1% maiores dos valores."
      ],
      "metadata": {
        "id": "95LYGQCnbVVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import mstats\n",
        "\n",
        "# Supondo que seu DataFrame se chame \"dados\"\n",
        "\n",
        "# Lista de variáveis para winsorizar\n",
        "variaveis_winsorizar = ['VM30Abril2011', 'PL2010', 'LL2010', 'INTANG2010',\n",
        "                        'CAXEEQUIV2010', 'CREC2010', 'REC2010', 'CAXOP2010', 'ORA2010']\n",
        "\n",
        "# Aplicar winsorização de 1% nas variáveis\n",
        "for coluna in variaveis_winsorizar:\n",
        "    dados[coluna] = mstats.winsorize(dados[coluna], limits=[0.01, 0.01])\n",
        "\n",
        "# Agora, as variáveis especificadas foram winsorizadas\n"
      ],
      "metadata": {
        "id": "bcS1mdNlbcTb"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MQO_SIMPLES"
      ],
      "metadata": {
        "id": "9rBG78W6yny2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from statsmodels.stats.diagnostic import het_white\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão linear\n",
        "modelo = sm.OLS(y, X).fit()\n",
        "\n",
        "# Visualize os resultados do modelo\n",
        "print(modelo.summary())\n",
        "\n",
        "# Calcule o MedAE\n",
        "y_pred = modelo.predict(X)\n",
        "medae = np.median(np.abs(y - y_pred))\n",
        "\n",
        "# Calcule o valor médio da variável de resposta\n",
        "valor_medio_y = np.mean(y)\n",
        "\n",
        "# Calcule o MedAE escalado pelo valor (ou preço)\n",
        "medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "print(\"Median Absolute Error (MedAE):\", medae)\n",
        "print(\"MedAE escalado pelo valor (ou preço) em percentagem:\", medae_scaled)\n",
        "\n",
        "# Calcular os VIFs (Fator de Inflação da Variância)\n",
        "def calculate_vif(dataframe):\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"Variável\"] = dataframe.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(dataframe.values, i) for i in range(dataframe.shape[1])]\n",
        "    return vif_data\n",
        "\n",
        "vif_result = calculate_vif(X.drop(columns=['const']))\n",
        "print(\"\\nFator de Inflação da Variância (VIF):\")\n",
        "print(vif_result)\n",
        "\n",
        "# Realizar o teste de heterocedasticidade de White\n",
        "white_test_result = het_white(modelo.resid, X)\n",
        "print(\"\\nResultado do teste de heterocedasticidade de White:\")\n",
        "print(\"LM Statistic:\", white_test_result[0])\n",
        "print(\"LM p-value:\", white_test_result[1])\n",
        "print(\"F Statistic:\", white_test_result[2])\n",
        "print(\"F p-value:\", white_test_result[3])\n"
      ],
      "metadata": {
        "id": "Rr4jfb92uIAe",
        "outputId": "ad3f9b0a-25f9-4aa3-b452-db5c1af4791a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:          VM30Abril2011   R-squared:                       0.948\n",
            "Model:                            OLS   Adj. R-squared:                  0.947\n",
            "Method:                 Least Squares   F-statistic:                     1552.\n",
            "Date:                Tue, 26 Sep 2023   Prob (F-statistic):          8.47e-111\n",
            "Time:                        18:17:57   Log-Likelihood:                -3001.6\n",
            "No. Observations:                 175   AIC:                             6009.\n",
            "Df Residuals:                     172   BIC:                             6019.\n",
            "Df Model:                           2                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const       1.899e+06   5.49e+05      3.456      0.001    8.14e+05    2.98e+06\n",
            "PL2010         0.2296      0.101      2.276      0.024       0.030       0.429\n",
            "LL2010         8.0245      0.411     19.509      0.000       7.213       8.836\n",
            "==============================================================================\n",
            "Omnibus:                      289.892   Durbin-Watson:                   2.072\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            46346.047\n",
            "Skew:                           7.694   Prob(JB):                         0.00\n",
            "Kurtosis:                      81.225   Cond. No.                     1.50e+07\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 1.5e+07. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n",
            "Median Absolute Error (MedAE): 1847236.258835081\n",
            "MedAE escalado pelo valor (ou preço) em percentagem: 22.191608205853576\n",
            "\n",
            "Fator de Inflação da Variância (VIF):\n",
            "  Variável       VIF\n",
            "0   PL2010  6.749509\n",
            "1   LL2010  6.749509\n",
            "\n",
            "Resultado do teste de heterocedasticidade de White:\n",
            "LM Statistic: 137.41521353622508\n",
            "LM p-value: 1.0091266798314561e-28\n",
            "F Statistic: 155.38591873918014\n",
            "F p-value: 1.1185812091961663e-55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MQO_COMPLEXO"
      ],
      "metadata": {
        "id": "7XF8A1GcyffN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from statsmodels.stats.diagnostic import het_white\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados[['PL2010', 'LL2010', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'd9', 'd1', 'INTANG2010',\n",
        "           'CAXEEQUIV2010', 'CREC2010', 'REC2010', 'CAXOP2010', 'ORA2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão linear\n",
        "modelo = sm.OLS(y, X).fit()\n",
        "\n",
        "# Visualize os resultados do modelo\n",
        "print(modelo.summary())\n",
        "\n",
        "# Calcule o MedAE\n",
        "y_pred = modelo.predict(X)\n",
        "medae = np.median(np.abs(y - y_pred))\n",
        "\n",
        "# Calcule o valor médio da variável de resposta\n",
        "valor_medio_y = np.mean(y)\n",
        "\n",
        "# Calcule o MedAE escalado pelo valor (ou preço)\n",
        "medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "print(\"Median Absolute Error (MedAE):\", medae)\n",
        "print(\"MedAE escalado pelo valor (ou preço) em percentagem:\", medae_scaled)\n",
        "\n",
        "# Calcular os VIFs (Fator de Inflação da Variância)\n",
        "def calculate_vif(dataframe):\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"Variável\"] = dataframe.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(dataframe.values, i) for i in range(dataframe.shape[1])]\n",
        "    return vif_data\n",
        "\n",
        "vif_result = calculate_vif(X.drop(columns=['const']))\n",
        "print(\"\\nFator de Inflação da Variância (VIF):\")\n",
        "print(vif_result)\n",
        "\n",
        "# Realizar o teste de heterocedasticidade de White\n",
        "white_test_result = het_white(modelo.resid, X)\n",
        "print(\"\\nResultado do teste de heterocedasticidade de White:\")\n",
        "print(\"LM Statistic:\", white_test_result[0])\n",
        "print(\"LM p-value:\", white_test_result[1])\n",
        "print(\"F Statistic:\", white_test_result[2])\n",
        "print(\"F p-value:\", white_test_result[3])\n"
      ],
      "metadata": {
        "id": "5zAUDDOGueoL",
        "outputId": "022af0f0-a5c7-4b38-c517-8ef9e8f4f7b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:          VM30Abril2011   R-squared:                       0.967\n",
            "Model:                            OLS   Adj. R-squared:                  0.964\n",
            "Method:                 Least Squares   F-statistic:                     290.6\n",
            "Date:                Tue, 26 Sep 2023   Prob (F-statistic):          2.83e-108\n",
            "Time:                        18:19:41   Log-Likelihood:                -2960.6\n",
            "No. Observations:                 175   AIC:                             5955.\n",
            "Df Residuals:                     158   BIC:                             6009.\n",
            "Df Model:                          16                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "=================================================================================\n",
            "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
            "---------------------------------------------------------------------------------\n",
            "const          9.012e+05   7.73e+05      1.166      0.245   -6.25e+05    2.43e+06\n",
            "PL2010           -0.4162      0.142     -2.925      0.004      -0.697      -0.135\n",
            "LL2010            3.5537      0.897      3.960      0.000       1.781       5.326\n",
            "d2            -2.974e+05   1.03e+06     -0.290      0.772   -2.32e+06    1.73e+06\n",
            "d3             7.336e+06   1.53e+06      4.792      0.000    4.31e+06    1.04e+07\n",
            "d4             -6.62e+05   1.14e+06     -0.580      0.563   -2.92e+06    1.59e+06\n",
            "d5             -2.69e+06   1.28e+06     -2.098      0.037   -5.22e+06   -1.58e+05\n",
            "d6             2.351e+06   2.12e+06      1.107      0.270   -1.85e+06    6.55e+06\n",
            "d7             1.818e+06   1.92e+06      0.947      0.345   -1.97e+06    5.61e+06\n",
            "d8             2.599e+05      3e+06      0.087      0.931   -5.67e+06    6.19e+06\n",
            "d9            -7.413e+06   3.33e+06     -2.228      0.027    -1.4e+07    -8.4e+05\n",
            "d1             1.985e+05   1.08e+06      0.183      0.855   -1.94e+06    2.34e+06\n",
            "INTANG2010       -0.4670      0.227     -2.054      0.042      -0.916      -0.018\n",
            "CAXEEQUIV2010     1.0438      0.511      2.044      0.043       0.035       2.052\n",
            "CREC2010      -2.546e+05   1.57e+06     -0.162      0.871   -3.36e+06    2.85e+06\n",
            "REC2010           0.0850      0.088      0.965      0.336      -0.089       0.259\n",
            "CAXOP2010         5.0650      0.931      5.440      0.000       3.226       6.904\n",
            "ORA2010         -15.4957      6.649     -2.330      0.021     -28.629      -2.363\n",
            "==============================================================================\n",
            "Omnibus:                      177.315   Durbin-Watson:                   2.059\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7637.501\n",
            "Skew:                           3.509   Prob(JB):                         0.00\n",
            "Kurtosis:                      34.594   Cond. No.                     9.60e+17\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is 6.76e-20. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n",
            "Median Absolute Error (MedAE): 1285924.589193818\n",
            "MedAE escalado pelo valor (ou preço) em percentagem: 15.448340475764851\n",
            "\n",
            "Fator de Inflação da Variância (VIF):\n",
            "         Variável        VIF\n",
            "0          PL2010  19.385067\n",
            "1          LL2010  46.364947\n",
            "2              d2   1.555731\n",
            "3              d3   1.363861\n",
            "4              d4   1.444060\n",
            "5              d5   1.320845\n",
            "6              d6   1.179904\n",
            "7              d7   1.059113\n",
            "8              d8   1.007168\n",
            "9              d9   1.267836\n",
            "10             d1   1.221495\n",
            "11     INTANG2010   1.708229\n",
            "12  CAXEEQUIV2010   5.530741\n",
            "13       CREC2010   1.127928\n",
            "14        REC2010   5.519270\n",
            "15      CAXOP2010  80.861848\n",
            "16        ORA2010   1.258409\n",
            "\n",
            "Resultado do teste de heterocedasticidade de White:\n",
            "LM Statistic: 174.5324370421358\n",
            "LM p-value: 8.035866145090785e-08\n",
            "F Statistic: 373.2811466489651\n",
            "F p-value: 6.87279073789292e-88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MQO ESCALADO SIMPLES"
      ],
      "metadata": {
        "id": "fSCSv5TM1vCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from statsmodels.stats.diagnostic import het_white\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes escalonadas\n",
        "X_scaled = dados[['PL2010', 'LL2010']].divide(dados['AT2009'], axis=0)\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X_scaled = sm.add_constant(X_scaled)\n",
        "\n",
        "# Escalone a variável dependente y pelo valor AT2009 (ou outro valor apropriado)\n",
        "y_scaled = dados['VM30Abril2011'] / dados['AT2009']\n",
        "\n",
        "# Crie o modelo de regressão linear\n",
        "modelo = sm.OLS(y_scaled, X_scaled).fit()\n",
        "\n",
        "# Visualize os resultados do modelo\n",
        "print(modelo.summary())\n",
        "\n",
        "# Calcule o MedAE\n",
        "y_pred_scaled = modelo.predict(X_scaled)\n",
        "medae_scaled = np.median(np.abs(y_scaled - y_pred_scaled)) * 100  # Em percentagem\n",
        "\n",
        "print(\"Median Absolute Error (MedAE) escalado pelo valor (ou preço) em percentagem:\", medae_scaled)\n",
        "\n",
        "# Agora, calcule o MedAE, valor médio da variável de resposta e o MedAE escalado pelo valor\n",
        "y_pred = modelo.predict(X_scaled) * dados['AT2009']  # Reverta o escalonamento de y\n",
        "medae = np.median(np.abs(dados['VM30Abril2011'] - y_pred))  # MedAE não escalado\n",
        "valor_medio_y = np.mean(dados['VM30Abril2011'])\n",
        "\n",
        "print(\"Median Absolute Error (MedAE):\", medae)\n",
        "print(\"Valor Médio da Variável de Resposta:\", valor_medio_y)\n",
        "\n",
        "# Calcular os VIFs (Fator de Inflação da Variância)\n",
        "def calculate_vif(dataframe):\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"Variável\"] = dataframe.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(dataframe.values, i) for i in range(dataframe.shape[1])]\n",
        "    return vif_data\n",
        "\n",
        "vif_result = calculate_vif(X_scaled.drop(columns=['const']))\n",
        "print(\"\\nFator de Inflação da Variância (VIF):\")\n",
        "print(vif_result)\n",
        "\n",
        "# Realizar o teste de heterocedasticidade de White\n",
        "white_test_result = het_white(modelo.resid, X_scaled)\n",
        "print(\"\\nResultado do teste de heterocedasticidade de White:\")\n",
        "print(\"LM Statistic:\", white_test_result[0])\n",
        "print(\"LM p-value:\", white_test_result[1])\n",
        "print(\"F Statistic:\", white_test_result[2])\n",
        "print(\"F p-value:\", white_test_result[3])\n",
        "\n",
        "# Calcule o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "medae_scaled = (medae / valor_medio_y) * 100\n",
        "print(\"MedAE escalado pelo valor (ou preço) em percentagem:\", medae_scaled)\n"
      ],
      "metadata": {
        "id": "GaS98Q-Tu3Vu",
        "outputId": "cddba2e1-c4ff-46d0-a105-e9b0437a7a66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.579\n",
            "Model:                            OLS   Adj. R-squared:                  0.574\n",
            "Method:                 Least Squares   F-statistic:                     118.3\n",
            "Date:                Tue, 26 Sep 2023   Prob (F-statistic):           4.84e-33\n",
            "Time:                        18:21:26   Log-Likelihood:                -295.54\n",
            "No. Observations:                 175   AIC:                             597.1\n",
            "Df Residuals:                     172   BIC:                             606.6\n",
            "Df Model:                           2                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const         -0.3450      0.169     -2.043      0.043      -0.678      -0.012\n",
            "PL2010         2.7594      0.180     15.359      0.000       2.405       3.114\n",
            "LL2010         1.2377      1.006      1.231      0.220      -0.748       3.223\n",
            "==============================================================================\n",
            "Omnibus:                       99.478   Durbin-Watson:                   1.907\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              604.776\n",
            "Skew:                           2.086   Prob(JB):                    4.73e-132\n",
            "Kurtosis:                      11.096   Cond. No.                         12.2\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "Median Absolute Error (MedAE) escalado pelo valor (ou preço) em percentagem: 54.18321802844454\n",
            "Median Absolute Error (MedAE): 914380.8981708887\n",
            "Valor Médio da Variável de Resposta: 8324030.6051718565\n",
            "\n",
            "Fator de Inflação da Variância (VIF):\n",
            "  Variável       VIF\n",
            "0   PL2010  1.132872\n",
            "1   LL2010  1.132872\n",
            "\n",
            "Resultado do teste de heterocedasticidade de White:\n",
            "LM Statistic: 25.084597007974935\n",
            "LM p-value: 0.0001341896385949223\n",
            "F Statistic: 5.6555854965393735\n",
            "F p-value: 7.546363062758209e-05\n",
            "MedAE escalado pelo valor (ou preço) em percentagem: 10.984833448386997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MQO ESCALADO COMPLEXO"
      ],
      "metadata": {
        "id": "p1BCSv3-1MyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from statsmodels.stats.diagnostic import het_white\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Variáveis independentes a serem escalonadas\n",
        "variaveis_escalonadas = ['PL2010', 'LL2010', 'INTANG2010', 'CAXEEQUIV2010', 'REC2010', 'CAXOP2010', 'ORA2010']\n",
        "\n",
        "# Variáveis independentes que não serão escalonadas\n",
        "variaveis_nao_escalonadas = ['d2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'd9', 'd1', 'CREC2010']\n",
        "\n",
        "# Combine as variáveis independentes escalonadas e não escalonadas\n",
        "X = pd.concat([dados[variaveis_escalonadas].divide(dados['AT2009'], axis=0), dados[variaveis_nao_escalonadas]], axis=1)\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Variável dependente escalonada\n",
        "y_scaled = dados['VM30Abril2011'] / dados['AT2009']\n",
        "\n",
        "# Crie o modelo de regressão linear\n",
        "modelo = sm.OLS(y_scaled, X).fit()\n",
        "\n",
        "# Visualize os resultados do modelo\n",
        "print(modelo.summary())\n",
        "\n",
        "# Calcule o MedAE escalonado\n",
        "y_pred_scaled = modelo.predict(X)\n",
        "medae_scaled = np.median(np.abs(y_scaled - y_pred_scaled)) * 100  # Em percentagem\n",
        "\n",
        "print(\"Median Absolute Error (MedAE) escalado pelo valor (ou preço) em percentagem:\", medae_scaled)\n",
        "\n",
        "# Reverta o escalonamento da variável dependente\n",
        "y_pred = modelo.predict(X) * dados['AT2009']\n",
        "\n",
        "# Calcule o MedAE não escalonado\n",
        "medae = np.median(np.abs(dados['VM30Abril2011'] - y_pred))\n",
        "\n",
        "# Calcule o valor médio da variável de resposta\n",
        "valor_medio_y = np.mean(dados['VM30Abril2011'])\n",
        "\n",
        "# Calcule o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "medae_scaled = (medae / valor_medio_y) * 100\n",
        "\n",
        "print(\"Median Absolute Error (MedAE) não escalado:\", medae)\n",
        "print(\"Valor Médio da Variável de Resposta:\", valor_medio_y)\n",
        "print(\"MedAE escalado pelo valor (ou preço) em percentagem:\", medae_scaled)\n",
        "\n",
        "# Calcular os VIFs (Fator de Inflação da Variância)\n",
        "def calculate_vif(dataframe):\n",
        "    vif_data = pd.DataFrame()\n",
        "    vif_data[\"Variável\"] = dataframe.columns\n",
        "    vif_data[\"VIF\"] = [variance_inflation_factor(dataframe.values, i) for i in range(dataframe.shape[1])]\n",
        "    return vif_data\n",
        "\n",
        "vif_result = calculate_vif(X.drop(columns=['const']))\n",
        "print(\"\\nFator de Inflação da Variância (VIF):\")\n",
        "print(vif_result)\n",
        "\n",
        "# Realizar o teste de heterocedasticidade de White\n",
        "white_test_result = het_white(modelo.resid, X)\n",
        "print(\"\\nResultado do teste de heterocedasticidade de White:\")\n",
        "print(\"LM Statistic:\", white_test_result[0])\n",
        "print(\"LM p-value:\", white_test_result[1])\n",
        "print(\"F Statistic:\", white_test_result[2])\n",
        "print(\"F p-value:\", white_test_result[3])\n"
      ],
      "metadata": {
        "id": "NDQUji5-vngl",
        "outputId": "0b3c683d-bb8c-466c-c1f4-0528a4b07592",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.681\n",
            "Model:                            OLS   Adj. R-squared:                  0.648\n",
            "Method:                 Least Squares   F-statistic:                     21.06\n",
            "Date:                Tue, 26 Sep 2023   Prob (F-statistic):           2.52e-31\n",
            "Time:                        18:24:38   Log-Likelihood:                -271.33\n",
            "No. Observations:                 175   AIC:                             576.7\n",
            "Df Residuals:                     158   BIC:                             630.5\n",
            "Df Model:                          16                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "=================================================================================\n",
            "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
            "---------------------------------------------------------------------------------\n",
            "const            -0.6606      0.254     -2.599      0.010      -1.163      -0.159\n",
            "PL2010            2.9732      0.184     16.160      0.000       2.610       3.337\n",
            "LL2010           -0.0857      1.048     -0.082      0.935      -2.156       1.985\n",
            "INTANG2010        0.0921      0.115      0.798      0.426      -0.136       0.320\n",
            "CAXEEQUIV2010    -0.6454      0.263     -2.451      0.015      -1.165      -0.125\n",
            "REC2010           0.2467      0.156      1.584      0.115      -0.061       0.554\n",
            "CAXOP2010         3.2640      0.803      4.063      0.000       1.677       4.851\n",
            "ORA2010          -6.0383      2.166     -2.788      0.006     -10.316      -1.760\n",
            "d2               -0.2116      0.217     -0.975      0.331      -0.640       0.217\n",
            "d3                0.2280      0.316      0.721      0.472      -0.397       0.853\n",
            "d4               -0.3220      0.239     -1.348      0.180      -0.794       0.150\n",
            "d5               -0.8000      0.265     -3.018      0.003      -1.324      -0.276\n",
            "d6                0.5129      0.477      1.076      0.284      -0.429       1.455\n",
            "d7                0.2066      0.421      0.491      0.624      -0.624       1.037\n",
            "d8                0.5026      0.647      0.777      0.438      -0.774       1.780\n",
            "d9               -0.6411      0.648     -0.990      0.324      -1.920       0.638\n",
            "d1               -0.1362      0.226     -0.602      0.548      -0.583       0.310\n",
            "CREC2010         -0.2538      0.331     -0.767      0.444      -0.907       0.399\n",
            "==============================================================================\n",
            "Omnibus:                       82.211   Durbin-Watson:                   1.803\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              386.317\n",
            "Skew:                           1.746   Prob(JB):                     1.30e-84\n",
            "Kurtosis:                       9.386   Cond. No.                     2.34e+16\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is 9.27e-31. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n",
            "Median Absolute Error (MedAE) escalado pelo valor (ou preço) em percentagem: 58.96383546976403\n",
            "Median Absolute Error (MedAE) não escalado: 831890.9488882995\n",
            "Valor Médio da Variável de Resposta: 8324030.6051718565\n",
            "MedAE escalado pelo valor (ou preço) em percentagem: 9.993847792575774\n",
            "\n",
            "Fator de Inflação da Variância (VIF):\n",
            "         Variável       VIF\n",
            "0          PL2010  1.293541\n",
            "1          LL2010  1.339575\n",
            "2      INTANG2010  1.301024\n",
            "3   CAXEEQUIV2010  1.318270\n",
            "4         REC2010  1.313857\n",
            "5       CAXOP2010  1.318892\n",
            "6         ORA2010  1.149111\n",
            "7              d2  3.507946\n",
            "8              d3  1.671274\n",
            "9              d4  1.772859\n",
            "10             d5  1.693408\n",
            "11             d6  1.596119\n",
            "12             d7  1.616440\n",
            "13             d8  1.185482\n",
            "14             d9  1.119288\n",
            "15             d1  2.427756\n",
            "16       CREC2010  1.113506\n",
            "\n",
            "Resultado do teste de heterocedasticidade de White:\n",
            "LM Statistic: 143.0580698819402\n",
            "LM p-value: 0.003773603987043326\n",
            "F Statistic: 3.237074483670973\n",
            "F p-value: 1.78986623229763e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Minimos Quadrados Ponderados (MQP), com pesos com base na variância dos erros_ MODELO COMPLEXO"
      ],
      "metadata": {
        "id": "Vmo8zEDpLVRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'd9','INTANG2010',\n",
        "           'CAXEEQUIV2010', 'CREC2010', 'REC2010', 'CAXOP2010', 'ORA2010']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão linear\n",
        "modelo = sm.OLS(y, X).fit()\n",
        "\n",
        "# Calcule os resíduos (erros)\n",
        "residuos = modelo.resid\n",
        "\n",
        "# Calcule a variância dos resíduos\n",
        "variancia_residuos = np.var(residuos)\n",
        "\n",
        "# Calcule os pesos com base na variância dos resíduos (inverso da variância)\n",
        "pesos = 1 / variancia_residuos\n",
        "\n",
        "# Crie o modelo de regressão linear ponderada (WLS) com os pesos calculados\n",
        "modelo_wls = sm.WLS(y, X, weights=pesos).fit()\n",
        "\n",
        "# Visualize os resultados do modelo ponderado\n",
        "print(modelo_wls.summary())\n",
        "\n",
        "# Calcule os resíduos ponderados (erros ponderados)\n",
        "y_pred_wls = modelo_wls.predict(X)\n",
        "residuos_wls = y - y_pred_wls\n",
        "\n",
        "# Calcule o MedAE ponderado\n",
        "medae_wls = np.median(np.abs(residuos_wls))\n",
        "\n",
        "# Calcule o valor médio da variável de resposta\n",
        "valor_medio_y = np.mean(y)\n",
        "\n",
        "# Calcule o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "medae_scaled_wls = (medae_wls / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "print(\"Median Absolute Error (MedAE) ponderado:\", medae_wls)\n",
        "print(\"MedAE ponderado escalado pelo valor (ou preço) em percentagem:\", medae_scaled_wls)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gfcj59gNQlc",
        "outputId": "9a76e446-9000-41a8-fee8-9911e518fab6"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            WLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:          VM30Abril2011   R-squared:                       0.822\n",
            "Model:                            WLS   Adj. R-squared:                  0.804\n",
            "Method:                 Least Squares   F-statistic:                     45.48\n",
            "Date:                Tue, 26 Sep 2023   Prob (F-statistic):           1.00e-50\n",
            "Time:                        16:10:52   Log-Likelihood:                -198.04\n",
            "No. Observations:                 175   AIC:                             430.1\n",
            "Df Residuals:                     158   BIC:                             483.9\n",
            "Df Model:                          16                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "=================================================================================\n",
            "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
            "---------------------------------------------------------------------------------\n",
            "const             2.3548      0.544      4.330      0.000       1.281       3.429\n",
            "PL2010            0.6592      0.063     10.543      0.000       0.536       0.783\n",
            "LL2010            0.0402      0.019      2.075      0.040       0.002       0.078\n",
            "d1                0.2025      0.149      1.355      0.177      -0.093       0.498\n",
            "d2                0.0947      0.138      0.684      0.495      -0.179       0.368\n",
            "d3                0.3310      0.222      1.493      0.137      -0.107       0.769\n",
            "d4                0.1116      0.168      0.665      0.507      -0.220       0.443\n",
            "d5               -0.2152      0.193     -1.117      0.266      -0.596       0.165\n",
            "d6                0.9188      0.315      2.920      0.004       0.297       1.540\n",
            "d7                0.3078      0.267      1.153      0.251      -0.219       0.835\n",
            "d8                0.3359      0.424      0.791      0.430      -0.502       1.174\n",
            "d9                0.2678      0.441      0.607      0.545      -0.604       1.140\n",
            "INTANG2010        0.0300      0.018      1.621      0.107      -0.007       0.066\n",
            "CAXEEQUIV2010     0.0751      0.039      1.913      0.058      -0.002       0.153\n",
            "CREC2010          0.0404      0.130      0.310      0.757      -0.217       0.298\n",
            "REC2010           0.0658      0.039      1.684      0.094      -0.011       0.143\n",
            "CAXOP2010         0.0260      0.023      1.121      0.264      -0.020       0.072\n",
            "ORA2010          -0.0369      0.018     -2.083      0.039      -0.072      -0.002\n",
            "==============================================================================\n",
            "Omnibus:                        3.085   Durbin-Watson:                   1.907\n",
            "Prob(Omnibus):                  0.214   Jarque-Bera (JB):                3.133\n",
            "Skew:                           0.314   Prob(JB):                        0.209\n",
            "Kurtosis:                       2.811   Cond. No.                     1.99e+17\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is 7.12e-30. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n",
            "Median Absolute Error (MedAE) ponderado: 0.5038092903671529\n",
            "MedAE ponderado escalado pelo valor (ou preço) em percentagem: 3.5112422219730584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MQP - MODELO SIMPLES"
      ],
      "metadata": {
        "id": "IXhYrWVgKtFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão linear\n",
        "modelo = sm.OLS(y, X).fit()\n",
        "\n",
        "# Calcule os resíduos (erros)\n",
        "residuos = modelo.resid\n",
        "\n",
        "# Calcule a variância dos resíduos\n",
        "variancia_residuos = np.var(residuos)\n",
        "\n",
        "# Calcule os pesos com base na variância dos resíduos (inverso da variância)\n",
        "pesos = 1 / variancia_residuos\n",
        "\n",
        "# Crie o modelo de regressão linear ponderada (WLS) com os pesos calculados\n",
        "modelo_wls = sm.WLS(y, X, weights=pesos).fit()\n",
        "\n",
        "# Visualize os resultados do modelo ponderado\n",
        "print(modelo_wls.summary())\n",
        "\n",
        "# Calcule os resíduos ponderados (erros ponderados)\n",
        "y_pred_wls = modelo_wls.predict(X)\n",
        "residuos_wls = y - y_pred_wls\n",
        "\n",
        "# Calcule o MedAE ponderado\n",
        "medae_wls = np.median(np.abs(residuos_wls))\n",
        "\n",
        "# Calcule o valor médio da variável de resposta\n",
        "valor_medio_y = np.mean(y)\n",
        "\n",
        "# Calcule o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "medae_scaled_wls = (medae_wls / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "print(\"Median Absolute Error (MedAE) ponderado:\", medae_wls)\n",
        "print(\"MedAE ponderado escalado pelo valor (ou preço) em percentagem:\", medae_scaled_wls)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad21390a-8930-4287-a3c4-a606e985790c",
        "id": "oIMBo59IK2xT"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            WLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:          VM30Abril2011   R-squared:                       0.963\n",
            "Model:                            WLS   Adj. R-squared:                  0.963\n",
            "Method:                 Least Squares   F-statistic:                     2242.\n",
            "Date:                Tue, 26 Sep 2023   Prob (F-statistic):          6.45e-124\n",
            "Time:                        13:40:27   Log-Likelihood:                -2999.5\n",
            "No. Observations:                 175   AIC:                             6005.\n",
            "Df Residuals:                     172   BIC:                             6015.\n",
            "Df Model:                           2                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const       1.855e+06   5.24e+05      3.543      0.001    8.22e+05    2.89e+06\n",
            "PL2010         0.1971      0.051      3.862      0.000       0.096       0.298\n",
            "LL2010         8.4327      0.364     23.192      0.000       7.715       9.150\n",
            "==============================================================================\n",
            "Omnibus:                      279.301   Durbin-Watson:                   2.057\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            40007.274\n",
            "Skew:                           7.196   Prob(JB):                         0.00\n",
            "Kurtosis:                      75.661   Cond. No.                     2.64e+07\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is 3.71e-12. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n",
            "Median Absolute Error (MedAE) ponderado: 1813759.6018572564\n",
            "MedAE ponderado escalado pelo valor (ou preço) em percentagem: 20.394401081320936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REGRESSÃO QUANTÍLICA"
      ],
      "metadata": {
        "id": "fUZVJwTv19EF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão quantílica\n",
        "modelo = sm.QuantReg(y, X).fit(q=0.5)  # q=0.5 representa a mediana, ajuste conforme necessário\n",
        "\n",
        "# Visualize os resultados do modelo\n",
        "print(modelo.summary())\n",
        "# Faça previsões com o modelo quantílico\n",
        "y_pred_quantreg = modelo.predict(X)\n",
        "\n",
        "# Calcule o MedAE para o modelo quantílico\n",
        "medae_quantreg = np.median(np.abs(y - y_pred_quantreg))\n",
        "\n",
        "# Calcule o valor médio da variável de resposta\n",
        "valor_medio_y = np.mean(y)\n",
        "\n",
        "# Calcule o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "medae_scaled_quantreg = (medae_quantreg / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "print(\"Median Absolute Error (MedAE) quantílico:\", medae_quantreg)\n",
        "print(\"MedAE quantílico escalado pelo valor (ou preço) em percentagem:\", medae_scaled_quantreg)\n"
      ],
      "metadata": {
        "id": "dgpuCY5p1_I5",
        "outputId": "7c17b10b-91eb-4f23-c2c4-bc00a426114b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         QuantReg Regression Results                          \n",
            "==============================================================================\n",
            "Dep. Variable:          VM30Abril2011   Pseudo R-squared:               0.7034\n",
            "Model:                       QuantReg   Bandwidth:                   1.230e+06\n",
            "Method:                 Least Squares   Sparsity:                    2.915e+06\n",
            "Date:                Tue, 26 Sep 2023   No. Observations:                  175\n",
            "Time:                        13:44:17   Df Residuals:                      172\n",
            "                                        Df Model:                            2\n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const       2.734e-07   1.13e+05   2.43e-12      1.000   -2.22e+05    2.22e+05\n",
            "PL2010         0.3167      0.011     28.892      0.000       0.295       0.338\n",
            "LL2010         7.4244      0.078     95.027      0.000       7.270       7.579\n",
            "==============================================================================\n",
            "\n",
            "The condition number is large, 2.64e+07. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n",
            "Median Absolute Error (MedAE) quantílico: 537773.1665478875\n",
            "MedAE quantílico escalado pelo valor (ou preço) em percentagem: 6.0468662098985115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RQ - Modelo **simples**"
      ],
      "metadata": {
        "id": "EZjW61OoLrfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão quantílica\n",
        "modelo = sm.QuantReg(y, X).fit(q=0.5)  # q=0.5 representa a mediana, ajuste conforme necessário\n",
        "\n",
        "# Visualize os resultados do modelo\n",
        "print(modelo.summary())\n",
        "# Faça previsões com o modelo quantílico\n",
        "y_pred_quantreg = modelo.predict(X)\n",
        "\n",
        "# Calcule o MedAE para o modelo quantílico\n",
        "medae_quantreg = np.median(np.abs(y - y_pred_quantreg))\n",
        "\n",
        "# Calcule o valor médio da variável de resposta\n",
        "valor_medio_y = np.mean(y)\n",
        "\n",
        "# Calcule o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "medae_scaled_quantreg = (medae_quantreg / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "print(\"Median Absolute Error (MedAE) quantílico:\", medae_quantreg)\n",
        "print(\"MedAE quantílico escalado pelo valor (ou preço) em percentagem:\", medae_scaled_quantreg)\n"
      ],
      "metadata": {
        "outputId": "3a525409-6d22-4193-b612-787adab707b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dov6TOxuLt01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         QuantReg Regression Results                          \n",
            "==============================================================================\n",
            "Dep. Variable:          VM30Abril2011   Pseudo R-squared:              0.05119\n",
            "Model:                       QuantReg   Bandwidth:                   2.204e+06\n",
            "Method:                 Least Squares   Sparsity:                    5.939e+06\n",
            "Date:                Thu, 21 Sep 2023   No. Observations:                  233\n",
            "Time:                        00:42:12   Df Residuals:                      222\n",
            "                                        Df Model:                           10\n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const      -2.037e+06   7.93e+05     -2.568      0.011    -3.6e+06   -4.74e+05\n",
            "PL2010      1.473e+05   6.71e+04      2.195      0.029     1.5e+04     2.8e+05\n",
            "LL2010      1.831e+05   5.52e+04      3.314      0.001    7.42e+04    2.92e+05\n",
            "d1         -6.203e+05   6.52e+05     -0.952      0.342    -1.9e+06    6.64e+05\n",
            "d2         -4.572e+04   5.99e+05     -0.076      0.939   -1.23e+06    1.13e+06\n",
            "d3           9.57e+05   8.52e+05      1.124      0.262   -7.21e+05    2.64e+06\n",
            "d4          1.078e+06   6.68e+05      1.613      0.108   -2.39e+05    2.39e+06\n",
            "d5          4.246e+05   7.58e+05      0.560      0.576   -1.07e+06    1.92e+06\n",
            "d6          5.048e+06   1.16e+06      4.358      0.000    2.77e+06    7.33e+06\n",
            "d7           9.23e+05   1.08e+06      0.852      0.395   -1.21e+06    3.06e+06\n",
            "d8           6.97e+05   1.78e+06      0.393      0.695    -2.8e+06     4.2e+06\n",
            "==============================================================================\n",
            "Median Absolute Error (MedAE) quantílico: 1446196.2802038135\n",
            "MedAE quantílico escalado pelo valor (ou preço) em percentagem: 15.79066708299929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/regression/quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
            "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REGRESSÃO BAYESIANA"
      ],
      "metadata": {
        "id": "d35ZXGV__UMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import median_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'INTANG2010',\n",
        "           'CAXEEQUIV2010', 'CREC2010', 'REC2010', 'CAXOP2010', 'ORA2010']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo Bayesian Ridge\n",
        "    modelo_bayesiano = BayesianRidge()\n",
        "\n",
        "    modelo_bayesiano.fit(X_train, y_train)\n",
        "    y_pred = modelo_bayesiano.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = median_absolute_error(y_test, y_pred)\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar os coeficientes do modelo (coeficientes Bayesianos)\n",
        "    coeficientes = modelo_bayesiano.coef_\n",
        "    print(\"Coeficientes do Modelo:\", coeficientes)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPyVyLlA_XEf",
        "outputId": "9a734e76-d495-437b-aa68-2675bf90dc0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coeficientes do Modelo: [ 7.08496313e-06  8.50551699e-06 -1.79938865e-07 -2.99273481e-07\n",
            "  7.74715337e-08 -9.77720389e-08  1.59503720e-07  2.72852696e-07\n",
            " -3.68232014e-08 -1.84567576e-08  6.26235546e-06  5.44375979e-06\n",
            " -1.40066325e-07  4.88001768e-06  7.76672262e-06  1.33286053e-06]\n",
            "Coeficientes do Modelo: [ 6.96622855e-06  8.59324119e-06 -1.95418983e-07 -2.84994665e-07\n",
            "  7.31044029e-08 -1.19940622e-07  1.50682792e-07  2.62474289e-07\n",
            " -4.62932362e-08 -1.89791311e-08  6.13004571e-06  5.13763836e-06\n",
            " -8.62902705e-08  4.53055832e-06  7.59223793e-06  1.79021918e-06]\n",
            "Coeficientes do Modelo: [ 7.50093250e-06  8.96193362e-06 -2.07201366e-07 -2.82470313e-07\n",
            "  1.23434111e-07 -5.76769448e-08 -6.20155007e-08  3.88196588e-07\n",
            " -4.32547321e-08 -1.94188176e-08  7.35434543e-06  5.57943273e-06\n",
            " -2.45610698e-07  5.11388978e-06  8.29081940e-06  2.29257129e-06]\n",
            "Coeficientes do Modelo: [ 7.01348368e-06  8.37231255e-06 -2.00702891e-07 -2.73820811e-07\n",
            "  4.00381872e-08 -8.83168929e-08  1.66644484e-07  2.71499606e-07\n",
            " -4.44495021e-08 -1.84617535e-08  6.33441555e-06  5.34124100e-06\n",
            " -1.51488131e-07  4.87421725e-06  7.74585812e-06  1.20050839e-06]\n",
            "Coeficientes do Modelo: [ 7.04375554e-06  8.62736665e-06 -2.11238331e-07 -3.18782780e-07\n",
            "  6.06153108e-08 -1.10897743e-07  1.76777236e-07  2.69983869e-07\n",
            " -2.59708037e-08 -1.18030996e-08  6.45148566e-06  5.40735565e-06\n",
            " -6.15561924e-08  4.85229147e-06  7.75342441e-06  1.89781038e-06]\n",
            "Coeficientes do Modelo: [ 6.94436512e-06  8.44545876e-06 -2.01776462e-07 -2.92380243e-07\n",
            " -2.64486712e-08 -1.11511481e-07  1.78085063e-07  2.88019666e-07\n",
            " -3.62362127e-08 -1.83790623e-08  6.50378020e-06  5.38255741e-06\n",
            " -8.08979691e-08  4.81237136e-06  7.95916152e-06  1.90943956e-06]\n",
            "Coeficientes do Modelo: [ 7.15267827e-06  8.62589360e-06 -2.05074678e-07 -3.05413267e-07\n",
            "  7.25996968e-08 -9.69553837e-08  1.64855628e-07  2.62304741e-07\n",
            " -3.98803287e-08 -1.52066274e-08  6.67601567e-06  5.38639133e-06\n",
            " -1.48903926e-07  4.94926732e-06  7.83421553e-06  1.71310782e-06]\n",
            "Coeficientes do Modelo: [ 9.80453912e-06  1.23507686e-05 -2.96673076e-07 -4.31461726e-07\n",
            "  1.58908349e-07 -1.22816528e-07  3.61404365e-07 -1.81042063e-08\n",
            " -7.25959261e-08 -2.83713837e-08  8.13669789e-06  7.23610503e-06\n",
            " -1.63770922e-07  6.30297989e-06  1.15450953e-05  4.34614286e-06]\n",
            "Coeficientes do Modelo: [ 7.18368105e-06  8.52018641e-06 -2.00590975e-07 -2.81911230e-07\n",
            "  6.68624790e-08 -1.17108548e-07  1.46119688e-07  2.60252253e-07\n",
            " -4.51008430e-08 -1.11865385e-08  6.55858876e-06  5.42537141e-06\n",
            " -1.36270243e-07  4.94068410e-06  7.85343474e-06  1.90639484e-06]\n",
            "Coeficientes do Modelo: [ 7.12540238e-06  8.67179467e-06 -1.87088952e-07 -2.85294292e-07\n",
            "  7.31692957e-08 -9.69535293e-08  1.75027645e-07  3.01985693e-07\n",
            " -3.99758480e-08 -1.89770845e-08  6.55989562e-06  5.58225527e-06\n",
            " -1.72568671e-07  5.10216985e-06  7.83845416e-06  9.73415543e-07]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 153.29743994723083\n",
            "Média do R²: -0.7490923071700291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RB_Simples"
      ],
      "metadata": {
        "id": "X-hPlPqnNEYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import median_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo Bayesian Ridge\n",
        "    modelo_bayesiano = BayesianRidge()\n",
        "\n",
        "    modelo_bayesiano.fit(X_train, y_train)\n",
        "    y_pred = modelo_bayesiano.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = median_absolute_error(y_test, y_pred)\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar os coeficientes do modelo (coeficientes Bayesianos)\n",
        "    coeficientes = modelo_bayesiano.coef_\n",
        "    print(\"Coeficientes do Modelo:\", coeficientes)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32c0862b-6765-40d3-b3c5-c08aa5978566",
        "id": "zj4mQ3zrNLrh"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coeficientes do Modelo: [0.19188281 8.45629113]\n",
            "Coeficientes do Modelo: [0.22668561 8.34082727]\n",
            "Coeficientes do Modelo: [0.19966138 8.40579709]\n",
            "Coeficientes do Modelo: [0.20303421 8.38661021]\n",
            "Coeficientes do Modelo: [0.19777606 8.41914842]\n",
            "Coeficientes do Modelo: [-0.27097269 12.80690676]\n",
            "Coeficientes do Modelo: [0.33935145 7.25871386]\n",
            "Coeficientes do Modelo: [0.19883149 8.40204373]\n",
            "Coeficientes do Modelo: [0.20031633 8.40661591]\n",
            "Coeficientes do Modelo: [0.19857645 8.40860678]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 34.72130288583516\n",
            "Média do R²: 0.6811624797220183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVR"
      ],
      "metadata": {
        "id": "NIw0ZhcK_9OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import median_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo SVR com kernel RBF\n",
        "    modelo_svr = SVR(kernel='rbf', C=1.0)\n",
        "\n",
        "    modelo_svr.fit(X_train, y_train)\n",
        "    y_pred = modelo_svr.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = median_absolute_error(y_test, y_pred)\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPXr6W3_Hh_z",
        "outputId": "8f2dd8d8-b648-43aa-87fd-ff6abc24f969"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 30.922557419026703\n",
            "Média do R²: -0.13998148176323186\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVR_simples"
      ],
      "metadata": {
        "id": "5QTAN2pFNmCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import median_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo SVR com kernel RBF\n",
        "    modelo_svr = SVR(kernel='rbf', C=1.0)\n",
        "\n",
        "    modelo_svr.fit(X_train, y_train)\n",
        "    y_pred = modelo_svr.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = median_absolute_error(y_test, y_pred)\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "307b501d-487d-46d3-bb4e-03db286b4f7c",
        "id": "k9USclUIN9aK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 24.44618188204652\n",
            "Média do R²: -0.11840171315472689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ARVORE DE DECISÃO"
      ],
      "metadata": {
        "id": "x6LWJCtFU0Od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'INTANG2010',\n",
        "           'CAXEEQUIV2010', 'CREC2010', 'REC2010', 'CAXOP2010', 'ORA2010']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de árvore de decisão com os parâmetros desejados\n",
        "    modelo_arvore = DecisionTreeRegressor(min_samples_split=5, random_state=42)\n",
        "\n",
        "    # Criar o modelo Bagging com 500 árvores\n",
        "    bagging_model = BaggingRegressor(base_estimator=modelo_arvore, n_estimators=500, bootstrap=True, random_state=42)\n",
        "\n",
        "    bagging_model.fit(X_train, y_train)\n",
        "    y_pred = bagging_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar a importância dos coeficientes (importância das variáveis)\n",
        "    importancia_coeficientes = np.mean([tree.feature_importances_ for tree in bagging_model.estimators_], axis=0)\n",
        "    print(\"Importância dos Coeficientes:\", importancia_coeficientes)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6G90UU8W4WZ",
        "outputId": "dd01abf2-a69b-4746-93ad-5a71ea9a96c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [9.10331917e-02 5.32096150e-01 7.46280579e-05 2.58125079e-05\n",
            " 1.53974109e-04 5.78882791e-05 7.41658812e-04 5.23380942e-04\n",
            " 7.13077098e-05 2.77884957e-05 3.26844256e-02 5.34216006e-02\n",
            " 2.30281210e-03 8.33399946e-02 2.03143408e-01 3.01979084e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [8.99028064e-02 5.51056557e-01 8.11885682e-05 1.99200889e-05\n",
            " 5.45854393e-04 9.36889971e-05 8.02070706e-04 9.26589024e-05\n",
            " 7.13288938e-05 2.73507441e-05 5.16125577e-02 4.89468239e-02\n",
            " 2.54056461e-03 6.53434222e-02 1.88372045e-01 4.91162430e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [9.54776694e-02 5.04529141e-01 1.65299357e-04 2.82789635e-05\n",
            " 3.48121511e-04 8.23264163e-05 7.73090836e-05 2.65261369e-04\n",
            " 1.61060904e-04 5.42178019e-05 1.11869793e-01 3.25982752e-02\n",
            " 1.07199253e-03 4.56973953e-02 2.06752235e-01 8.21623532e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [6.16855495e-02 6.27540994e-01 1.17727978e-04 1.74139920e-05\n",
            " 4.35611252e-05 8.00237642e-05 4.60348274e-05 1.05843942e-04\n",
            " 1.35130253e-04 4.39048749e-05 4.25530543e-02 5.07585790e-02\n",
            " 1.82124511e-03 4.82482145e-02 1.66619181e-01 1.83541699e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [7.61818254e-02 5.20850450e-01 7.44396938e-05 2.42881163e-05\n",
            " 5.34983696e-04 1.45307277e-04 4.88677751e-04 6.07334903e-04\n",
            " 2.33680810e-05 3.97721214e-05 4.54133559e-02 8.28631425e-02\n",
            " 1.69659458e-03 6.31614556e-02 2.07663919e-01 2.31085456e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [1.61306710e-01 3.22361264e-01 9.41297056e-06 1.69934508e-05\n",
            " 8.51689390e-05 1.02569277e-04 4.52452724e-04 1.18480891e-04\n",
            " 1.25419440e-04 3.42172907e-05 5.90710623e-02 6.72401050e-02\n",
            " 1.67643908e-03 8.32452385e-02 3.03643092e-01 5.11374190e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [6.83011600e-02 5.72288523e-01 7.30054353e-05 1.92055731e-05\n",
            " 3.58669740e-04 9.29456352e-05 1.44187156e-03 1.07295091e-04\n",
            " 9.87457840e-05 3.16178422e-07 2.23185008e-02 7.14029141e-02\n",
            " 1.98741215e-03 6.79756902e-02 1.93243472e-01 2.90272117e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [7.01982063e-02 6.04196581e-01 1.54987797e-04 2.94631419e-05\n",
            " 6.43468124e-04 1.83651625e-04 4.14365935e-03 1.48577343e-04\n",
            " 1.01398800e-04 4.07532837e-05 1.76587591e-03 2.36138007e-02\n",
            " 4.70261921e-03 1.94771074e-02 2.69824977e-01 7.74872587e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [8.18612788e-02 5.70434659e-01 1.02837171e-04 2.22868456e-05\n",
            " 5.83176184e-04 7.08342412e-05 3.19345555e-03 1.31757575e-03\n",
            " 1.16723514e-04 3.23718670e-05 2.23499745e-02 8.49471059e-02\n",
            " 2.01311714e-03 5.22062771e-02 1.80358124e-01 3.90202013e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [1.32806403e-01 3.86808020e-01 1.02486056e-04 3.60330752e-05\n",
            " 1.02488883e-03 9.60165010e-05 1.01063999e-03 4.93724109e-05\n",
            " 8.53327941e-05 4.09381062e-05 7.40642359e-02 9.76945658e-02\n",
            " 2.59502261e-03 1.40678238e-01 1.62499782e-01 4.08023444e-04]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 11.733740348672065\n",
            "Média do R²: 0.6541393514686065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CART_simples"
      ],
      "metadata": {
        "id": "ZYtjgE_9OP3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de árvore de decisão com os parâmetros desejados\n",
        "    modelo_arvore = DecisionTreeRegressor(min_samples_split=5, random_state=42)\n",
        "\n",
        "    # Criar o modelo Bagging com 500 árvores\n",
        "    bagging_model = BaggingRegressor(base_estimator=modelo_arvore, n_estimators=500, bootstrap=True, random_state=42)\n",
        "\n",
        "    bagging_model.fit(X_train, y_train)\n",
        "    y_pred = bagging_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar a importância dos coeficientes (importância das variáveis)\n",
        "    importancia_coeficientes = np.mean([tree.feature_importances_ for tree in bagging_model.estimators_], axis=0)\n",
        "    print(\"Importância dos Coeficientes:\", importancia_coeficientes)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1baaa15-f0f2-4586-a43b-f929fc207601",
        "id": "c3TdDSmhOYKa"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.26435473 0.73564527]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.24348095 0.75651905]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.29777168 0.70222832]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.35158443 0.64841557]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.31177375 0.68822625]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.33001857 0.66998143]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.40618415 0.59381585]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.26812092 0.73187908]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.31483018 0.68516982]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.33916319 0.66083681]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 16.456373355133202\n",
            "Média do R²: 0.6510814839522938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FLORESTA ALEATÓRIA"
      ],
      "metadata": {
        "id": "OZLbiycNZm26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de Floresta Aleatória com os parâmetros desejados\n",
        "    random_forest_model = RandomForestRegressor(n_estimators=500, random_state=42)\n",
        "\n",
        "    random_forest_model.fit(X_train, y_train)\n",
        "    y_pred = random_forest_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar a importância das variáveis\n",
        "    importancia_variaveis = random_forest_model.feature_importances_\n",
        "    print(\"Importância das Variáveis:\", importancia_variaveis)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "id": "lpAmsgS7Zph4",
        "outputId": "c26e9bd1-e127-46f0-f9e9-a2fb293b7a3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância das Variáveis: [0.27604685 0.72395315]\n",
            "Importância das Variáveis: [0.27016554 0.72983446]\n",
            "Importância das Variáveis: [0.32547679 0.67452321]\n",
            "Importância das Variáveis: [0.36455873 0.63544127]\n",
            "Importância das Variáveis: [0.35340058 0.64659942]\n",
            "Importância das Variáveis: [0.34137838 0.65862162]\n",
            "Importância das Variáveis: [0.43362569 0.56637431]\n",
            "Importância das Variáveis: [0.28144652 0.71855348]\n",
            "Importância das Variáveis: [0.32181164 0.67818836]\n",
            "Importância das Variáveis: [0.35888294 0.64111706]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 16.098113430815424\n",
            "Média do R²: 0.6636209661932576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RF-simples"
      ],
      "metadata": {
        "id": "yx7kQryEO5xl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados_log[['PL2010', 'LL2010']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de Floresta Aleatória com os parâmetros desejados\n",
        "    random_forest_model = RandomForestRegressor(n_estimators=500, random_state=42)\n",
        "\n",
        "    random_forest_model.fit(X_train, y_train)\n",
        "    y_pred = random_forest_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar a importância das variáveis\n",
        "    importancia_variaveis = random_forest_model.feature_importances_\n",
        "    print(\"Importância das Variáveis:\", importancia_variaveis)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "outputId": "97431978-a319-4223-f94a-7d842aa8b066",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP-9l579PAS_"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância das Variáveis: [0.66151711 0.33848289]\n",
            "Importância das Variáveis: [0.69921784 0.30078216]\n",
            "Importância das Variáveis: [0.69164002 0.30835998]\n",
            "Importância das Variáveis: [0.69997231 0.30002769]\n",
            "Importância das Variáveis: [0.65348849 0.34651151]\n",
            "Importância das Variáveis: [0.70261148 0.29738852]\n",
            "Importância das Variáveis: [0.72090539 0.27909461]\n",
            "Importância das Variáveis: [0.61428666 0.38571334]\n",
            "Importância das Variáveis: [0.66004532 0.33995468]\n",
            "Importância das Variáveis: [0.6768845 0.3231155]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 3.3385672448187877\n",
            "Média do R²: 0.735425099674524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRADIENT BOOSTING"
      ],
      "metadata": {
        "id": "gReIxsDPa_9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de Regressão Gradient Boosting com os parâmetros desejados\n",
        "    gradient_boosting_model = GradientBoostingRegressor(n_estimators=500, random_state=42)\n",
        "\n",
        "    gradient_boosting_model.fit(X_train, y_train)\n",
        "    y_pred = gradient_boosting_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar a importância das variáveis\n",
        "    importancia_variaveis = gradient_boosting_model.feature_importances_\n",
        "    print(\"Importância das Variáveis:\", importancia_variaveis)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "id": "NvfZ3qUAbCf5",
        "outputId": "1da8b300-99ef-408f-b2d3-542f2746dd16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância das Variáveis: [0.05716617 0.94283383]\n",
            "Importância das Variáveis: [0.07175369 0.92824631]\n",
            "Importância das Variáveis: [0.05991082 0.94008918]\n",
            "Importância das Variáveis: [0.06428654 0.93571346]\n",
            "Importância das Variáveis: [0.05817394 0.94182606]\n",
            "Importância das Variáveis: [0.43240805 0.56759195]\n",
            "Importância das Variáveis: [0.55107801 0.44892199]\n",
            "Importância das Variáveis: [0.0582299 0.9417701]\n",
            "Importância das Variáveis: [0.05961152 0.94038848]\n",
            "Importância das Variáveis: [0.05944205 0.94055795]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 16.925302771549593\n",
            "Média do R²: 0.657517829900359\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GB-SIMPLES"
      ],
      "metadata": {
        "id": "nqnLHReIPr4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de Regressão Gradient Boosting com os parâmetros desejados\n",
        "    gradient_boosting_model = GradientBoostingRegressor(n_estimators=500, random_state=42)\n",
        "\n",
        "    gradient_boosting_model.fit(X_train, y_train)\n",
        "    y_pred = gradient_boosting_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar a importância das variáveis\n",
        "    importancia_variaveis = gradient_boosting_model.feature_importances_\n",
        "    print(\"Importância das Variáveis:\", importancia_variaveis)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "outputId": "d6e3ba19-b466-4524-edf9-a7b1682ac76f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYfOHR_NPz63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância das Variáveis: [1.22486979e-01 8.57342657e-01 2.60251479e-04 5.00926953e-05\n",
            " 5.17114161e-03 3.08890958e-05 8.59360938e-03 5.98157575e-03\n",
            " 7.62790184e-05 6.52440298e-06]\n",
            "Importância das Variáveis: [9.25235879e-02 8.98729918e-01 2.25660079e-04 2.31454288e-05\n",
            " 5.00105918e-03 7.61562315e-05 2.30804942e-03 1.02685989e-03\n",
            " 8.05739417e-05 4.98996125e-06]\n",
            "Importância das Variáveis: [7.61690203e-02 8.28379994e-01 1.23463666e-04 2.18603930e-05\n",
            " 1.20798471e-02 3.81737371e-05 2.99713738e-05 8.30595768e-02\n",
            " 8.88154135e-05 9.27726494e-06]\n",
            "Importância das Variáveis: [8.25451447e-02 9.07169147e-01 2.03102789e-04 1.06464145e-05\n",
            " 2.12865558e-03 1.69658262e-04 3.91894653e-03 3.76936246e-03\n",
            " 8.17742816e-05 3.56217304e-06]\n",
            "Importância das Variáveis: [7.89982856e-02 9.00467211e-01 1.58309071e-04 1.80276654e-05\n",
            " 5.56638252e-03 2.37462239e-04 1.01289963e-02 4.35510838e-03\n",
            " 5.24730059e-05 1.77441810e-05]\n",
            "Importância das Variáveis: [7.37958361e-02 9.15695825e-01 1.39371817e-04 2.54882404e-05\n",
            " 1.61267829e-04 2.06177574e-05 5.06486627e-03 4.97738304e-03\n",
            " 1.11305427e-04 8.03838628e-06]\n",
            "Importância das Variáveis: [9.00511266e-02 8.92972527e-01 2.16555678e-04 2.26711012e-05\n",
            " 5.50781200e-03 1.49805982e-04 6.70480409e-03 4.30019004e-03\n",
            " 7.39735611e-05 5.33624022e-07]\n",
            "Importância das Variáveis: [6.55702287e-02 8.77464966e-01 5.11462696e-04 4.10807307e-05\n",
            " 5.06598018e-03 9.95397566e-05 5.08704619e-02 3.03094794e-04\n",
            " 6.10375286e-05 1.21478700e-05]\n",
            "Importância das Variáveis: [1.24227183e-01 8.54363135e-01 2.47890763e-04 2.21540382e-05\n",
            " 5.99024725e-03 9.69708533e-05 1.20541495e-02 2.90722770e-03\n",
            " 8.36976921e-05 7.34368219e-06]\n",
            "Importância das Variáveis: [3.32291956e-01 6.48653152e-01 4.06616931e-04 2.47537190e-05\n",
            " 7.06091374e-03 6.86761992e-05 6.04965595e-03 5.34744253e-03\n",
            " 8.85244671e-05 8.30854156e-06]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 11.033212056692873\n",
            "Média do R²: 0.8123781223518403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REDES NEURAIS"
      ],
      "metadata": {
        "id": "Gy8Aqujjc2rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PL2010', 'LL2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de regressão de rede neural com os parâmetros desejados\n",
        "    modelo_rede_neural = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
        "\n",
        "    modelo_rede_neural.fit(X_train, y_train)\n",
        "    y_pred = modelo_rede_neural.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "id": "yygOLB39c4OY",
        "outputId": "4ac0dd37-a3f3-4b70-a759-0afb9caeb2a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 13.698779559100988\n",
            "Média do R²: 0.5947388544717401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7FEGQu5PQTiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NN_simples"
      ],
      "metadata": {
        "id": "i3Ep3oDeQXIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de regressão de rede neural com os parâmetros desejados\n",
        "    modelo_rede_neural = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
        "\n",
        "    modelo_rede_neural.fit(X_train, y_train)\n",
        "    y_pred = modelo_rede_neural.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "outputId": "723bcd2f-03f2-4b53-fb47-a0be5625a295",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcBDiLVzQT5m"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 14.796065460978616\n",
            "Média do R²: -0.1516691707421371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}