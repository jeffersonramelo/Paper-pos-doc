{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORpsjb9oX1VV6kqkbTiMIK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffersonramelo/Paper-pos-doc/blob/main/modelos_tradicionais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Caminho para o arquivo XLSX\n",
        "caminho_arquivo = '/content/2010.xlsx'\n",
        "\n",
        "# Lê o arquivo XLSX\n",
        "dados = pd.read_excel(caminho_arquivo)\n",
        "\n",
        "# Agora, 'dados' contém os dados do arquivo XLSX\n"
      ],
      "metadata": {
        "id": "DOE1GbH_7pjb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibe as primeiras linhas do DataFrame\n",
        "print(dados.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JswF8j8m8FiD",
        "outputId": "85c7b76c-4ab9-41b8-ed17-41436fad5c33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID Código    Setor EconômicoB3     VM30Abr11   PLDez2010  LLDez2010  \\\n",
            "0   5  EALT4     Bens industriais  6.072750e+04     45809.0     5927.0   \n",
            "1  21  ALPA4      Consumo cíclico  3.893923e+06   1310475.0   306341.0   \n",
            "2  26  ABEV3  Consumo não cíclico  1.422082e+08  24361863.0  7561383.0   \n",
            "3  28  AMER3      Consumo cíclico  2.382110e+06    225945.0    33587.0   \n",
            "4  29  CBEE3    Utilidade pública  4.773374e+06   1583469.0   216092.0   \n",
            "\n",
            "    ATDez2010   PTDez2010  VM30Abr11esc  PLDez2010esc  LLDez2010esc  \\\n",
            "0    237963.0    192154.0      0.424087      0.319904      0.041391   \n",
            "1   2246603.0    936128.0      2.226423      0.749289      0.175156   \n",
            "2  42678300.0  18316437.0      3.546250      0.607512      0.188558   \n",
            "3   3212014.0   2986069.0      1.024863      0.097209      0.014450   \n",
            "4   4313606.0   2730137.0      1.040166      0.345054      0.047089   \n",
            "\n",
            "   ATDez2010esc  PTDez2010esc   ATDez2009  \n",
            "0      1.661799      1.341895    143196.0  \n",
            "1      1.284537      0.535249   1748959.0  \n",
            "2      1.064270      0.456757  40101017.0  \n",
            "3      1.381916      1.284706   2324320.0  \n",
            "4      0.939978      0.594924   4589050.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REGRESSÃO SEM ESCALA"
      ],
      "metadata": {
        "id": "_lfctlNuhZs5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tratar outliers: A winsorização ao nível de 1% envolve substituir os 1% dos valores mais extremos por valores no limite do intervalo aceitável, ou seja, os 1% menores e os 1% maiores dos valores."
      ],
      "metadata": {
        "id": "95LYGQCnbVVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats.mstats import winsorize\n",
        "\n",
        "nivel_winsorizacao = 0.01  # 1% de winsorização\n",
        "\n",
        "# Aplica a winsorização às variáveis\n",
        "dados['PLDez2010_winsorizada'] = winsorize(dados['PLDez2010'], limits=[nivel_winsorizacao, nivel_winsorizacao])\n",
        "dados['LLDez2010_winsorizada'] = winsorize(dados['LLDez2010'], limits=[nivel_winsorizacao, nivel_winsorizacao])\n",
        "dados['VM30Abr11_winsorizada'] = winsorize(dados['VM30Abr11'], limits=[nivel_winsorizacao, nivel_winsorizacao])\n",
        "# Variáveis winsorizadas agora contêm os valores winsorizados"
      ],
      "metadata": {
        "id": "bcS1mdNlbcTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados[['PLDez2010_winsorizada', 'LLDez2010_winsorizada']]\n",
        "y = dados['VM30Abr11_winsorizada']\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão linear\n",
        "modelo = sm.OLS(y, X).fit()\n",
        "\n",
        "# Visualize os resultados do modelo\n",
        "print(modelo.summary())\n",
        "\n",
        "# Calcule o MedAE\n",
        "y_pred = modelo.predict(X)\n",
        "medae = np.median(np.abs(y - y_pred))\n",
        "\n",
        "# Calcule o valor médio da variável de resposta\n",
        "valor_medio_y = np.mean(y)\n",
        "\n",
        "# Calcule o MedAE escalado pelo valor (ou preço)\n",
        "medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "print(\"Median Absolute Error (MedAE):\", medae)\n",
        "print(\"MedAE escalado pelo valor (ou preço) em percentagem:\", medae_scaled)\n"
      ],
      "metadata": {
        "id": "eUYMK2RnbdGD",
        "outputId": "7f474860-a5d7-4e0e-c093-56e5e28315ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                              OLS Regression Results                             \n",
            "=================================================================================\n",
            "Dep. Variable:     VM30Abr11_winsorizada   R-squared:                       0.948\n",
            "Model:                               OLS   Adj. R-squared:                  0.947\n",
            "Method:                    Least Squares   F-statistic:                     1674.\n",
            "Date:                   Thu, 14 Sep 2023   Prob (F-statistic):          3.20e-119\n",
            "Time:                           23:06:18   Log-Likelihood:                -3218.1\n",
            "No. Observations:                    188   AIC:                             6442.\n",
            "Df Residuals:                        185   BIC:                             6452.\n",
            "Df Model:                              2                                         \n",
            "Covariance Type:               nonrobust                                         \n",
            "=========================================================================================\n",
            "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
            "-----------------------------------------------------------------------------------------\n",
            "const                  1.773e+06    5.1e+05      3.478      0.001    7.67e+05    2.78e+06\n",
            "PLDez2010_winsorizada     0.2362      0.097      2.431      0.016       0.045       0.428\n",
            "LLDez2010_winsorizada     8.0064      0.397     20.177      0.000       7.224       8.789\n",
            "==============================================================================\n",
            "Omnibus:                      314.077   Durbin-Watson:                   2.055\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            57533.200\n",
            "Skew:                           7.979   Prob(JB):                         0.00\n",
            "Kurtosis:                      87.202   Cond. No.                     1.44e+07\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 1.44e+07. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n",
            "Median Absolute Error (MedAE): 1727481.6787896082\n",
            "MedAE escalado pelo valor (ou preço) em percentagem: 22.38428034289984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em relação aos resultados apresentados no seu modelo de regressão:\n",
        "\n",
        "O valor do teste de Durbin-Watson é 1.676, o que sugere uma leve autocorrelação positiva nos resíduos, mas não muito forte.\n",
        "O valor-p associado ao teste de Jarque-Bera é praticamente zero (0.00), o que indica que os resíduos não seguem uma distribuição normal.\n",
        "\n",
        "Interpretação DW:\n",
        "\n",
        "Valor DW ≈ 2: Ausência de autocorrelação significativa nos resíduos (boa notícia).\n",
        "Valor DW < 2: Autocorrelação positiva nos resíduos (erros adjacentes são correlacionados positivamente).\n",
        "Valor DW > 2: Autocorrelação negativa nos resíduos (erros adjacentes são correlacionados negativamente)."
      ],
      "metadata": {
        "id": "BYoRhNnCeQLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesse caso específico, o valor de 17.74% indica que, em média, as previsões do modelo estão erradas em cerca de 17.74% do valor médio (ou preço) da variável de resposta. Isso ajuda a ter uma ideia do tamanho relativo dos erros do modelo em relação ao valor médio dos dados."
      ],
      "metadata": {
        "id": "SzP6fpN084-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "teste de heterocedasticidade de White. Se o valor-p for menor que um nível de significância escolhido (por exemplo, 0,05), você pode rejeitar a hipótese nula de homocedasticidade"
      ],
      "metadata": {
        "id": "9Zd9X-08b9S_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.diagnostic import het_white\n",
        "\n",
        "# Calcule os resíduos do modelo\n",
        "residuos = modelo.resid\n",
        "\n",
        "# Realize o teste de White para heterocedasticidade\n",
        "teste_white = het_white(residuos, X)\n",
        "\n",
        "# Imprima os resultados do teste\n",
        "print(\"Estatística do teste de White:\", teste_white[0])\n",
        "print(\"Valor-p do teste de White:\", teste_white[1])"
      ],
      "metadata": {
        "id": "ICEs0hnicHRU",
        "outputId": "3c45ce38-be80-434f-e265-18d32aab19db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estatística do teste de White: 113.73736510497207\n",
            "Valor-p do teste de White: 6.642361768007011e-23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "minimos quadrados ponderados (MQP), com pesos com base na variância dos erros"
      ],
      "metadata": {
        "id": "Vmo8zEDpLVRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados[['PLDez2010', 'LLDez2010']]\n",
        "y = dados['VM30Abr11']\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão linear\n",
        "modelo = sm.OLS(y, X).fit()\n",
        "\n",
        "# Calcule os resíduos (erros)\n",
        "residuos = modelo.resid\n",
        "\n",
        "# Calcule a variância dos resíduos\n",
        "variancia_residuos = np.var(residuos)\n",
        "\n",
        "# Calcule os pesos com base na variância dos resíduos (inverso da variância)\n",
        "pesos = 1 / variancia_residuos\n",
        "\n",
        "# Crie o modelo de regressão linear ponderada (WLS) com os pesos calculados\n",
        "modelo_wls = sm.WLS(y, X, weights=pesos).fit()\n",
        "\n",
        "# Visualize os resultados do modelo ponderado\n",
        "print(modelo_wls.summary())\n",
        "\n",
        "# Calcule os resíduos ponderados (erros ponderados)\n",
        "y_pred_wls = modelo_wls.predict(X)\n",
        "residuos_wls = y - y_pred_wls\n",
        "\n",
        "# Calcule o MedAE ponderado\n",
        "medae_wls = np.median(np.abs(residuos_wls))\n",
        "\n",
        "# Calcule o valor médio da variável de resposta\n",
        "valor_medio_y = np.mean(y)\n",
        "\n",
        "# Calcule o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "medae_scaled_wls = (medae_wls / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "print(\"Median Absolute Error (MedAE) ponderado:\", medae_wls)\n",
        "print(\"MedAE ponderado escalado pelo valor (ou preço) em percentagem:\", medae_scaled_wls)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gfcj59gNQlc",
        "outputId": "ebacec5a-ba9c-4612-bc9e-ca85459ce386"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            WLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:              VM30Abr11   R-squared:                       0.963\n",
            "Model:                            WLS   Adj. R-squared:                  0.963\n",
            "Method:                 Least Squares   F-statistic:                     2411.\n",
            "Date:                Thu, 14 Sep 2023   Prob (F-statistic):          3.13e-133\n",
            "Time:                        23:10:36   Log-Likelihood:                -3216.0\n",
            "No. Observations:                 188   AIC:                             6438.\n",
            "Df Residuals:                     185   BIC:                             6448.\n",
            "Df Model:                           2                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const       1.752e+06   4.87e+05      3.595      0.000    7.91e+05    2.71e+06\n",
            "PLDez2010      0.1983      0.049      4.023      0.000       0.101       0.296\n",
            "LLDez2010      8.4291      0.351     24.002      0.000       7.736       9.122\n",
            "==============================================================================\n",
            "Omnibus:                      302.482   Durbin-Watson:                   2.045\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            49384.538\n",
            "Skew:                           7.451   Prob(JB):                         0.00\n",
            "Kurtosis:                      80.989   Cond. No.                     2.54e+07\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is 4.28e-12. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n",
            "Median Absolute Error (MedAE) ponderado: 1710616.3343900286\n",
            "MedAE ponderado escalado pelo valor (ou preço) em percentagem: 20.74108453982559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REGRESSÃO QUANTÍLICA"
      ],
      "metadata": {
        "id": "fUZVJwTv19EF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados[['PLDez2010', 'LLDez2010']]\n",
        "y = dados['VM30Abr11']\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão quantílica\n",
        "modelo = sm.QuantReg(y, X).fit(q=0.5)  # q=0.5 representa a mediana, ajuste conforme necessário\n",
        "\n",
        "# Visualize os resultados do modelo\n",
        "print(modelo.summary())\n",
        "# Faça previsões com o modelo quantílico\n",
        "y_pred_quantreg = modelo.predict(X)\n",
        "\n",
        "# Calcule o MedAE para o modelo quantílico\n",
        "medae_quantreg = np.median(np.abs(y - y_pred_quantreg))\n",
        "\n",
        "# Calcule o valor médio da variável de resposta\n",
        "valor_medio_y = np.mean(y)\n",
        "\n",
        "# Calcule o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "medae_scaled_quantreg = (medae_quantreg / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "print(\"Median Absolute Error (MedAE) quantílico:\", medae_quantreg)\n",
        "print(\"MedAE quantílico escalado pelo valor (ou preço) em percentagem:\", medae_scaled_quantreg)\n"
      ],
      "metadata": {
        "id": "dgpuCY5p1_I5",
        "outputId": "de86e179-0fd9-49f3-ae28-7282c4d2b58b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         QuantReg Regression Results                          \n",
            "==============================================================================\n",
            "Dep. Variable:              VM30Abr11   Pseudo R-squared:               0.7041\n",
            "Model:                       QuantReg   Bandwidth:                   1.101e+06\n",
            "Method:                 Least Squares   Sparsity:                    2.608e+06\n",
            "Date:                Thu, 14 Sep 2023   No. Observations:                  188\n",
            "Time:                        23:13:19   Df Residuals:                      185\n",
            "                                        Df Model:                            2\n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const       2.734e-07    9.7e+04   2.82e-12      1.000   -1.91e+05    1.91e+05\n",
            "PLDez2010      0.3167      0.010     32.294      0.000       0.297       0.336\n",
            "LLDez2010      7.4244      0.070    106.250      0.000       7.287       7.562\n",
            "==============================================================================\n",
            "\n",
            "The condition number is large, 2.54e+07. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n",
            "Median Absolute Error (MedAE) quantílico: 429489.5109996567\n",
            "MedAE quantílico escalado pelo valor (ou preço) em percentagem: 5.207525543586414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ARVORE DE DECISÃO"
      ],
      "metadata": {
        "id": "x6LWJCtFU0Od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PLDez2010', 'LLDez2010']]\n",
        "y = dados['VM30Abr11']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de árvore de decisão com os parâmetros desejados\n",
        "    modelo_arvore = DecisionTreeRegressor(min_samples_split=5, random_state=42)\n",
        "\n",
        "    # Criar o modelo Bagging com 500 árvores\n",
        "    bagging_model = BaggingRegressor(base_estimator=modelo_arvore, n_estimators=500, bootstrap=True, random_state=42)\n",
        "\n",
        "    bagging_model.fit(X_train, y_train)\n",
        "    y_pred = bagging_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar a importância dos coeficientes (importância das variáveis)\n",
        "    importancia_coeficientes = np.mean([tree.feature_importances_ for tree in bagging_model.estimators_], axis=0)\n",
        "    print(\"Importância dos Coeficientes:\", importancia_coeficientes)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6G90UU8W4WZ",
        "outputId": "b7deaefb-8522-4ef8-b768-ff3faec76f57"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.31087793 0.68912207]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.26966413 0.73033587]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.27365315 0.72634685]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.34814187 0.65185813]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.31230977 0.68769023]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.31024623 0.68975377]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.30164173 0.69835827]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.30222298 0.69777702]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.36834952 0.63165048]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [0.33073917 0.66926083]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 14.856151860032648\n",
            "Média do R²: 0.4084875580187829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FLORESTA ALEATÓRIA"
      ],
      "metadata": {
        "id": "OZLbiycNZm26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PLDez2010', 'LLDez2010']]\n",
        "y = dados['VM30Abr11']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de Floresta Aleatória com os parâmetros desejados\n",
        "    random_forest_model = RandomForestRegressor(n_estimators=500, random_state=42)\n",
        "\n",
        "    random_forest_model.fit(X_train, y_train)\n",
        "    y_pred = random_forest_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar a importância das variáveis\n",
        "    importancia_variaveis = random_forest_model.feature_importances_\n",
        "    print(\"Importância das Variáveis:\", importancia_variaveis)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "id": "lpAmsgS7Zph4",
        "outputId": "e4ac3704-4a80-4f0e-954f-9d507c558657",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância das Variáveis: [0.31842794 0.68157206]\n",
            "Importância das Variáveis: [0.30453222 0.69546778]\n",
            "Importância das Variáveis: [0.28855295 0.71144705]\n",
            "Importância das Variáveis: [0.36906466 0.63093534]\n",
            "Importância das Variáveis: [0.33007599 0.66992401]\n",
            "Importância das Variáveis: [0.31355714 0.68644286]\n",
            "Importância das Variáveis: [0.29990677 0.70009323]\n",
            "Importância das Variáveis: [0.33802255 0.66197745]\n",
            "Importância das Variáveis: [0.38840874 0.61159126]\n",
            "Importância das Variáveis: [0.3477504 0.6522496]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 15.23551347039687\n",
            "Média do R²: 0.44605769846916177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRADIENT BOOSTING"
      ],
      "metadata": {
        "id": "gReIxsDPa_9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PLDez2010', 'LLDez2010']]\n",
        "y = dados['VM30Abr11']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de Regressão Gradient Boosting com os parâmetros desejados\n",
        "    gradient_boosting_model = GradientBoostingRegressor(n_estimators=500, random_state=42)\n",
        "\n",
        "    gradient_boosting_model.fit(X_train, y_train)\n",
        "    y_pred = gradient_boosting_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar a importância das variáveis\n",
        "    importancia_variaveis = gradient_boosting_model.feature_importances_\n",
        "    print(\"Importância das Variáveis:\", importancia_variaveis)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "id": "NvfZ3qUAbCf5",
        "outputId": "d2cfe4ce-f14e-43af-c915-0624a5b5c013",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância das Variáveis: [0.06043902 0.93956098]\n",
            "Importância das Variáveis: [0.0600929 0.9399071]\n",
            "Importância das Variáveis: [0.05490082 0.94509918]\n",
            "Importância das Variáveis: [0.49315536 0.50684464]\n",
            "Importância das Variáveis: [0.06078807 0.93921193]\n",
            "Importância das Variáveis: [0.05784883 0.94215117]\n",
            "Importância das Variáveis: [0.05967908 0.94032092]\n",
            "Importância das Variáveis: [0.06168044 0.93831956]\n",
            "Importância das Variáveis: [0.64166641 0.35833359]\n",
            "Importância das Variáveis: [0.06517312 0.93482688]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 14.830985633320406\n",
            "Média do R²: -0.40832224064784056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REDES NEURAIS"
      ],
      "metadata": {
        "id": "Gy8Aqujjc2rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PLDez2010', 'LLDez2010']]\n",
        "y = dados['VM30Abr11']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de regressão de rede neural com os parâmetros desejados\n",
        "    modelo_rede_neural = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
        "\n",
        "    modelo_rede_neural.fit(X_train, y_train)\n",
        "    y_pred = modelo_rede_neural.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "id": "yygOLB39c4OY",
        "outputId": "2782ac2d-31ee-409b-8fdb-776ccd0f8a95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 15.96109313311435\n",
            "Média do R²: 0.3470305530009682\n"
          ]
        }
      ]
    }
  ]
}