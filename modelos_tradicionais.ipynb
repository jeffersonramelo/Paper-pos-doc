{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMCXfMNYg/jxPZIxTqWzY1j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffersonramelo/Paper-pos-doc/blob/main/modelos_tradicionais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Caminho para o arquivo XLSX\n",
        "caminho_arquivo = '/content/2010.xlsx'\n",
        "\n",
        "# Lê o arquivo XLSX\n",
        "dados = pd.read_excel(caminho_arquivo)\n",
        "\n",
        "# Agora, 'dados' contém os dados do arquivo XLSX\n"
      ],
      "metadata": {
        "id": "DOE1GbH_7pjb"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibe as primeiras linhas do DataFrame\n",
        "print(dados.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JswF8j8m8FiD",
        "outputId": "85c7b76c-4ab9-41b8-ed17-41436fad5c33"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID Código    Setor EconômicoB3     VM30Abr11   PLDez2010  LLDez2010  \\\n",
            "0   5  EALT4     Bens industriais  6.072750e+04     45809.0     5927.0   \n",
            "1  21  ALPA4      Consumo cíclico  3.893923e+06   1310475.0   306341.0   \n",
            "2  26  ABEV3  Consumo não cíclico  1.422082e+08  24361863.0  7561383.0   \n",
            "3  28  AMER3      Consumo cíclico  2.382110e+06    225945.0    33587.0   \n",
            "4  29  CBEE3    Utilidade pública  4.773374e+06   1583469.0   216092.0   \n",
            "\n",
            "    ATDez2010   PTDez2010  VM30Abr11esc  PLDez2010esc  LLDez2010esc  \\\n",
            "0    237963.0    192154.0      0.424087      0.319904      0.041391   \n",
            "1   2246603.0    936128.0      2.226423      0.749289      0.175156   \n",
            "2  42678300.0  18316437.0      3.546250      0.607512      0.188558   \n",
            "3   3212014.0   2986069.0      1.024863      0.097209      0.014450   \n",
            "4   4313606.0   2730137.0      1.040166      0.345054      0.047089   \n",
            "\n",
            "   ATDez2010esc  PTDez2010esc   ATDez2009  \n",
            "0      1.661799      1.341895    143196.0  \n",
            "1      1.284537      0.535249   1748959.0  \n",
            "2      1.064270      0.456757  40101017.0  \n",
            "3      1.381916      1.284706   2324320.0  \n",
            "4      0.939978      0.594924   4589050.0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REGRESSÃO SEM ESCALA"
      ],
      "metadata": {
        "id": "_lfctlNuhZs5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tratar outliers: A winsorização ao nível de 1% envolve substituir os 1% dos valores mais extremos por valores no limite do intervalo aceitável, ou seja, os 1% menores e os 1% maiores dos valores."
      ],
      "metadata": {
        "id": "95LYGQCnbVVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats.mstats import winsorize\n",
        "\n",
        "nivel_winsorizacao = 0.01  # 1% de winsorização\n",
        "\n",
        "# Aplica a winsorização às variáveis\n",
        "dados['PLDez2010_winsorizada'] = winsorize(dados['PLDez2010esc'], limits=[nivel_winsorizacao, nivel_winsorizacao])\n",
        "dados['LLDez2010_winsorizada'] = winsorize(dados['LLDez2010esc'], limits=[nivel_winsorizacao, nivel_winsorizacao])\n",
        "dados['VM30Abr11_winsorizada'] = winsorize(dados['VM30Abr11esc'], limits=[nivel_winsorizacao, nivel_winsorizacao])\n",
        "# Variáveis winsorizadas agora contêm os valores winsorizados"
      ],
      "metadata": {
        "id": "bcS1mdNlbcTb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados[['PLDez2010_winsorizada', 'LLDez2010_winsorizada']]\n",
        "y = dados['VM30Abr11_winsorizada']\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão linear\n",
        "modelo = sm.OLS(y, X).fit()\n",
        "\n",
        "# Visualize os resultados do modelo\n",
        "print(modelo.summary())"
      ],
      "metadata": {
        "id": "eUYMK2RnbdGD",
        "outputId": "84c95139-a5f2-4a2a-8fca-2eeb6eb8c56f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                              OLS Regression Results                             \n",
            "=================================================================================\n",
            "Dep. Variable:     VM30Abr11_winsorizada   R-squared:                       0.102\n",
            "Model:                               OLS   Adj. R-squared:                  0.093\n",
            "Method:                    Least Squares   F-statistic:                     10.54\n",
            "Date:                   Thu, 14 Sep 2023   Prob (F-statistic):           4.63e-05\n",
            "Time:                           15:49:51   Log-Likelihood:                -450.56\n",
            "No. Observations:                    188   AIC:                             907.1\n",
            "Df Residuals:                        185   BIC:                             916.8\n",
            "Df Model:                              2                                         \n",
            "Covariance Type:               nonrobust                                         \n",
            "=========================================================================================\n",
            "                            coef    std err          t      P>|t|      [0.025      0.975]\n",
            "-----------------------------------------------------------------------------------------\n",
            "const                     1.7692      0.201      8.782      0.000       1.372       2.167\n",
            "PLDez2010_winsorizada    -0.3840      0.138     -2.778      0.006      -0.657      -0.111\n",
            "LLDez2010_winsorizada    -1.5753      1.614     -0.976      0.330      -4.760       1.610\n",
            "==============================================================================\n",
            "Omnibus:                      199.887   Durbin-Watson:                   2.064\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5600.214\n",
            "Skew:                           4.139   Prob(JB):                         0.00\n",
            "Kurtosis:                      28.424   Cond. No.                         15.7\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em relação aos resultados apresentados no seu modelo de regressão:\n",
        "\n",
        "O valor do teste de Durbin-Watson é 1.676, o que sugere uma leve autocorrelação positiva nos resíduos, mas não muito forte.\n",
        "O valor-p associado ao teste de Jarque-Bera é praticamente zero (0.00), o que indica que os resíduos não seguem uma distribuição normal.\n",
        "\n",
        "Interpretação DW:\n",
        "\n",
        "Valor DW ≈ 2: Ausência de autocorrelação significativa nos resíduos (boa notícia).\n",
        "Valor DW < 2: Autocorrelação positiva nos resíduos (erros adjacentes são correlacionados positivamente).\n",
        "Valor DW > 2: Autocorrelação negativa nos resíduos (erros adjacentes são correlacionados negativamente)."
      ],
      "metadata": {
        "id": "BYoRhNnCeQLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "teste de heterocedasticidade de White. Se o valor-p for menor que um nível de significância escolhido (por exemplo, 0,05), você pode rejeitar a hipótese nula de homocedasticidade"
      ],
      "metadata": {
        "id": "9Zd9X-08b9S_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.diagnostic import het_white\n",
        "\n",
        "# Calcule os resíduos do modelo\n",
        "residuos = modelo.resid\n",
        "\n",
        "# Realize o teste de White para heterocedasticidade\n",
        "teste_white = het_white(residuos, X)\n",
        "\n",
        "# Imprima os resultados do teste\n",
        "print(\"Estatística do teste de White:\", teste_white[0])\n",
        "print(\"Valor-p do teste de White:\", teste_white[1])"
      ],
      "metadata": {
        "id": "ICEs0hnicHRU",
        "outputId": "3c45ce38-be80-434f-e265-18d32aab19db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estatística do teste de White: 113.73736510497207\n",
            "Valor-p do teste de White: 6.642361768007011e-23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "erro absoluto médio (MAE) e erro médio quadrático (MSE)"
      ],
      "metadata": {
        "id": "-lNjj-1DYqxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão linear\n",
        "modelo = sm.OLS(y, X).fit()\n",
        "\n",
        "# Faça previsões com o modelo\n",
        "previsoes = modelo.predict(X)\n",
        "\n",
        "# Calcule o Median Absolute Error (MedAE)\n",
        "medae = np.median(np.abs(y - previsoes))\n",
        "\n",
        "# Calcule o valor médio da variável de resposta\n",
        "valor_medio_y = np.mean(y)\n",
        "\n",
        "# Calcule o MedAE escalado pelo valor (ou preço)\n",
        "medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "# Calcule o Erro Absoluto Médio (MAE)\n",
        "mae = np.mean(np.abs(y - previsoes))\n",
        "\n",
        "# Calcule o Erro Médio Quadrático (MSE)\n",
        "mse = np.mean((y - previsoes) ** 2)\n",
        "\n",
        "# Calcule a Raiz do Erro Quadrático Médio (RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Median Absolute Error (MedAE):\", medae)\n",
        "print(\"MedAE escalado pelo valor (ou preço) em percentagem:\", medae_scaled)\n",
        "print(\"Erro Absoluto Médio (MAE):\", mae)\n",
        "print(\"Erro Médio Quadrático (MSE):\", mse)\n",
        "print(\"Raiz do Erro Quadrático Médio (RMSE):\", rmse)\n"
      ],
      "metadata": {
        "id": "ofykdFz56YXe",
        "outputId": "3acd4033-7d8c-43f4-836a-8c35e1dc01bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Median Absolute Error (MedAE): 0.907334942505559\n",
            "MedAE escalado pelo valor (ou preço) em percentagem: 56.79161460647346\n",
            "Erro Absoluto Médio (MAE): 1.3779344200822823\n",
            "Erro Médio Quadrático (MSE): 7.066169255778478\n",
            "Raiz do Erro Quadrático Médio (RMSE): 2.6582267126372945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesse caso específico, o valor de 17.74% indica que, em média, as previsões do modelo estão erradas em cerca de 17.74% do valor médio (ou preço) da variável de resposta. Isso ajuda a ter uma ideia do tamanho relativo dos erros do modelo em relação ao valor médio dos dados."
      ],
      "metadata": {
        "id": "YWiLqzmM7ERc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "minimos quadrados ponderados, com pesos com base na variância dos erros"
      ],
      "metadata": {
        "id": "Vmo8zEDpLVRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados[['PLDez2010', 'LLDez2010']]\n",
        "y = dados['VM30Abr11']\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão linear\n",
        "modelo = sm.OLS(y, X).fit()\n",
        "\n",
        "# Calcule os resíduos (erros)\n",
        "residuos = modelo.resid\n",
        "\n",
        "# Calcule a variância dos resíduos\n",
        "variancia_residuos = np.var(residuos)\n",
        "\n",
        "# Calcule os pesos com base na variância dos resíduos (inverso da variância)\n",
        "pesos = 1 / variancia_residuos\n",
        "\n",
        "# Crie o modelo de regressão linear ponderada (WLS) com os pesos calculados\n",
        "modelo_wls = sm.WLS(y, X, weights=pesos).fit()\n",
        "\n",
        "# Visualize os resultados do modelo ponderado\n",
        "print(modelo_wls.summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gfcj59gNQlc",
        "outputId": "3c6fc954-f955-473d-df50-f284d1823e66"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            WLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:              VM30Abr11   R-squared:                       0.963\n",
            "Model:                            WLS   Adj. R-squared:                  0.963\n",
            "Method:                 Least Squares   F-statistic:                     2411.\n",
            "Date:                Thu, 14 Sep 2023   Prob (F-statistic):          3.13e-133\n",
            "Time:                        13:30:10   Log-Likelihood:                -3216.0\n",
            "No. Observations:                 188   AIC:                             6438.\n",
            "Df Residuals:                     185   BIC:                             6448.\n",
            "Df Model:                           2                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const       1.752e+06   4.87e+05      3.595      0.000    7.91e+05    2.71e+06\n",
            "PLDez2010      0.1983      0.049      4.023      0.000       0.101       0.296\n",
            "LLDez2010      8.4291      0.351     24.002      0.000       7.736       9.122\n",
            "==============================================================================\n",
            "Omnibus:                      302.482   Durbin-Watson:                   2.045\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            49384.538\n",
            "Skew:                           7.451   Prob(JB):                         0.00\n",
            "Kurtosis:                      80.989   Cond. No.                     2.54e+07\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is 4.28e-12. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão linear ponderada (WLS) com os pesos calculados\n",
        "modelo_wls = sm.WLS(y, X, weights=pesos).fit()\n",
        "\n",
        "# Faça previsões com o modelo\n",
        "previsoes = modelo_wls.predict(X)\n",
        "\n",
        "# Calcule o Median Absolute Error (MedAE)\n",
        "medae = np.median(np.abs(y - previsoes))\n",
        "\n",
        "# Calcule o valor médio da variável de resposta\n",
        "valor_medio_y = np.mean(y)\n",
        "\n",
        "# Calcule o MedAE escalado pelo valor (ou preço)\n",
        "medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "# Calcule o Erro Absoluto Médio (MAE)\n",
        "mae = np.mean(np.abs(y - previsoes))\n",
        "\n",
        "# Calcule o Erro Médio Quadrático (MSE)\n",
        "mse = np.mean((y - previsoes) ** 2)\n",
        "\n",
        "# Calcule a Raiz do Erro Quadrático Médio (RMSE)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "print(\"Median Absolute Error (MedAE):\", medae)\n",
        "print(\"MedAE escalado pelo valor (ou preço) em percentagem:\", medae_scaled)\n",
        "print(\"Erro Absoluto Médio (MAE):\", mae)\n",
        "print(\"Erro Médio Quadrático (MSE):\", mse)\n",
        "print(\"Raiz do Erro Quadrático Médio (RMSE):\", rmse)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svQj7pwx5dry",
        "outputId": "3eb3775d-1643-4018-9339-c3120088c786"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Median Absolute Error (MedAE): 1710616.3343900286\n",
            "MedAE escalado pelo valor (ou preço) em percentagem: 20.74108453982559\n",
            "Erro Absoluto Médio (MAE): 2842520.7540884106\n",
            "Erro Médio Quadrático (MSE): 42280004974664.125\n",
            "Raiz do Erro Quadrático Médio (RMSE): 6502307.665334217\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ESTIMAÇÃO FORA DA AMOSTRA MQO"
      ],
      "metadata": {
        "id": "0vo_AkMGd9Jk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_val_predict, KFold\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependentes\n",
        "X = dados[['PL Dez 2010', 'LLDez 2010']]\n",
        "y = dados['VM30Abr11']\n",
        "\n",
        "# Converta os dados para matrizes NumPy\n",
        "X = X.to_numpy()\n",
        "y = y.to_numpy()\n",
        "\n",
        "# Crie o modelo de regressão linear\n",
        "modelo = sm.OLS(y, X)\n",
        "\n",
        "# Defina a validação cruzada de 10-fold\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Lista para armazenar as métricas de MedAE escalado pelo valor (ou preço) em percentagem\n",
        "medae_scaled_scores = []\n",
        "\n",
        "# Realize a validação cruzada e calcule as métricas em cada fold\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    modelo_fold = modelo.fit()\n",
        "    y_pred = modelo_fold.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scaled_scores.append(medae_scaled)\n",
        "\n",
        "# Calcule a média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scaled_scores)\n",
        "\n",
        "# Imprima a média do R² e do MedAE escalado\n",
        "print(f'Média do R²: {mean_r2_score}')\n",
        "print(f'Média do MedAE escalado pelo valor (ou preço) em percentagem: {mean_medae_scaled}')\n"
      ],
      "metadata": {
        "id": "Wr21kssWeHXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ARVORE DE DECISÃO_dentro da amostra"
      ],
      "metadata": {
        "id": "YS45zrNJY5qs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PLDez2010', 'LLDez2010']]\n",
        "y = dados['VM30Abr11']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Criar o modelo de árvore de decisão com os parâmetros desejados\n",
        "modelo_arvore = DecisionTreeRegressor(min_samples_split=5, random_state=42)\n",
        "\n",
        "# Criar o modelo Bagging com 500 árvores\n",
        "bagging_model = BaggingRegressor(base_estimator=modelo_arvore, n_estimators=500, bootstrap=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    bagging_model.fit(X_train, y_train)\n",
        "    y_pred = bagging_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CTjZoPNY7Ug",
        "outputId": "f1409cf4-70e9-49df-ca03-056ed1549d4a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 14.856151860032648\n",
            "Média do R²: 0.4084875580187829\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ARVORE DE DECISÃO FORA DA AMOSTRA"
      ],
      "metadata": {
        "id": "GUxdnCz6bo-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PLDez2010', 'LLDez2010']]\n",
        "y = dados['VM30Abr11']\n",
        "\n",
        "# Dividir os dados em conjunto de treinamento e teste (80% treinamento, 20% teste)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Criar o modelo de árvore de decisão com os parâmetros desejados\n",
        "modelo_arvore = DecisionTreeRegressor(min_samples_split=5, random_state=42)\n",
        "\n",
        "# Criar o modelo Bagging com 500 árvores\n",
        "bagging_model = BaggingRegressor(base_estimator=modelo_arvore, n_estimators=500, bootstrap=True, random_state=42)\n",
        "\n",
        "# Treinar o modelo no conjunto de treinamento\n",
        "bagging_model.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsões no conjunto de teste\n",
        "y_pred = bagging_model.predict(X_test)\n",
        "\n",
        "# Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "medae = np.median(np.abs(y_test - y_pred))\n",
        "valor_medio_y = np.mean(y_test)\n",
        "medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "# Calcular o R²\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Exibir resultados\n",
        "print(\"MedAE escalado pelo valor (ou preço) em percentagem:\", medae_scaled)\n",
        "print(\"R²:\", r2)\n"
      ],
      "metadata": {
        "id": "skIUnsnQbomO",
        "outputId": "8db65c47-fe3e-4951-aa2b-3d063d19848b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MedAE escalado pelo valor (ou preço) em percentagem: 18.42446864752979\n",
            "R²: 0.7630562414726623\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SUPORTE VECTOR REGRESSION DENTRO DA AMOSTRA"
      ],
      "metadata": {
        "id": "LmoKRnbJyT08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PLDez2010', 'LLDez2010']]\n",
        "y = dados['VM30Abr11']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Criar o modelo SVR com os parâmetros desejados\n",
        "svr_model = SVR(kernel='linear', C=1.0)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    svr_model.fit(X_train, y_train)\n",
        "    y_pred = svr_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "id": "OR8kNOvCySG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SUPORTE VECTOR REGRESSION FORA DA AMOSTRA"
      ],
      "metadata": {
        "id": "_TDCktDSyqNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados[['PLDez2010', 'LLDez2010']]\n",
        "y = dados['VM30Abr11']\n",
        "\n",
        "# Dividir os dados em conjunto de treinamento e teste (80% treinamento, 20% teste)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Criar o modelo SVR com os parâmetros desejados\n",
        "svr_model = SVR(kernel='linear', C=1.0)\n",
        "\n",
        "# Treinar o modelo no conjunto de treinamento\n",
        "svr_model.fit(X_train, y_train)\n",
        "\n",
        "# Fazer previsões no conjunto de teste\n",
        "y_pred = svr_model.predict(X_test)\n",
        "\n",
        "# Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "medae = np.median(np.abs(y_test - y_pred))\n",
        "valor_medio_y = np.mean(y_test)\n",
        "medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "# Calcular o R²\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Exibir resultados\n",
        "print(\"MedAE escalado pelo valor (ou preço) em percentagem:\", medae_scaled)\n",
        "print(\"R²:\", r2)\n"
      ],
      "metadata": {
        "id": "4gvz8JY6yuER",
        "outputId": "5c40d59b-4dd3-4d16-c829-5069ef4a3d47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MedAE escalado pelo valor (ou preço) em percentagem: 25.92721366061097\n",
            "R²: -0.10119344188688628\n"
          ]
        }
      ]
    }
  ]
}