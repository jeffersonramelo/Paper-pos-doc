{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMelRcaYyja+gyXWZ0Qe39Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffersonramelo/Paper-pos-doc/blob/main/modelos_tradicionais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Caminho para o arquivo XLSX\n",
        "caminho_arquivo = '/content/Jefferson - Dados3 - Copia.xlsx'\n",
        "\n",
        "# Lê o arquivo XLSX\n",
        "dados = pd.read_excel(caminho_arquivo)\n",
        "\n",
        "# Agora, 'dados' contém os dados do arquivo XLSX\n"
      ],
      "metadata": {
        "id": "DOE1GbH_7pjb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar o conteúdo do DataFrame \"dados\"\n",
        "print(dados)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5DK3CKBghzv",
        "outputId": "70e2fe4c-2eb7-474a-f1df-c349fcfbda23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id     COD              SETOR  d1  d2  d3  d4  d5  d6  d7  ...  \\\n",
            "3      4   ABCB4         Financeiro   0   0   0   0   0   0   0  ...   \n",
            "4      5   EALT4   Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "8      9   AFLT3  Utilidade pública   0   0   0   1   0   0   0  ...   \n",
            "11    12  BRGE12         Financeiro   0   0   0   0   0   0   0  ...   \n",
            "12    13   CRIV4         Financeiro   0   0   0   0   0   0   0  ...   \n",
            "..   ...     ...                ...  ..  ..  ..  ..  ..  ..  ..  ...   \n",
            "386  388   MWET4   Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "387  389   WHRL4    Consumo cíclico   0   1   0   0   0   0   0  ...   \n",
            "388  390   PORT3   Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "390  392   WLMM4   Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "392  394   YDUQ3    Consumo cíclico   0   1   0   0   0   0   0  ...   \n",
            "\n",
            "      ORA2013        ORA2014        ORA2015        ORA2016        ORA2017  \\\n",
            "3   -5440.345 -142816.729785 -254434.460868 -206297.998359 -137394.689307   \n",
            "4       0.000       0.000000       0.000000       0.000000       0.000000   \n",
            "8       0.000       0.000000       0.000000       0.000000       0.000000   \n",
            "11      0.000       0.000000       0.000000       0.000000       0.000000   \n",
            "12      0.000       0.000000       0.000000       0.000000       0.000000   \n",
            "..        ...            ...            ...            ...            ...   \n",
            "386     0.000       0.000000       0.000000       0.000000       0.000000   \n",
            "387     0.000       0.000000       0.000000       0.000000       0.000000   \n",
            "388     0.000       0.000000       0.000000       0.000000       0.000000   \n",
            "390     0.000       0.000000       0.000000       0.000000       0.000000   \n",
            "392     0.000       0.000000       0.000000       0.000000       0.000000   \n",
            "\n",
            "           ORA2018        ORA2019       ORA2020       ORA2021      ORA2022  \n",
            "3   -196080.157023 -243922.349606 -227484.43583 -51106.424082   -7121.3714  \n",
            "4         0.000000       0.000000       0.00000      0.000000       0.0000  \n",
            "8         0.000000       0.000000       0.00000      0.000000       0.0000  \n",
            "11        0.000000       0.000000       0.00000      0.000000       0.0000  \n",
            "12        0.000000       0.000000       0.00000      0.000000       0.0000  \n",
            "..             ...            ...           ...           ...          ...  \n",
            "386       0.000000       0.000000       0.00000      0.000000       0.0000  \n",
            "387       0.000000       0.000000       0.00000      0.000000       0.0000  \n",
            "388       0.000000       0.000000       0.00000      0.000000  723446.0000  \n",
            "390       0.000000       0.000000  102837.00000  99077.000000   98279.0000  \n",
            "392       0.000000       0.000000       0.00000      0.000000       0.0000  \n",
            "\n",
            "[233 rows x 150 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "excluir setor financeiro e empresas com PL negativo"
      ],
      "metadata": {
        "id": "kEKhC6-Wf6ro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agora, vamos remover as linhas onde 'd9' seja igual a 1\n",
        "dados = dados[dados['d9'] != 1]\n",
        "\n",
        "# A partir deste ponto, 'dados' conterá apenas as linhas onde 'd9' não é igual a 1\n",
        "print(dados)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cQ_iqhOf9H_",
        "outputId": "b40d6d28-a2aa-411c-d650-883b300821e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id     COD                           SETOR  d1  d2  d3  d4  d5  d6  d7  \\\n",
            "0      1   RRRP3  Petróleo gás e biocombustíveis   0   0   0   0   0   1   0   \n",
            "1      2   TTEN3             Consumo não cíclico   0   0   1   0   0   0   0   \n",
            "2      3  QVQP3B                          Outros   0   0   0   0   0   0   0   \n",
            "4      5   EALT4                Bens industriais   1   0   0   0   0   0   0   \n",
            "5      6   AERI3                Bens industriais   1   0   0   0   0   0   0   \n",
            "..   ...     ...                             ...  ..  ..  ..  ..  ..  ..  ..   \n",
            "388  390   PORT3                Bens industriais   1   0   0   0   0   0   0   \n",
            "390  392   WLMM4                Bens industriais   1   0   0   0   0   0   0   \n",
            "391  393   YBRA3                          Outros   0   0   0   0   0   0   0   \n",
            "392  394   YDUQ3                 Consumo cíclico   0   1   0   0   0   0   0   \n",
            "393  395   ZAMP3                 Consumo cíclico   0   1   0   0   0   0   0   \n",
            "\n",
            "     ...  ORA2013  ORA2014 ORA2015 ORA2016 ORA2017 ORA2018 ORA2019 ORA2020  \\\n",
            "0    ...        -        -       -       -       0       0       0       0   \n",
            "1    ...        -        -       -       -       -       -       -       0   \n",
            "2    ...        0        0       0       0       0       0       0       0   \n",
            "4    ...        0        0       0       0       0       0       0       0   \n",
            "5    ...        -        -       -       -       0       0       0       0   \n",
            "..   ...      ...      ...     ...     ...     ...     ...     ...     ...   \n",
            "388  ...        0        0       0       0       0       0       0       0   \n",
            "390  ...        0        0       0       0       0       0       0  102837   \n",
            "391  ...        0        0       0       0       0       0       0       0   \n",
            "392  ...        0        0       0       0       0       0       0       0   \n",
            "393  ...        -        0       0       0       0      -2      17     300   \n",
            "\n",
            "    ORA2021 ORA2022  \n",
            "0         0       0  \n",
            "1         0       0  \n",
            "2         0       0  \n",
            "4         0       0  \n",
            "5         0       0  \n",
            "..      ...     ...  \n",
            "388       0  723446  \n",
            "390   99077   98279  \n",
            "391       0       0  \n",
            "392       0       0  \n",
            "393     147       0  \n",
            "\n",
            "[336 rows x 150 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converte a coluna 'PL2010' para números (float) e remove as linhas onde 'PL2010' seja negativo\n",
        "dados['PL2010'] = pd.to_numeric(dados['PL2010'], errors='coerce')  # 'coerce' trata strings não numéricas como NaN\n",
        "dados = dados[dados['PL2010'] >= 0]\n",
        "\n",
        "# A partir deste ponto, 'dados' conterá apenas as linhas onde 'd9' não é igual a 1\n",
        "print(dados)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3PUXYCZ78ba",
        "outputId": "0c0aad18-a6ff-4602-e7ad-1361bb7a396a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id     COD                SETOR  d1  d2  d3  d4  d5  d6  d7  ...  \\\n",
            "2      3  QVQP3B               Outros   0   0   0   0   0   0   0  ...   \n",
            "4      5   EALT4     Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "6      7   AESB3    Utilidade pública   0   0   0   1   0   0   0  ...   \n",
            "8      9   AFLT3    Utilidade pública   0   0   0   1   0   0   0  ...   \n",
            "16    17   APTI4  Consumo não cíclico   0   0   1   0   0   0   0  ...   \n",
            "..   ...     ...                  ...  ..  ..  ..  ..  ..  ..  ..  ...   \n",
            "387  389   WHRL4      Consumo cíclico   0   1   0   0   0   0   0  ...   \n",
            "388  390   PORT3     Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "390  392   WLMM4     Bens industriais   1   0   0   0   0   0   0  ...   \n",
            "391  393   YBRA3               Outros   0   0   0   0   0   0   0  ...   \n",
            "392  394   YDUQ3      Consumo cíclico   0   1   0   0   0   0   0  ...   \n",
            "\n",
            "     ORA2013  ORA2014 ORA2015 ORA2016 ORA2017 ORA2018 ORA2019 ORA2020  \\\n",
            "2          0        0       0       0       0       0       0       0   \n",
            "4          0        0       0       0       0       0       0       0   \n",
            "6     489138   388514  923107   -3289    1394  -14697  -59906  532895   \n",
            "8          0        0       0       0       0       0       0       0   \n",
            "16         0        0       0       0       0       0       0       0   \n",
            "..       ...      ...     ...     ...     ...     ...     ...     ...   \n",
            "387        0        0       0       0       0       0       0       0   \n",
            "388        0        0       0       0       0       0       0       0   \n",
            "390        0        0       0       0       0       0       0  102837   \n",
            "391        0        0       0       0       0       0       0       0   \n",
            "392        0        0       0       0       0       0       0       0   \n",
            "\n",
            "     ORA2021  ORA2022  \n",
            "2          0        0  \n",
            "4          0        0  \n",
            "6    -153563  -155638  \n",
            "8          0        0  \n",
            "16         0        0  \n",
            "..       ...      ...  \n",
            "387        0        0  \n",
            "388        0   723446  \n",
            "390    99077    98279  \n",
            "391        0        0  \n",
            "392        0        0  \n",
            "\n",
            "[209 rows x 150 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "excluir valores ausentes na variável dependente"
      ],
      "metadata": {
        "id": "HPTV8NDAhkT2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agora, vamos remover as linhas onde 'VM30Abril11' seja igual a '-'\n",
        "dados = dados[dados['VM30Abril2011'] != '-']\n",
        "\n",
        "# A partir deste ponto, 'dados' conterá apenas as linhas onde 'VM30Abril11' não é igual a '-'\n",
        "print(dados)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPddSXYKho22",
        "outputId": "2b2166f5-84d3-4081-ff63-33c58086e9ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id     COD              SETOR  d1  d2  d3  d4  d5  d6  d7  ...  ORA2013  \\\n",
            "3      4   ABCB4         Financeiro   0   0   0   0   0   0   0  ...        -   \n",
            "4      5   EALT4   Bens industriais   1   0   0   0   0   0   0  ...        0   \n",
            "8      9   AFLT3  Utilidade pública   0   0   0   1   0   0   0  ...        0   \n",
            "11    12  BRGE12         Financeiro   0   0   0   0   0   0   0  ...        0   \n",
            "12    13   CRIV4         Financeiro   0   0   0   0   0   0   0  ...        0   \n",
            "..   ...     ...                ...  ..  ..  ..  ..  ..  ..  ..  ...      ...   \n",
            "386  388   MWET4   Bens industriais   1   0   0   0   0   0   0  ...        0   \n",
            "387  389   WHRL4    Consumo cíclico   0   1   0   0   0   0   0  ...        0   \n",
            "388  390   PORT3   Bens industriais   1   0   0   0   0   0   0  ...        0   \n",
            "390  392   WLMM4   Bens industriais   1   0   0   0   0   0   0  ...        0   \n",
            "392  394   YDUQ3    Consumo cíclico   0   1   0   0   0   0   0  ...        0   \n",
            "\n",
            "     ORA2014 ORA2015 ORA2016 ORA2017 ORA2018 ORA2019 ORA2020 ORA2021 ORA2022  \n",
            "3          -       -       -       -       -       -       -       -       -  \n",
            "4          0       0       0       0       0       0       0       0       0  \n",
            "8          0       0       0       0       0       0       0       0       0  \n",
            "11         0       0       0       0       0       0       0       0       0  \n",
            "12         0       0       0       0       0       0       0       0       0  \n",
            "..       ...     ...     ...     ...     ...     ...     ...     ...     ...  \n",
            "386        0       0       0       0       0       0       0       0       0  \n",
            "387        0       0       0       0       0       0       0       0       0  \n",
            "388        0       0       0       0       0       0       0       0  723446  \n",
            "390        0       0       0       0       0       0  102837   99077   98279  \n",
            "392        0       0       0       0       0       0       0       0       0  \n",
            "\n",
            "[233 rows x 150 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tratar valores ausentes substituindo pela média da coluna"
      ],
      "metadata": {
        "id": "tSBa2W135L_Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que seu DataFrame se chame \"dados\"\n",
        "\n",
        "# Substituir apenas traços (\"-\") e valores em branco por NaN\n",
        "dados = dados.replace(['-',''], np.nan)\n",
        "\n",
        "# Calcular a média de todas as colunas, ignorando os valores NaN\n",
        "media_por_coluna = dados.mean(numeric_only=True)\n",
        "\n",
        "# Preencher os valores ausentes em todas as colunas com a média de cada coluna\n",
        "dados.fillna(media_por_coluna, inplace=True)\n"
      ],
      "metadata": {
        "id": "jlrJKMff7WNL"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tratar outliers: A winsorização ao nível de 1% envolve substituir os 1% dos valores mais extremos por valores no limite do intervalo aceitável, ou seja, os 1% menores e os 1% maiores dos valores."
      ],
      "metadata": {
        "id": "95LYGQCnbVVn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import mstats\n",
        "\n",
        "# Supondo que seu DataFrame se chame \"dados\"\n",
        "\n",
        "# Lista de variáveis para winsorizar\n",
        "variaveis_winsorizar = ['VM30Abril2011', 'PL2010', 'LL2010', 'INTANG2010',\n",
        "                        'CAXEEQUIV2010', 'CREC2010', 'REC2010', 'CAXOP2010', 'ORA2010']\n",
        "\n",
        "# Aplicar winsorização de 1% nas variáveis\n",
        "for coluna in variaveis_winsorizar:\n",
        "    dados[coluna] = mstats.winsorize(dados[coluna], limits=[0.01, 0.01])\n",
        "\n",
        "# Agora, as variáveis especificadas foram winsorizadas\n"
      ],
      "metadata": {
        "id": "bcS1mdNlbcTb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "REGRESSÃO SEM ESCALA _ MODELO SIMPLES"
      ],
      "metadata": {
        "id": "f1IWhxH2BV5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão linear\n",
        "modelo = sm.OLS(y, X).fit()\n",
        "\n",
        "# Visualize os resultados do modelo\n",
        "print(modelo.summary())\n",
        "\n",
        "# Calcule o MedAE\n",
        "y_pred = modelo.predict(X)\n",
        "medae = np.median(np.abs(y - y_pred))\n",
        "\n",
        "# Calcule o valor médio da variável de resposta\n",
        "valor_medio_y = np.mean(y)\n",
        "\n",
        "# Calcule o MedAE escalado pelo valor (ou preço)\n",
        "medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "print(\"Median Absolute Error (MedAE):\", medae)\n",
        "print(\"MedAE escalado pelo valor (ou preço) em percentagem:\", medae_scaled)\n"
      ],
      "metadata": {
        "outputId": "49917f20-acd2-4931-e0b1-ad3b1b234fcc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2RXQ4HUBd-S"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:          VM30Abril2011   R-squared:                       0.202\n",
            "Model:                            OLS   Adj. R-squared:                  0.166\n",
            "Method:                 Least Squares   F-statistic:                     5.611\n",
            "Date:                Thu, 21 Sep 2023   Prob (F-statistic):           1.82e-07\n",
            "Time:                        00:13:30   Log-Likelihood:                -4250.3\n",
            "No. Observations:                 233   AIC:                             8523.\n",
            "Df Residuals:                     222   BIC:                             8561.\n",
            "Df Model:                          10                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const      -1.016e+07   5.55e+06     -1.830      0.069   -2.11e+07    7.81e+05\n",
            "PL2010      8.007e+05   4.69e+05      1.708      0.089   -1.23e+05    1.72e+06\n",
            "LL2010      1.229e+06   3.86e+05      3.188      0.002    4.69e+05    1.99e+06\n",
            "d1         -8.674e+06   4.55e+06     -1.907      0.058   -1.76e+07    2.91e+05\n",
            "d2          -8.96e+06   4.18e+06     -2.144      0.033   -1.72e+07   -7.25e+05\n",
            "d3          4.712e+06   5.94e+06      0.793      0.429      -7e+06    1.64e+07\n",
            "d4         -8.201e+06   4.67e+06     -1.758      0.080   -1.74e+07    9.93e+05\n",
            "d5          -3.21e+05   5.29e+06     -0.061      0.952   -1.08e+07    1.01e+07\n",
            "d6          1.669e+07   8.08e+06      2.064      0.040    7.56e+05    3.26e+07\n",
            "d7         -7.872e+06   7.56e+06     -1.041      0.299   -2.28e+07    7.03e+06\n",
            "d8         -7.761e+06   1.24e+07     -0.626      0.532   -3.22e+07    1.67e+07\n",
            "==============================================================================\n",
            "Omnibus:                      245.018   Durbin-Watson:                   1.953\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6023.192\n",
            "Skew:                           4.414   Prob(JB):                         0.00\n",
            "Kurtosis:                      26.291   Cond. No.                         161.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "Median Absolute Error (MedAE): 5553518.0853379695\n",
            "MedAE escalado pelo valor (ou preço) em percentagem: 70.76358662791358\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REGRESSÃO SEM ESCALA _ MODELO COMPLEXO"
      ],
      "metadata": {
        "id": "65Djf3cL9jTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'INTANG2010',\n",
        "                        'CAXEEQUIV2010', 'CREC2010', 'REC2010', 'CAXOP2010', 'ORA2010']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão linear\n",
        "modelo = sm.OLS(y, X).fit()\n",
        "\n",
        "# Visualize os resultados do modelo\n",
        "print(modelo.summary())\n",
        "\n",
        "# Calcule o MedAE\n",
        "y_pred = modelo.predict(X)\n",
        "medae = np.median(np.abs(y - y_pred))\n",
        "\n",
        "# Calcule o valor médio da variável de resposta\n",
        "valor_medio_y = np.mean(y)\n",
        "\n",
        "# Calcule o MedAE escalado pelo valor (ou preço)\n",
        "medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "print(\"Median Absolute Error (MedAE):\", medae)\n",
        "print(\"MedAE escalado pelo valor (ou preço) em percentagem:\", medae_scaled)\n"
      ],
      "metadata": {
        "id": "eUYMK2RnbdGD",
        "outputId": "25815587-82f5-49d3-d313-9bc8f8e02862",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:          VM30Abril2011   R-squared:                       0.241\n",
            "Model:                            OLS   Adj. R-squared:                  0.185\n",
            "Method:                 Least Squares   F-statistic:                     4.296\n",
            "Date:                Thu, 21 Sep 2023   Prob (F-statistic):           2.86e-07\n",
            "Time:                        00:14:54   Log-Likelihood:                -4244.4\n",
            "No. Observations:                 233   AIC:                             8523.\n",
            "Df Residuals:                     216   BIC:                             8582.\n",
            "Df Model:                          16                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "=================================================================================\n",
            "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
            "---------------------------------------------------------------------------------\n",
            "const         -1.804e+07   7.26e+06     -2.486      0.014   -3.23e+07   -3.74e+06\n",
            "PL2010         2.342e+05   5.27e+05      0.444      0.657   -8.04e+05    1.27e+06\n",
            "LL2010         7.969e+05   4.26e+05      1.871      0.063   -4.26e+04    1.64e+06\n",
            "d1            -8.485e+06    4.7e+06     -1.805      0.073   -1.78e+07    7.82e+05\n",
            "d2            -8.759e+06   4.38e+06     -1.998      0.047   -1.74e+07    -1.2e+05\n",
            "d3             4.314e+06   6.05e+06      0.714      0.476    -7.6e+06    1.62e+07\n",
            "d4            -9.564e+06   4.77e+06     -2.003      0.046    -1.9e+07   -1.54e+05\n",
            "d5             -9.11e+05   5.47e+06     -0.167      0.868   -1.17e+07    9.87e+06\n",
            "d6             1.674e+07   8.21e+06      2.039      0.043     5.6e+05    3.29e+07\n",
            "d7             -7.44e+06   7.62e+06     -0.977      0.330   -2.25e+07    7.58e+06\n",
            "d8            -6.234e+06   1.24e+07     -0.502      0.616   -3.07e+07    1.82e+07\n",
            "INTANG2010     1.967e+05   4.09e+05      0.481      0.631   -6.08e+05       1e+06\n",
            "CAXEEQUIV2010  5.391e+05   7.59e+05      0.710      0.478   -9.57e+05    2.04e+06\n",
            "CREC2010      -6.546e+05   1.94e+06     -0.338      0.736   -4.47e+06    3.16e+06\n",
            "REC2010        1.238e+05   6.57e+05      0.188      0.851   -1.17e+06    1.42e+06\n",
            "CAXOP2010      8.392e+05   4.32e+05      1.942      0.053   -1.26e+04    1.69e+06\n",
            "ORA2010        4.594e+05   3.96e+05      1.161      0.247   -3.21e+05    1.24e+06\n",
            "==============================================================================\n",
            "Omnibus:                      240.953   Durbin-Watson:                   1.967\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5801.720\n",
            "Skew:                           4.303   Prob(JB):                         0.00\n",
            "Kurtosis:                      25.881   Cond. No.                         284.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "Median Absolute Error (MedAE): 5662800.298844765\n",
            "MedAE escalado pelo valor (ou preço) em percentagem: 72.15607356386055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em relação aos resultados apresentados no seu modelo de regressão:\n",
        "\n",
        "O valor do teste de Durbin-Watson é 1.676, o que sugere uma leve autocorrelação positiva nos resíduos, mas não muito forte.\n",
        "O valor-p associado ao teste de Jarque-Bera é praticamente zero (0.00), o que indica que os resíduos não seguem uma distribuição normal.\n",
        "\n",
        "Interpretação DW:\n",
        "\n",
        "Valor DW ≈ 2: Ausência de autocorrelação significativa nos resíduos (boa notícia).\n",
        "Valor DW < 2: Autocorrelação positiva nos resíduos (erros adjacentes são correlacionados positivamente).\n",
        "Valor DW > 2: Autocorrelação negativa nos resíduos (erros adjacentes são correlacionados negativamente)."
      ],
      "metadata": {
        "id": "BYoRhNnCeQLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nesse caso específico, o valor de 17.74% indica que, em média, as previsões do modelo estão erradas em cerca de 17.74% do valor médio (ou preço) da variável de resposta. Isso ajuda a ter uma ideia do tamanho relativo dos erros do modelo em relação ao valor médio dos dados."
      ],
      "metadata": {
        "id": "SzP6fpN084-3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Caculo do VIF para multicolinearidade - valores acima de 1,5 ou 2 geralmente levantam preocupações"
      ],
      "metadata": {
        "id": "BkwA7_gg6UOc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8']]\n",
        "\n",
        "# Adicione uma coluna constante para o cálculo do VIF\n",
        "X = pd.concat([pd.Series(1, index=X.index, name='const'), X], axis=1)\n",
        "\n",
        "# Calcular o VIF para cada variável independente\n",
        "vif_data = pd.DataFrame()\n",
        "vif_data[\"Variável\"] = X.columns\n",
        "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "\n",
        "# Exibir os resultados\n",
        "print(vif_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTxnuDmr6Yji",
        "outputId": "30bd3c34-7776-462e-9d7f-bde653197c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Variável        VIF\n",
            "0     const  16.702550\n",
            "1    PL2010   1.859448\n",
            "2    LL2010   1.854578\n",
            "3        d1   1.531467\n",
            "4        d2   1.663845\n",
            "5        d3   1.296102\n",
            "6        d4   1.506356\n",
            "7        d5   1.351448\n",
            "8        d6   1.174862\n",
            "9        d7   1.151338\n",
            "10       d8   1.058612\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlação - Alta pode implicar em multicolinearidade"
      ],
      "metadata": {
        "id": "2CeJcN3D-LL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correlacao = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'INTANG2010', 'CAXEEQUIV2010', 'CREC2010', 'REC2010', 'CAXOP2010', 'ORA2010']].corr()\n",
        "\n",
        "# Exibir a matriz de correlação\n",
        "print(correlacao)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3O5noDU-Ps0",
        "outputId": "36d42d45-6b57-4aae-9864-96cb986fb13e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 PL2010    LL2010        d1        d2        d3        d4  \\\n",
            "PL2010         1.000000  0.649435 -0.104438 -0.102511 -0.032110  0.138777   \n",
            "LL2010         0.649435  1.000000 -0.011246 -0.034078 -0.113490  0.044667   \n",
            "d1            -0.104438 -0.011246  1.000000 -0.239539 -0.123843 -0.185599   \n",
            "d2            -0.102511 -0.034078 -0.239539  1.000000 -0.152230 -0.228141   \n",
            "d3            -0.032110 -0.113490 -0.123843 -0.152230  1.000000 -0.117950   \n",
            "d4             0.138777  0.044667 -0.185599 -0.228141 -0.117950  1.000000   \n",
            "d5             0.084391  0.039364 -0.146093 -0.179579 -0.092844 -0.139141   \n",
            "d6             0.011686 -0.122869 -0.083239 -0.102319 -0.052899 -0.079278   \n",
            "d7            -0.054424  0.001839 -0.088485 -0.108767 -0.056233 -0.084275   \n",
            "d8             0.002960 -0.047804 -0.050416 -0.061972 -0.032040 -0.048017   \n",
            "INTANG2010     0.468068  0.345837 -0.113593 -0.137554  0.046607  0.192964   \n",
            "CAXEEQUIV2010  0.632350  0.470082 -0.136538 -0.097948 -0.008727  0.102123   \n",
            "CREC2010      -0.047691 -0.092361 -0.056957 -0.006710  0.082378 -0.095125   \n",
            "REC2010        0.541393  0.438128 -0.065597 -0.023006  0.069255  0.134093   \n",
            "CAXOP2010      0.497192  0.602703 -0.005899 -0.008485 -0.083578  0.088743   \n",
            "ORA2010        0.149149  0.061237 -0.055663 -0.119687  0.029196  0.091221   \n",
            "\n",
            "                     d5        d6        d7        d8  INTANG2010  \\\n",
            "PL2010         0.084391  0.011686 -0.054424  0.002960    0.468068   \n",
            "LL2010         0.039364 -0.122869  0.001839 -0.047804    0.345837   \n",
            "d1            -0.146093 -0.083239 -0.088485 -0.050416   -0.113593   \n",
            "d2            -0.179579 -0.102319 -0.108767 -0.061972   -0.137554   \n",
            "d3            -0.092844 -0.052899 -0.056233 -0.032040    0.046607   \n",
            "d4            -0.139141 -0.079278 -0.084275 -0.048017    0.192964   \n",
            "d5             1.000000 -0.062403 -0.066336 -0.037796   -0.064915   \n",
            "d6            -0.062403  1.000000 -0.037796 -0.021535   -0.018404   \n",
            "d7            -0.066336 -0.037796  1.000000 -0.022893    0.050059   \n",
            "d8            -0.037796 -0.021535 -0.022893  1.000000    0.039832   \n",
            "INTANG2010    -0.064915 -0.018404  0.050059  0.039832    1.000000   \n",
            "CAXEEQUIV2010  0.083703  0.066189 -0.076737  0.005663    0.576162   \n",
            "CREC2010      -0.046398  0.131107 -0.020985 -0.031605   -0.007301   \n",
            "REC2010        0.049919  0.013136 -0.026082  0.024364    0.598389   \n",
            "CAXOP2010      0.100397 -0.044828 -0.027719 -0.074711    0.389010   \n",
            "ORA2010       -0.044239 -0.079236 -0.040497 -0.047992    0.224206   \n",
            "\n",
            "               CAXEEQUIV2010  CREC2010   REC2010  CAXOP2010   ORA2010  \n",
            "PL2010              0.632350 -0.047691  0.541393   0.497192  0.149149  \n",
            "LL2010              0.470082 -0.092361  0.438128   0.602703  0.061237  \n",
            "d1                 -0.136538 -0.056957 -0.065597  -0.005899 -0.055663  \n",
            "d2                 -0.097948 -0.006710 -0.023006  -0.008485 -0.119687  \n",
            "d3                 -0.008727  0.082378  0.069255  -0.083578  0.029196  \n",
            "d4                  0.102123 -0.095125  0.134093   0.088743  0.091221  \n",
            "d5                  0.083703 -0.046398  0.049919   0.100397 -0.044239  \n",
            "d6                  0.066189  0.131107  0.013136  -0.044828 -0.079236  \n",
            "d7                 -0.076737 -0.020985 -0.026082  -0.027719 -0.040497  \n",
            "d8                  0.005663 -0.031605  0.024364  -0.074711 -0.047992  \n",
            "INTANG2010          0.576162 -0.007301  0.598389   0.389010  0.224206  \n",
            "CAXEEQUIV2010       1.000000 -0.005551  0.637337   0.535426  0.177959  \n",
            "CREC2010           -0.005551  1.000000 -0.018366  -0.219656 -0.019254  \n",
            "REC2010             0.637337 -0.018366  1.000000   0.470629  0.171398  \n",
            "CAXOP2010           0.535426 -0.219656  0.470629   1.000000  0.130473  \n",
            "ORA2010             0.177959 -0.019254  0.171398   0.130473  1.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRANSFORMAÇÃO EM LOG"
      ],
      "metadata": {
        "id": "WWwpAlRW86aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "variaveis_para_transformar = ['PL2010', 'LL2010', 'INTANG2010', 'CAXEEQUIV2010', 'REC2010', 'CAXOP2010', 'ORA2010']\n",
        "\n",
        "# Aplicar o logaritmo natural (ln) às variáveis selecionadas\n",
        "dados_log = dados.copy()  # Crie uma cópia dos dados originais para manter os dados originais intactos\n",
        "\n",
        "for variavel in variaveis_para_transformar:\n",
        "    dados_log[variavel] = dados_log[variavel].apply(lambda x: np.log(x) if x > 0 else 0)  # Aplica o logaritmo, tratando valores <= 0\n",
        "\n",
        "# Agora, dados_log contém as variáveis transformadas em log\n"
      ],
      "metadata": {
        "id": "-Oq0UBOM89VZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "teste de heterocedasticidade de White. Se o valor-p for menor que um nível de significância escolhido (por exemplo, 0,05), você pode rejeitar a hipótese nula de homocedasticidade"
      ],
      "metadata": {
        "id": "9Zd9X-08b9S_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "from statsmodels.stats.diagnostic import het_white\n",
        "\n",
        "# Calcule os resíduos do modelo\n",
        "residuos = modelo.resid\n",
        "\n",
        "# Realize o teste de White para heterocedasticidade\n",
        "teste_white = het_white(residuos, X)\n",
        "\n",
        "# Imprima os resultados do teste\n",
        "print(\"Estatística do teste de White:\", teste_white[0])\n",
        "print(\"Valor-p do teste de White:\", teste_white[1])"
      ],
      "metadata": {
        "id": "ICEs0hnicHRU",
        "outputId": "ef00fb27-fa29-436d-d982-d57be17a8563",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estatística do teste de White: 67.70225561116487\n",
            "Valor-p do teste de White: 3.079384249137414e-13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MQO ESCALADO SIMPLES"
      ],
      "metadata": {
        "id": "fSCSv5TM1vCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Copie as variáveis não escalonadas para X_unscaled\n",
        "X_unscaled = X[['d1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8']]\n",
        "\n",
        "# Escalone as variáveis escalonáveis pelo valor AT2009\n",
        "X_scaled = X[['PL2010', 'LL2010']].divide(dados['AT2009'], axis=0)\n",
        "\n",
        "# Junte as variáveis escalonadas e não escalonadas\n",
        "X_combined = pd.concat([X_scaled, X_unscaled], axis=1)\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X_combined = sm.add_constant(X_combined)\n",
        "\n",
        "# Crie o modelo de regressão linear\n",
        "modelo = sm.OLS(y, X_combined).fit()\n",
        "\n",
        "# Visualize os resultados do modelo\n",
        "print(modelo.summary())\n",
        "\n",
        "# Calcule o MedAE\n",
        "y_pred = modelo.predict(X_combined)\n",
        "medae = np.median(np.abs(y - y_pred))\n",
        "\n",
        "print(\"Median Absolute Error (MedAE):\", medae)\n"
      ],
      "metadata": {
        "outputId": "3e2e71fe-3306-47a6-db90-e9ec0adf182c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gteelql31lOs"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:          VM30Abril2011   R-squared:                       0.089\n",
            "Model:                            OLS   Adj. R-squared:                  0.048\n",
            "Method:                 Least Squares   F-statistic:                     2.165\n",
            "Date:                Thu, 21 Sep 2023   Prob (F-statistic):             0.0209\n",
            "Time:                        17:40:49   Log-Likelihood:                -4265.8\n",
            "No. Observations:                 233   AIC:                             8554.\n",
            "Df Residuals:                     222   BIC:                             8591.\n",
            "Df Model:                          10                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const       1.258e+07   3.33e+06      3.778      0.000    6.02e+06    1.91e+07\n",
            "PL2010     -6.573e+05   5.58e+05     -1.177      0.240   -1.76e+06    4.43e+05\n",
            "LL2010      2.329e+07   1.21e+07      1.927      0.055   -5.29e+05    4.71e+07\n",
            "d1         -1.143e+07   4.86e+06     -2.355      0.019    -2.1e+07   -1.86e+06\n",
            "d2          -1.18e+07   4.46e+06     -2.647      0.009   -2.06e+07   -3.01e+06\n",
            "d3          1.695e+06   6.36e+06      0.267      0.790   -1.08e+07    1.42e+07\n",
            "d4         -8.083e+06   4.98e+06     -1.624      0.106   -1.79e+07    1.72e+06\n",
            "d5         -1.404e+05   5.67e+06     -0.025      0.980   -1.13e+07     1.1e+07\n",
            "d6          1.681e+07   9.05e+06      1.858      0.065   -1.02e+06    3.46e+07\n",
            "d7         -9.924e+06   8.09e+06     -1.227      0.221   -2.59e+07    6.01e+06\n",
            "d8          -1.12e+07   1.32e+07     -0.848      0.397   -3.72e+07    1.48e+07\n",
            "==============================================================================\n",
            "Omnibus:                      257.321   Durbin-Watson:                   1.985\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7123.066\n",
            "Skew:                           4.726   Prob(JB):                         0.00\n",
            "Kurtosis:                      28.384   Cond. No.                         40.5\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "Median Absolute Error (MedAE): 4040223.6037496356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MQO ESCALADO COMPLEXO"
      ],
      "metadata": {
        "id": "p1BCSv3-1MyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'INTANG2010',\n",
        "           'CAXEEQUIV2010', 'CREC2010', 'REC2010', 'CAXOP2010', 'ORA2010']]\n",
        "y = dados['VM30Abril2011']\n",
        "\n",
        "# Copie as variáveis não escalonadas para X_unscaled\n",
        "X_unscaled = X[['d1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8']]\n",
        "\n",
        "# Escalone as variáveis escalonáveis pelo valor AT2009\n",
        "X_scaled = X[['PL2010', 'LL2010', 'INTANG2010', 'CAXEEQUIV2010', 'CREC2010', 'REC2010', 'CAXOP2010', 'ORA2010']].divide(dados['AT2009'], axis=0)\n",
        "\n",
        "# Junte as variáveis escalonadas e não escalonadas\n",
        "X_combined = pd.concat([X_scaled, X_unscaled], axis=1)\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X_combined = sm.add_constant(X_combined)\n",
        "\n",
        "# Crie o modelo de regressão linear\n",
        "modelo = sm.OLS(y, X_combined).fit()\n",
        "\n",
        "# Visualize os resultados do modelo\n",
        "print(modelo.summary())\n",
        "\n",
        "# Calcule o MedAE\n",
        "y_pred = modelo.predict(X_combined)\n",
        "medae = np.median(np.abs(y - y_pred))\n",
        "\n",
        "print(\"Median Absolute Error (MedAE):\", medae)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1WbhVYb0gAz",
        "outputId": "ae4871ed-827b-4800-d7e0-6256b39f2415"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:          VM30Abril2011   R-squared:                       0.121\n",
            "Model:                            OLS   Adj. R-squared:                  0.056\n",
            "Method:                 Least Squares   F-statistic:                     1.859\n",
            "Date:                Thu, 21 Sep 2023   Prob (F-statistic):             0.0257\n",
            "Time:                        17:37:43   Log-Likelihood:                -4261.6\n",
            "No. Observations:                 233   AIC:                             8557.\n",
            "Df Residuals:                     216   BIC:                             8616.\n",
            "Df Model:                          16                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "=================================================================================\n",
            "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
            "---------------------------------------------------------------------------------\n",
            "const          1.665e+07   3.63e+06      4.581      0.000    9.48e+06    2.38e+07\n",
            "PL2010        -1.678e+06   9.69e+05     -1.732      0.085   -3.59e+06    2.32e+05\n",
            "LL2010         2.712e+07   1.29e+07      2.103      0.037     1.7e+06    5.25e+07\n",
            "INTANG2010      1.13e+04   2.94e+05      0.038      0.969   -5.69e+05    5.91e+05\n",
            "CAXEEQUIV2010 -4.527e+06    4.3e+06     -1.052      0.294    -1.3e+07    3.95e+06\n",
            "CREC2010      -5.504e+10   4.16e+10     -1.324      0.187   -1.37e+11    2.69e+10\n",
            "REC2010       -2.364e+06   1.32e+06     -1.792      0.075   -4.96e+06    2.37e+05\n",
            "CAXOP2010     -1.987e+05   4.29e+05     -0.463      0.644   -1.04e+06    6.47e+05\n",
            "ORA2010        -7.12e+06   2.42e+07     -0.294      0.769   -5.48e+07    4.06e+07\n",
            "d1            -1.218e+07   4.91e+06     -2.482      0.014   -2.19e+07   -2.51e+06\n",
            "d2            -1.273e+07   4.49e+06     -2.838      0.005   -2.16e+07   -3.89e+06\n",
            "d3             1.504e+06   6.37e+06      0.236      0.814    -1.1e+07    1.41e+07\n",
            "d4            -1.031e+07   5.02e+06     -2.051      0.041   -2.02e+07   -4.04e+05\n",
            "d5            -1.392e+06   5.67e+06     -0.245      0.806   -1.26e+07    9.79e+06\n",
            "d6             1.979e+07   9.33e+06      2.121      0.035     1.4e+06    3.82e+07\n",
            "d7             -9.18e+06   8.52e+06     -1.078      0.282    -2.6e+07    7.61e+06\n",
            "d8            -1.027e+07   1.32e+07     -0.777      0.438   -3.63e+07    1.58e+07\n",
            "==============================================================================\n",
            "Omnibus:                      250.797   Durbin-Watson:                   1.968\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6599.816\n",
            "Skew:                           4.552   Prob(JB):                         0.00\n",
            "Kurtosis:                      27.432   Cond. No.                     1.55e+05\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The condition number is large, 1.55e+05. This might indicate that there are\n",
            "strong multicollinearity or other numerical problems.\n",
            "Median Absolute Error (MedAE): 4210688.463465561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Minimos Quadrados Ponderados (MQP), com pesos com base na variância dos erros_ MODELO COMPLEXO"
      ],
      "metadata": {
        "id": "Vmo8zEDpLVRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'INTANG2010',\n",
        "           'CAXEEQUIV2010', 'CREC2010', 'REC2010', 'CAXOP2010', 'ORA2010']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão linear\n",
        "modelo = sm.OLS(y, X).fit()\n",
        "\n",
        "# Calcule os resíduos (erros)\n",
        "residuos = modelo.resid\n",
        "\n",
        "# Calcule a variância dos resíduos\n",
        "variancia_residuos = np.var(residuos)\n",
        "\n",
        "# Calcule os pesos com base na variância dos resíduos (inverso da variância)\n",
        "pesos = 1 / variancia_residuos\n",
        "\n",
        "# Crie o modelo de regressão linear ponderada (WLS) com os pesos calculados\n",
        "modelo_wls = sm.WLS(y, X, weights=pesos).fit()\n",
        "\n",
        "# Visualize os resultados do modelo ponderado\n",
        "print(modelo_wls.summary())\n",
        "\n",
        "# Calcule os resíduos ponderados (erros ponderados)\n",
        "y_pred_wls = modelo_wls.predict(X)\n",
        "residuos_wls = y - y_pred_wls\n",
        "\n",
        "# Calcule o MedAE ponderado\n",
        "medae_wls = np.median(np.abs(residuos_wls))\n",
        "\n",
        "# Calcule o valor médio da variável de resposta\n",
        "valor_medio_y = np.mean(y)\n",
        "\n",
        "# Calcule o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "medae_scaled_wls = (medae_wls / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "print(\"Median Absolute Error (MedAE) ponderado:\", medae_wls)\n",
        "print(\"MedAE ponderado escalado pelo valor (ou preço) em percentagem:\", medae_scaled_wls)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gfcj59gNQlc",
        "outputId": "3e4917b2-fc50-46d6-911d-7c024b4c0a5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            WLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:          VM30Abril2011   R-squared:                       0.218\n",
            "Model:                            WLS   Adj. R-squared:                  0.160\n",
            "Method:                 Least Squares   F-statistic:                     3.772\n",
            "Date:                Thu, 21 Sep 2023   Prob (F-statistic):           3.70e-06\n",
            "Time:                        00:33:15   Log-Likelihood:                -4339.0\n",
            "No. Observations:                 233   AIC:                             8712.\n",
            "Df Residuals:                     216   BIC:                             8771.\n",
            "Df Model:                          16                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "=================================================================================\n",
            "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
            "---------------------------------------------------------------------------------\n",
            "const         -2.942e+07   1.09e+07     -2.701      0.007   -5.09e+07   -7.95e+06\n",
            "PL2010          1.57e+05   7.91e+05      0.199      0.843    -1.4e+06    1.72e+06\n",
            "LL2010         1.215e+06    6.4e+05      1.899      0.059   -4.58e+04    2.48e+06\n",
            "d1             -7.83e+06   7.06e+06     -1.109      0.269   -2.18e+07    6.09e+06\n",
            "d2            -8.243e+06   6.58e+06     -1.252      0.212   -2.12e+07    4.73e+06\n",
            "d3             5.053e+06   9.07e+06      0.557      0.578   -1.28e+07    2.29e+07\n",
            "d4             -1.02e+07   7.16e+06     -1.424      0.156   -2.43e+07    3.92e+06\n",
            "d5             3.295e+06   8.21e+06      0.401      0.689   -1.29e+07    1.95e+07\n",
            "d6             4.276e+07   1.23e+07      3.473      0.001    1.85e+07     6.7e+07\n",
            "d7            -7.317e+06   1.14e+07     -0.640      0.523   -2.99e+07    1.52e+07\n",
            "d8            -5.991e+06   1.86e+07     -0.322      0.748   -4.27e+07    3.07e+07\n",
            "INTANG2010     3.904e+05   6.12e+05      0.638      0.524   -8.16e+05     1.6e+06\n",
            "CAXEEQUIV2010  8.072e+05   1.14e+06      0.710      0.478   -1.43e+06    3.05e+06\n",
            "CREC2010      -7.935e+05   2.25e+06     -0.353      0.724   -5.22e+06    3.63e+06\n",
            "REC2010        3.721e+05   9.86e+05      0.378      0.706   -1.57e+06    2.31e+06\n",
            "CAXOP2010      8.374e+05    6.5e+05      1.288      0.199   -4.44e+05    2.12e+06\n",
            "ORA2010        2.867e+05   5.91e+05      0.485      0.628   -8.78e+05    1.45e+06\n",
            "==============================================================================\n",
            "Omnibus:                      308.290   Durbin-Watson:                   2.110\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            22185.987\n",
            "Skew:                           5.888   Prob(JB):                         0.00\n",
            "Kurtosis:                      49.331   Cond. No.                         285.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is 2.81e-15. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n",
            "Median Absolute Error (MedAE) ponderado: 7575826.291824429\n",
            "MedAE ponderado escalado pelo valor (ou preço) em percentagem: 82.71861329637318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MQP - MODELO SIMPLES"
      ],
      "metadata": {
        "id": "IXhYrWVgKtFr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_x0KEUlXKwVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "import numpy as np\n",
        "\n",
        "# Suponha que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão linear\n",
        "modelo = sm.OLS(y, X).fit()\n",
        "\n",
        "# Calcule os resíduos (erros)\n",
        "residuos = modelo.resid\n",
        "\n",
        "# Calcule a variância dos resíduos\n",
        "variancia_residuos = np.var(residuos)\n",
        "\n",
        "# Calcule os pesos com base na variância dos resíduos (inverso da variância)\n",
        "pesos = 1 / variancia_residuos\n",
        "\n",
        "# Crie o modelo de regressão linear ponderada (WLS) com os pesos calculados\n",
        "modelo_wls = sm.WLS(y, X, weights=pesos).fit()\n",
        "\n",
        "# Visualize os resultados do modelo ponderado\n",
        "print(modelo_wls.summary())\n",
        "\n",
        "# Calcule os resíduos ponderados (erros ponderados)\n",
        "y_pred_wls = modelo_wls.predict(X)\n",
        "residuos_wls = y - y_pred_wls\n",
        "\n",
        "# Calcule o MedAE ponderado\n",
        "medae_wls = np.median(np.abs(residuos_wls))\n",
        "\n",
        "# Calcule o valor médio da variável de resposta\n",
        "valor_medio_y = np.mean(y)\n",
        "\n",
        "# Calcule o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "medae_scaled_wls = (medae_wls / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "print(\"Median Absolute Error (MedAE) ponderado:\", medae_wls)\n",
        "print(\"MedAE ponderado escalado pelo valor (ou preço) em percentagem:\", medae_scaled_wls)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6d30721-1d55-4943-89a2-f4d5d97c2fa2",
        "id": "oIMBo59IK2xT"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            WLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:          VM30Abril2011   R-squared:                       0.192\n",
            "Model:                            WLS   Adj. R-squared:                  0.155\n",
            "Method:                 Least Squares   F-statistic:                     5.259\n",
            "Date:                Thu, 21 Sep 2023   Prob (F-statistic):           6.14e-07\n",
            "Time:                        00:35:04   Log-Likelihood:                -4342.9\n",
            "No. Observations:                 233   AIC:                             8708.\n",
            "Df Residuals:                     222   BIC:                             8746.\n",
            "Df Model:                          10                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const      -1.779e+07   8.24e+06     -2.159      0.032    -3.4e+07   -1.55e+06\n",
            "PL2010      9.658e+05   6.97e+05      1.385      0.167   -4.08e+05    2.34e+06\n",
            "LL2010       1.73e+06   5.74e+05      3.015      0.003    5.99e+05    2.86e+06\n",
            "d1         -7.816e+06   6.77e+06     -1.155      0.249   -2.12e+07    5.52e+06\n",
            "d2         -8.044e+06   6.22e+06     -1.294      0.197   -2.03e+07    4.21e+06\n",
            "d3            6.4e+06   8.84e+06      0.724      0.470    -1.1e+07    2.38e+07\n",
            "d4         -8.029e+06   6.94e+06     -1.157      0.249   -2.17e+07    5.65e+06\n",
            "d5           4.26e+06   7.87e+06      0.541      0.589   -1.13e+07    1.98e+07\n",
            "d6          4.378e+07    1.2e+07      3.640      0.000    2.01e+07    6.75e+07\n",
            "d7         -7.075e+06   1.12e+07     -0.629      0.530   -2.92e+07    1.51e+07\n",
            "d8         -6.131e+06   1.84e+07     -0.333      0.740   -4.25e+07    3.02e+07\n",
            "==============================================================================\n",
            "Omnibus:                      310.565   Durbin-Watson:                   2.113\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            22597.171\n",
            "Skew:                           5.964   Prob(JB):                         0.00\n",
            "Kurtosis:                      49.747   Cond. No.                         162.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is 2.86e-15. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n",
            "Median Absolute Error (MedAE) ponderado: 6938513.467166096\n",
            "MedAE ponderado escalado pelo valor (ou preço) em percentagem: 75.75994884697536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REGRESSÃO QUANTÍLICA"
      ],
      "metadata": {
        "id": "fUZVJwTv19EF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'INTANG2010',\n",
        "           'CAXEEQUIV2010', 'CREC2010', 'REC2010', 'CAXOP2010', 'ORA2010']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão quantílica\n",
        "modelo = sm.QuantReg(y, X).fit(q=0.5)  # q=0.5 representa a mediana, ajuste conforme necessário\n",
        "\n",
        "# Visualize os resultados do modelo\n",
        "print(modelo.summary())\n",
        "# Faça previsões com o modelo quantílico\n",
        "y_pred_quantreg = modelo.predict(X)\n",
        "\n",
        "# Calcule o MedAE para o modelo quantílico\n",
        "medae_quantreg = np.median(np.abs(y - y_pred_quantreg))\n",
        "\n",
        "# Calcule o valor médio da variável de resposta\n",
        "valor_medio_y = np.mean(y)\n",
        "\n",
        "# Calcule o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "medae_scaled_quantreg = (medae_quantreg / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "print(\"Median Absolute Error (MedAE) quantílico:\", medae_quantreg)\n",
        "print(\"MedAE quantílico escalado pelo valor (ou preço) em percentagem:\", medae_scaled_quantreg)\n"
      ],
      "metadata": {
        "id": "dgpuCY5p1_I5",
        "outputId": "927e257e-79a5-4168-9ef1-24ca1c310022",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         QuantReg Regression Results                          \n",
            "==============================================================================\n",
            "Dep. Variable:          VM30Abril2011   Pseudo R-squared:              0.07045\n",
            "Model:                       QuantReg   Bandwidth:                   2.256e+06\n",
            "Method:                 Least Squares   Sparsity:                    6.097e+06\n",
            "Date:                Thu, 21 Sep 2023   No. Observations:                  233\n",
            "Time:                        00:41:23   Df Residuals:                      216\n",
            "                                        Df Model:                           16\n",
            "=================================================================================\n",
            "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
            "---------------------------------------------------------------------------------\n",
            "const         -4.663e+06   1.08e+06     -4.316      0.000   -6.79e+06   -2.53e+06\n",
            "PL2010         8.584e+04   7.84e+04      1.094      0.275   -6.88e+04     2.4e+05\n",
            "LL2010         1.435e+05   6.35e+04      2.260      0.025    1.84e+04    2.69e+05\n",
            "d1             -2.33e+05      7e+05     -0.333      0.740   -1.61e+06    1.15e+06\n",
            "d2             -1.93e+05   6.53e+05     -0.296      0.768   -1.48e+06    1.09e+06\n",
            "d3             2.246e+06   8.99e+05      2.497      0.013    4.74e+05    4.02e+06\n",
            "d4             8.388e+05    7.1e+05      1.181      0.239   -5.61e+05    2.24e+06\n",
            "d5             1.844e+06   8.14e+05      2.264      0.025    2.39e+05    3.45e+06\n",
            "d6              4.48e+06   1.22e+06      3.668      0.000    2.07e+06    6.89e+06\n",
            "d7             7.442e+04   1.13e+06      0.066      0.948   -2.16e+06    2.31e+06\n",
            "d8             1.403e+06   1.85e+06      0.759      0.448   -2.24e+06    5.04e+06\n",
            "INTANG2010     4.291e+04   6.07e+04      0.707      0.481   -7.68e+04    1.63e+05\n",
            "CAXEEQUIV2010  2.319e+05   1.13e+05      2.056      0.041    9623.477    4.54e+05\n",
            "CREC2010      -1.251e+05   2.23e+05     -0.561      0.575   -5.64e+05    3.14e+05\n",
            "REC2010        -2.05e+04   9.78e+04     -0.210      0.834   -2.13e+05    1.72e+05\n",
            "CAXOP2010      1.176e+05   6.45e+04      1.823      0.070   -9532.192    2.45e+05\n",
            "ORA2010       -7.173e+04   5.86e+04     -1.224      0.222   -1.87e+05    4.38e+04\n",
            "=================================================================================\n",
            "Median Absolute Error (MedAE) quantílico: 1441679.5999216535\n",
            "MedAE quantílico escalado pelo valor (ou preço) em percentagem: 15.741350544413061\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/regression/quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
            "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RQ - Modelo **simples**"
      ],
      "metadata": {
        "id": "EZjW61OoLrfE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "\n",
        "# Defina as variáveis independentes e dependente\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Adicione uma constante ao conjunto de variáveis independentes\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Crie o modelo de regressão quantílica\n",
        "modelo = sm.QuantReg(y, X).fit(q=0.5)  # q=0.5 representa a mediana, ajuste conforme necessário\n",
        "\n",
        "# Visualize os resultados do modelo\n",
        "print(modelo.summary())\n",
        "# Faça previsões com o modelo quantílico\n",
        "y_pred_quantreg = modelo.predict(X)\n",
        "\n",
        "# Calcule o MedAE para o modelo quantílico\n",
        "medae_quantreg = np.median(np.abs(y - y_pred_quantreg))\n",
        "\n",
        "# Calcule o valor médio da variável de resposta\n",
        "valor_medio_y = np.mean(y)\n",
        "\n",
        "# Calcule o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "medae_scaled_quantreg = (medae_quantreg / valor_medio_y) * 100  # Em percentagem\n",
        "\n",
        "print(\"Median Absolute Error (MedAE) quantílico:\", medae_quantreg)\n",
        "print(\"MedAE quantílico escalado pelo valor (ou preço) em percentagem:\", medae_scaled_quantreg)\n"
      ],
      "metadata": {
        "outputId": "3a525409-6d22-4193-b612-787adab707b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dov6TOxuLt01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         QuantReg Regression Results                          \n",
            "==============================================================================\n",
            "Dep. Variable:          VM30Abril2011   Pseudo R-squared:              0.05119\n",
            "Model:                       QuantReg   Bandwidth:                   2.204e+06\n",
            "Method:                 Least Squares   Sparsity:                    5.939e+06\n",
            "Date:                Thu, 21 Sep 2023   No. Observations:                  233\n",
            "Time:                        00:42:12   Df Residuals:                      222\n",
            "                                        Df Model:                           10\n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const      -2.037e+06   7.93e+05     -2.568      0.011    -3.6e+06   -4.74e+05\n",
            "PL2010      1.473e+05   6.71e+04      2.195      0.029     1.5e+04     2.8e+05\n",
            "LL2010      1.831e+05   5.52e+04      3.314      0.001    7.42e+04    2.92e+05\n",
            "d1         -6.203e+05   6.52e+05     -0.952      0.342    -1.9e+06    6.64e+05\n",
            "d2         -4.572e+04   5.99e+05     -0.076      0.939   -1.23e+06    1.13e+06\n",
            "d3           9.57e+05   8.52e+05      1.124      0.262   -7.21e+05    2.64e+06\n",
            "d4          1.078e+06   6.68e+05      1.613      0.108   -2.39e+05    2.39e+06\n",
            "d5          4.246e+05   7.58e+05      0.560      0.576   -1.07e+06    1.92e+06\n",
            "d6          5.048e+06   1.16e+06      4.358      0.000    2.77e+06    7.33e+06\n",
            "d7           9.23e+05   1.08e+06      0.852      0.395   -1.21e+06    3.06e+06\n",
            "d8           6.97e+05   1.78e+06      0.393      0.695    -2.8e+06     4.2e+06\n",
            "==============================================================================\n",
            "Median Absolute Error (MedAE) quantílico: 1446196.2802038135\n",
            "MedAE quantílico escalado pelo valor (ou preço) em percentagem: 15.79066708299929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/statsmodels/regression/quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
            "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REGRESSÃO BAYESIANA"
      ],
      "metadata": {
        "id": "d35ZXGV__UMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import median_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'INTANG2010',\n",
        "           'CAXEEQUIV2010', 'CREC2010', 'REC2010', 'CAXOP2010', 'ORA2010']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo Bayesian Ridge\n",
        "    modelo_bayesiano = BayesianRidge()\n",
        "\n",
        "    modelo_bayesiano.fit(X_train, y_train)\n",
        "    y_pred = modelo_bayesiano.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = median_absolute_error(y_test, y_pred)\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar os coeficientes do modelo (coeficientes Bayesianos)\n",
        "    coeficientes = modelo_bayesiano.coef_\n",
        "    print(\"Coeficientes do Modelo:\", coeficientes)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPyVyLlA_XEf",
        "outputId": "9a734e76-d495-437b-aa68-2675bf90dc0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coeficientes do Modelo: [ 7.08496313e-06  8.50551699e-06 -1.79938865e-07 -2.99273481e-07\n",
            "  7.74715337e-08 -9.77720389e-08  1.59503720e-07  2.72852696e-07\n",
            " -3.68232014e-08 -1.84567576e-08  6.26235546e-06  5.44375979e-06\n",
            " -1.40066325e-07  4.88001768e-06  7.76672262e-06  1.33286053e-06]\n",
            "Coeficientes do Modelo: [ 6.96622855e-06  8.59324119e-06 -1.95418983e-07 -2.84994665e-07\n",
            "  7.31044029e-08 -1.19940622e-07  1.50682792e-07  2.62474289e-07\n",
            " -4.62932362e-08 -1.89791311e-08  6.13004571e-06  5.13763836e-06\n",
            " -8.62902705e-08  4.53055832e-06  7.59223793e-06  1.79021918e-06]\n",
            "Coeficientes do Modelo: [ 7.50093250e-06  8.96193362e-06 -2.07201366e-07 -2.82470313e-07\n",
            "  1.23434111e-07 -5.76769448e-08 -6.20155007e-08  3.88196588e-07\n",
            " -4.32547321e-08 -1.94188176e-08  7.35434543e-06  5.57943273e-06\n",
            " -2.45610698e-07  5.11388978e-06  8.29081940e-06  2.29257129e-06]\n",
            "Coeficientes do Modelo: [ 7.01348368e-06  8.37231255e-06 -2.00702891e-07 -2.73820811e-07\n",
            "  4.00381872e-08 -8.83168929e-08  1.66644484e-07  2.71499606e-07\n",
            " -4.44495021e-08 -1.84617535e-08  6.33441555e-06  5.34124100e-06\n",
            " -1.51488131e-07  4.87421725e-06  7.74585812e-06  1.20050839e-06]\n",
            "Coeficientes do Modelo: [ 7.04375554e-06  8.62736665e-06 -2.11238331e-07 -3.18782780e-07\n",
            "  6.06153108e-08 -1.10897743e-07  1.76777236e-07  2.69983869e-07\n",
            " -2.59708037e-08 -1.18030996e-08  6.45148566e-06  5.40735565e-06\n",
            " -6.15561924e-08  4.85229147e-06  7.75342441e-06  1.89781038e-06]\n",
            "Coeficientes do Modelo: [ 6.94436512e-06  8.44545876e-06 -2.01776462e-07 -2.92380243e-07\n",
            " -2.64486712e-08 -1.11511481e-07  1.78085063e-07  2.88019666e-07\n",
            " -3.62362127e-08 -1.83790623e-08  6.50378020e-06  5.38255741e-06\n",
            " -8.08979691e-08  4.81237136e-06  7.95916152e-06  1.90943956e-06]\n",
            "Coeficientes do Modelo: [ 7.15267827e-06  8.62589360e-06 -2.05074678e-07 -3.05413267e-07\n",
            "  7.25996968e-08 -9.69553837e-08  1.64855628e-07  2.62304741e-07\n",
            " -3.98803287e-08 -1.52066274e-08  6.67601567e-06  5.38639133e-06\n",
            " -1.48903926e-07  4.94926732e-06  7.83421553e-06  1.71310782e-06]\n",
            "Coeficientes do Modelo: [ 9.80453912e-06  1.23507686e-05 -2.96673076e-07 -4.31461726e-07\n",
            "  1.58908349e-07 -1.22816528e-07  3.61404365e-07 -1.81042063e-08\n",
            " -7.25959261e-08 -2.83713837e-08  8.13669789e-06  7.23610503e-06\n",
            " -1.63770922e-07  6.30297989e-06  1.15450953e-05  4.34614286e-06]\n",
            "Coeficientes do Modelo: [ 7.18368105e-06  8.52018641e-06 -2.00590975e-07 -2.81911230e-07\n",
            "  6.68624790e-08 -1.17108548e-07  1.46119688e-07  2.60252253e-07\n",
            " -4.51008430e-08 -1.11865385e-08  6.55858876e-06  5.42537141e-06\n",
            " -1.36270243e-07  4.94068410e-06  7.85343474e-06  1.90639484e-06]\n",
            "Coeficientes do Modelo: [ 7.12540238e-06  8.67179467e-06 -1.87088952e-07 -2.85294292e-07\n",
            "  7.31692957e-08 -9.69535293e-08  1.75027645e-07  3.01985693e-07\n",
            " -3.99758480e-08 -1.89770845e-08  6.55989562e-06  5.58225527e-06\n",
            " -1.72568671e-07  5.10216985e-06  7.83845416e-06  9.73415543e-07]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 153.29743994723083\n",
            "Média do R²: -0.7490923071700291\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RB_Simples"
      ],
      "metadata": {
        "id": "X-hPlPqnNEYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import BayesianRidge\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import median_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo Bayesian Ridge\n",
        "    modelo_bayesiano = BayesianRidge()\n",
        "\n",
        "    modelo_bayesiano.fit(X_train, y_train)\n",
        "    y_pred = modelo_bayesiano.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = median_absolute_error(y_test, y_pred)\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar os coeficientes do modelo (coeficientes Bayesianos)\n",
        "    coeficientes = modelo_bayesiano.coef_\n",
        "    print(\"Coeficientes do Modelo:\", coeficientes)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e548b05-753e-44e4-bee3-09b4fa6fa539",
        "id": "zj4mQ3zrNLrh"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coeficientes do Modelo: [ 7.08445812e-06  8.50491072e-06 -1.79926039e-07 -2.99252149e-07\n",
            "  7.74660116e-08 -9.77650698e-08  1.59492350e-07  2.72833247e-07\n",
            " -3.68205767e-08 -1.84554420e-08]\n",
            "Coeficientes do Modelo: [ 6.96575957e-06  8.59266268e-06 -1.95405827e-07 -2.84975479e-07\n",
            "  7.30994815e-08 -1.19932547e-07  1.50672648e-07  2.62456619e-07\n",
            " -4.62901197e-08 -1.89778534e-08]\n",
            "Coeficientes do Modelo: [ 7.50030115e-06  8.96117929e-06 -2.07183926e-07 -2.82446538e-07\n",
            "  1.23423721e-07 -5.76720901e-08 -6.20102809e-08  3.88163914e-07\n",
            " -4.32510913e-08 -1.94171831e-08]\n",
            "Coeficientes do Modelo: [ 7.01298838e-06  8.37172128e-06 -2.00688716e-07 -2.73801473e-07\n",
            "  4.00353596e-08 -8.83106557e-08  1.66632715e-07  2.71480432e-07\n",
            " -4.44463630e-08 -1.84604497e-08]\n",
            "Coeficientes do Modelo: [ 7.04324004e-06  8.62673524e-06 -2.11222871e-07 -3.18759450e-07\n",
            "  6.06108746e-08 -1.10889627e-07  1.76764299e-07  2.69964109e-07\n",
            " -2.59689030e-08 -1.18022358e-08]\n",
            "Coeficientes do Modelo: [ 6.94385088e-06  8.44483335e-06 -2.01761520e-07 -2.92358591e-07\n",
            " -2.64467126e-08 -1.11503224e-07  1.78071875e-07  2.87998338e-07\n",
            " -3.62335293e-08 -1.83777013e-08]\n",
            "Coeficientes do Modelo: [ 7.15214219e-06  8.62524709e-06 -2.05059307e-07 -3.05390377e-07\n",
            "  7.25942555e-08 -9.69481170e-08  1.64843272e-07  2.62285081e-07\n",
            " -3.98773397e-08 -1.52054877e-08]\n",
            "Coeficientes do Modelo: [ 9.80313213e-06  1.23489962e-05 -2.96630502e-07 -4.31399809e-07\n",
            "  1.58885545e-07 -1.22798904e-07  3.61352502e-07 -1.81016082e-08\n",
            " -7.25855083e-08 -2.83673123e-08]\n",
            "Coeficientes do Modelo: [ 7.18314259e-06  8.51954776e-06 -2.00575940e-07 -2.81890099e-07\n",
            "  6.68574673e-08 -1.17099770e-07  1.46108736e-07  2.60232745e-07\n",
            " -4.50974624e-08 -1.11857000e-08]\n",
            "Coeficientes do Modelo: [ 7.12487141e-06  8.67114846e-06 -1.87075010e-07 -2.85273033e-07\n",
            "  7.31638433e-08 -9.69463045e-08  1.75014603e-07  3.01963189e-07\n",
            " -3.99728691e-08 -1.89756703e-08]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 153.29743994745755\n",
            "Média do R²: -0.7490923071823945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVR"
      ],
      "metadata": {
        "id": "NIw0ZhcK_9OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import median_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8' ,'INTANG2010',\n",
        "           'CAXEEQUIV2010', 'CREC2010', 'REC2010', 'CAXOP2010', 'ORA2010']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo SVR com kernel RBF\n",
        "    modelo_svr = SVR(kernel='rbf', C=1.0)\n",
        "\n",
        "    modelo_svr.fit(X_train, y_train)\n",
        "    y_pred = modelo_svr.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = median_absolute_error(y_test, y_pred)\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPXr6W3_Hh_z",
        "outputId": "6d49ac61-039a-47bb-af8c-8b37968a466e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 24.446137613876168\n",
            "Média do R²: -0.11840191906907234\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVR_simples"
      ],
      "metadata": {
        "id": "5QTAN2pFNmCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import median_absolute_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo SVR com kernel RBF\n",
        "    modelo_svr = SVR(kernel='rbf', C=1.0)\n",
        "\n",
        "    modelo_svr.fit(X_train, y_train)\n",
        "    y_pred = modelo_svr.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = median_absolute_error(y_test, y_pred)\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "307b501d-487d-46d3-bb4e-03db286b4f7c",
        "id": "k9USclUIN9aK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 24.44618188204652\n",
            "Média do R²: -0.11840171315472689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ARVORE DE DECISÃO"
      ],
      "metadata": {
        "id": "x6LWJCtFU0Od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'INTANG2010',\n",
        "           'CAXEEQUIV2010', 'CREC2010', 'REC2010', 'CAXOP2010', 'ORA2010']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de árvore de decisão com os parâmetros desejados\n",
        "    modelo_arvore = DecisionTreeRegressor(min_samples_split=5, random_state=42)\n",
        "\n",
        "    # Criar o modelo Bagging com 500 árvores\n",
        "    bagging_model = BaggingRegressor(base_estimator=modelo_arvore, n_estimators=500, bootstrap=True, random_state=42)\n",
        "\n",
        "    bagging_model.fit(X_train, y_train)\n",
        "    y_pred = bagging_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar a importância dos coeficientes (importância das variáveis)\n",
        "    importancia_coeficientes = np.mean([tree.feature_importances_ for tree in bagging_model.estimators_], axis=0)\n",
        "    print(\"Importância dos Coeficientes:\", importancia_coeficientes)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6G90UU8W4WZ",
        "outputId": "dd01abf2-a69b-4746-93ad-5a71ea9a96c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [9.10331917e-02 5.32096150e-01 7.46280579e-05 2.58125079e-05\n",
            " 1.53974109e-04 5.78882791e-05 7.41658812e-04 5.23380942e-04\n",
            " 7.13077098e-05 2.77884957e-05 3.26844256e-02 5.34216006e-02\n",
            " 2.30281210e-03 8.33399946e-02 2.03143408e-01 3.01979084e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [8.99028064e-02 5.51056557e-01 8.11885682e-05 1.99200889e-05\n",
            " 5.45854393e-04 9.36889971e-05 8.02070706e-04 9.26589024e-05\n",
            " 7.13288938e-05 2.73507441e-05 5.16125577e-02 4.89468239e-02\n",
            " 2.54056461e-03 6.53434222e-02 1.88372045e-01 4.91162430e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [9.54776694e-02 5.04529141e-01 1.65299357e-04 2.82789635e-05\n",
            " 3.48121511e-04 8.23264163e-05 7.73090836e-05 2.65261369e-04\n",
            " 1.61060904e-04 5.42178019e-05 1.11869793e-01 3.25982752e-02\n",
            " 1.07199253e-03 4.56973953e-02 2.06752235e-01 8.21623532e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [6.16855495e-02 6.27540994e-01 1.17727978e-04 1.74139920e-05\n",
            " 4.35611252e-05 8.00237642e-05 4.60348274e-05 1.05843942e-04\n",
            " 1.35130253e-04 4.39048749e-05 4.25530543e-02 5.07585790e-02\n",
            " 1.82124511e-03 4.82482145e-02 1.66619181e-01 1.83541699e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [7.61818254e-02 5.20850450e-01 7.44396938e-05 2.42881163e-05\n",
            " 5.34983696e-04 1.45307277e-04 4.88677751e-04 6.07334903e-04\n",
            " 2.33680810e-05 3.97721214e-05 4.54133559e-02 8.28631425e-02\n",
            " 1.69659458e-03 6.31614556e-02 2.07663919e-01 2.31085456e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [1.61306710e-01 3.22361264e-01 9.41297056e-06 1.69934508e-05\n",
            " 8.51689390e-05 1.02569277e-04 4.52452724e-04 1.18480891e-04\n",
            " 1.25419440e-04 3.42172907e-05 5.90710623e-02 6.72401050e-02\n",
            " 1.67643908e-03 8.32452385e-02 3.03643092e-01 5.11374190e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [6.83011600e-02 5.72288523e-01 7.30054353e-05 1.92055731e-05\n",
            " 3.58669740e-04 9.29456352e-05 1.44187156e-03 1.07295091e-04\n",
            " 9.87457840e-05 3.16178422e-07 2.23185008e-02 7.14029141e-02\n",
            " 1.98741215e-03 6.79756902e-02 1.93243472e-01 2.90272117e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [7.01982063e-02 6.04196581e-01 1.54987797e-04 2.94631419e-05\n",
            " 6.43468124e-04 1.83651625e-04 4.14365935e-03 1.48577343e-04\n",
            " 1.01398800e-04 4.07532837e-05 1.76587591e-03 2.36138007e-02\n",
            " 4.70261921e-03 1.94771074e-02 2.69824977e-01 7.74872587e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [8.18612788e-02 5.70434659e-01 1.02837171e-04 2.22868456e-05\n",
            " 5.83176184e-04 7.08342412e-05 3.19345555e-03 1.31757575e-03\n",
            " 1.16723514e-04 3.23718670e-05 2.23499745e-02 8.49471059e-02\n",
            " 2.01311714e-03 5.22062771e-02 1.80358124e-01 3.90202013e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [1.32806403e-01 3.86808020e-01 1.02486056e-04 3.60330752e-05\n",
            " 1.02488883e-03 9.60165010e-05 1.01063999e-03 4.93724109e-05\n",
            " 8.53327941e-05 4.09381062e-05 7.40642359e-02 9.76945658e-02\n",
            " 2.59502261e-03 1.40678238e-01 1.62499782e-01 4.08023444e-04]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 11.733740348672065\n",
            "Média do R²: 0.6541393514686065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CART_simples"
      ],
      "metadata": {
        "id": "ZYtjgE_9OP3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de árvore de decisão com os parâmetros desejados\n",
        "    modelo_arvore = DecisionTreeRegressor(min_samples_split=5, random_state=42)\n",
        "\n",
        "    # Criar o modelo Bagging com 500 árvores\n",
        "    bagging_model = BaggingRegressor(base_estimator=modelo_arvore, n_estimators=500, bootstrap=True, random_state=42)\n",
        "\n",
        "    bagging_model.fit(X_train, y_train)\n",
        "    y_pred = bagging_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar a importância dos coeficientes (importância das variáveis)\n",
        "    importancia_coeficientes = np.mean([tree.feature_importances_ for tree in bagging_model.estimators_], axis=0)\n",
        "    print(\"Importância dos Coeficientes:\", importancia_coeficientes)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e98d7ea0-bfc5-4397-941f-bbc3954d1513",
        "id": "c3TdDSmhOYKa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [2.09229364e-01 7.85952004e-01 3.44221518e-04 7.67421850e-05\n",
            " 2.58215239e-04 1.26388491e-04 1.63230017e-03 2.24393173e-03\n",
            " 1.04435703e-04 3.23968553e-05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [1.76460882e-01 8.16594930e-01 3.17517583e-04 6.51812272e-05\n",
            " 8.27064298e-04 1.04939505e-04 3.92653532e-03 1.59271961e-03\n",
            " 7.97959179e-05 3.04348547e-05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [2.15862709e-01 7.81567037e-01 3.18202117e-04 1.01397114e-04\n",
            " 1.09027299e-03 2.37532188e-04 2.17688044e-04 3.24419934e-04\n",
            " 2.16524289e-04 6.42173155e-05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [1.78680541e-01 8.20115767e-01 3.75345594e-04 8.55945785e-05\n",
            " 1.29780041e-04 1.45981259e-04 1.09701048e-04 1.59620074e-04\n",
            " 1.51911513e-04 4.57580078e-05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [1.96559782e-01 7.97691372e-01 2.44293291e-04 7.20954785e-05\n",
            " 7.44946898e-04 1.38456233e-04 2.70144887e-03 1.78153858e-03\n",
            " 2.69784512e-05 3.90881403e-05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [3.46503474e-01 6.51409559e-01 1.75262666e-04 4.08613490e-05\n",
            " 1.73428368e-04 1.34051827e-04 1.26767068e-03 1.41547442e-04\n",
            " 1.20318507e-04 3.38264821e-05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [1.62345793e-01 8.30791719e-01 3.64495983e-04 7.50664969e-05\n",
            " 8.52547883e-04 2.31354067e-04 3.22714515e-03 1.99979726e-03\n",
            " 1.11264179e-04 8.16919043e-07]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [1.34973242e-01 8.54761040e-01 5.97828999e-04 1.25538680e-04\n",
            " 1.38247281e-03 2.58614577e-04 7.49425577e-03 2.37833933e-04\n",
            " 1.19613374e-04 4.95597659e-05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [1.76042930e-01 8.15241074e-01 3.59758839e-04 7.07654953e-05\n",
            " 9.97340524e-04 9.50403805e-05 4.69766165e-03 2.35084564e-03\n",
            " 1.13355519e-04 3.12284741e-05]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância dos Coeficientes: [3.43593446e-01 6.49711437e-01 4.68029748e-04 9.69702781e-05\n",
            " 2.06621097e-03 1.95293792e-04 3.61267728e-03 7.25532813e-05\n",
            " 1.32362056e-04 5.10191568e-05]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 11.945785112250316\n",
            "Média do R²: 0.7046654553019173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FLORESTA ALEATÓRIA"
      ],
      "metadata": {
        "id": "OZLbiycNZm26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'INTANG2010',\n",
        "           'CAXEEQUIV2010', 'CREC2010', 'REC2010', 'CAXOP2010', 'ORA2010']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de Floresta Aleatória com os parâmetros desejados\n",
        "    random_forest_model = RandomForestRegressor(n_estimators=500, random_state=42)\n",
        "\n",
        "    random_forest_model.fit(X_train, y_train)\n",
        "    y_pred = random_forest_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar a importância das variáveis\n",
        "    importancia_variaveis = random_forest_model.feature_importances_\n",
        "    print(\"Importância das Variáveis:\", importancia_variaveis)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "id": "lpAmsgS7Zph4",
        "outputId": "9650e00f-14ae-43c1-a0fe-e4eb775a3353",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância das Variáveis: [8.96545338e-02 5.17903293e-01 8.54110772e-05 3.35932555e-05\n",
            " 8.25049829e-04 8.05219229e-05 5.54067789e-03 3.60406204e-03\n",
            " 7.38747829e-05 2.55945453e-05 4.37166686e-02 6.41055441e-02\n",
            " 9.30464149e-03 8.25815622e-02 1.78198235e-01 4.26673659e-03]\n",
            "Importância das Variáveis: [9.48529681e-02 5.07910066e-01 7.99275443e-05 2.51481856e-05\n",
            " 1.10094210e-03 1.10129965e-04 5.45249872e-03 5.70227778e-03\n",
            " 7.16735587e-05 2.63058232e-05 5.26970953e-02 5.61305011e-02\n",
            " 8.96843461e-03 6.90796558e-02 1.93020372e-01 4.77200350e-03]\n",
            "Importância das Variáveis: [1.03725628e-01 4.68990894e-01 1.59465747e-04 3.92516516e-05\n",
            " 2.04831899e-03 1.37572640e-04 1.24136053e-04 1.01932049e-02\n",
            " 1.65655704e-04 5.08253952e-05 1.17297946e-01 4.29809234e-02\n",
            " 5.32585022e-03 4.48051685e-02 1.99237805e-01 4.71735412e-03]\n",
            "Importância das Variáveis: [7.30407684e-02 6.01199818e-01 1.27791299e-04 2.16331244e-05\n",
            " 1.33384484e-03 1.10438008e-04 5.23044542e-03 2.68758103e-03\n",
            " 1.20400895e-04 4.31127197e-05 4.34619175e-02 5.78572429e-02\n",
            " 9.85014846e-03 5.39375002e-02 1.47891061e-01 3.08629713e-03]\n",
            "Importância das Variáveis: [7.64070802e-02 5.06869144e-01 8.43611149e-05 3.05552667e-05\n",
            " 1.84879704e-03 1.49701676e-04 6.11464817e-03 5.91465828e-03\n",
            " 2.56999324e-05 3.72785856e-05 5.33168263e-02 7.62987821e-02\n",
            " 7.88236456e-03 6.47973333e-02 1.96095741e-01 4.12702836e-03]\n",
            "Importância das Variáveis: [1.66792008e-01 3.05915693e-01 1.96368310e-05 2.26806125e-05\n",
            " 9.48149499e-05 1.07745641e-04 4.41119554e-03 2.90205020e-03\n",
            " 1.20085702e-04 3.10154384e-05 6.65735286e-02 7.77056616e-02\n",
            " 1.03923063e-02 6.53397042e-02 2.91862432e-01 7.70944090e-03]\n",
            "Importância das Variáveis: [8.77494306e-02 5.45665960e-01 7.63309152e-05 2.64832063e-05\n",
            " 9.95539716e-04 1.10208490e-04 5.22928332e-03 5.20775573e-03\n",
            " 9.23072564e-05 3.61438122e-07 2.70506804e-02 6.72016218e-02\n",
            " 8.38394721e-03 7.32433485e-02 1.75983707e-01 2.98303405e-03]\n",
            "Importância das Variáveis: [8.44132794e-02 5.73040792e-01 1.52270385e-04 3.65268450e-05\n",
            " 1.81158378e-03 2.17014607e-04 1.18126322e-02 1.50077632e-04\n",
            " 9.50101763e-05 3.88183786e-05 2.93377392e-03 2.56178053e-02\n",
            " 1.24744365e-02 2.40965781e-02 2.60101937e-01 3.00746432e-03]\n",
            "Importância das Variáveis: [9.00857474e-02 5.32397584e-01 1.00357562e-04 2.78911357e-05\n",
            " 1.12151585e-03 1.11440244e-04 6.50511367e-03 5.16663579e-03\n",
            " 1.04836625e-04 3.07288185e-05 1.99209499e-02 8.71026731e-02\n",
            " 8.74260769e-03 6.48302158e-02 1.79705758e-01 4.04594488e-03]\n",
            "Importância das Variáveis: [1.40784218e-01 3.54802570e-01 1.15669797e-04 4.56345229e-05\n",
            " 3.92813067e-03 1.30090997e-04 6.07958494e-03 3.06275876e-03\n",
            " 8.12586373e-05 3.91302674e-05 7.77347648e-02 1.02938272e-01\n",
            " 7.86390272e-03 1.46393753e-01 1.55053235e-01 9.47026972e-04]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 11.59931850679992\n",
            "Média do R²: 0.7249919712297856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RF-simples"
      ],
      "metadata": {
        "id": "yx7kQryEO5xl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de Floresta Aleatória com os parâmetros desejados\n",
        "    random_forest_model = RandomForestRegressor(n_estimators=500, random_state=42)\n",
        "\n",
        "    random_forest_model.fit(X_train, y_train)\n",
        "    y_pred = random_forest_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar a importância das variáveis\n",
        "    importancia_variaveis = random_forest_model.feature_importances_\n",
        "    print(\"Importância das Variáveis:\", importancia_variaveis)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "outputId": "ac386f9c-6105-4f12-9744-679ff35c718e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pP-9l579PAS_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância das Variáveis: [2.32494818e-01 7.39198971e-01 3.57541429e-04 1.04960343e-04\n",
            " 3.08502106e-03 2.17942702e-04 1.40855071e-02 1.03150052e-02\n",
            " 1.09853441e-04 3.03797473e-05]\n",
            "Importância das Variáveis: [1.97764109e-01 7.74706247e-01 3.18864289e-04 8.48573727e-05\n",
            " 2.75454973e-03 1.52621739e-04 1.20003938e-02 1.21075136e-02\n",
            " 8.16746930e-05 2.91681654e-05]\n",
            "Importância das Variáveis: [2.26923151e-01 7.46512711e-01 3.18347588e-04 1.60885196e-04\n",
            " 6.06888252e-03 4.43196186e-04 5.42954356e-04 1.87515179e-02\n",
            " 2.18221508e-04 6.01328823e-05]\n",
            "Importância das Variáveis: [1.84571013e-01 7.91171473e-01 3.52399420e-04 1.09166022e-04\n",
            " 3.03920874e-03 2.87982536e-04 9.37616032e-03 1.08838044e-02\n",
            " 1.62851874e-04 4.59404452e-05]\n",
            "Importância das Variáveis: [2.19533287e-01 7.53456840e-01 2.62798436e-04 9.65593760e-05\n",
            " 3.52955214e-03 2.38529826e-04 1.29896695e-02 9.82383387e-03\n",
            " 3.20126390e-05 3.69165842e-05]\n",
            "Importância das Variáveis: [3.46280518e-01 6.30961570e-01 1.53609450e-04 5.93711617e-05\n",
            " 2.19052741e-04 1.93993043e-04 1.05634206e-02 1.14129669e-02\n",
            " 1.23087766e-04 3.24104636e-05]\n",
            "Importância das Variáveis: [1.84837599e-01 7.89837104e-01 3.34426178e-04 9.77212746e-05\n",
            " 3.24521679e-03 3.05953336e-04 1.27516862e-02 8.47149883e-03\n",
            " 1.17965361e-04 8.28101938e-07]\n",
            "Importância das Variáveis: [1.53706823e-01 8.13280712e-01 6.00986867e-04 1.56219804e-04\n",
            " 4.82545092e-03 4.61576578e-04 2.65405825e-02 2.64600263e-04\n",
            " 1.13847559e-04 4.92007495e-05]\n",
            "Importância das Variáveis: [1.97567058e-01 7.73431831e-01 3.77609534e-04 9.52354097e-05\n",
            " 3.20841517e-03 1.69997642e-04 1.21730245e-02 1.28314678e-02\n",
            " 1.16732923e-04 2.86272817e-05]\n",
            "Importância das Variáveis: [3.22179788e-01 6.55780907e-01 4.64849168e-04 1.29568833e-04\n",
            " 5.85030759e-03 3.14067519e-04 1.10833347e-02 4.01320937e-03\n",
            " 1.35250636e-04 4.87166174e-05]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 12.29673269657949\n",
            "Média do R²: 0.7735490010594318\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRADIENT BOOSTING"
      ],
      "metadata": {
        "id": "gReIxsDPa_9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'INTANG2010',\n",
        "           'CAXEEQUIV2010', 'CREC2010', 'REC2010', 'CAXOP2010', 'ORA2010']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de Regressão Gradient Boosting com os parâmetros desejados\n",
        "    gradient_boosting_model = GradientBoostingRegressor(n_estimators=500, random_state=42)\n",
        "\n",
        "    gradient_boosting_model.fit(X_train, y_train)\n",
        "    y_pred = gradient_boosting_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar a importância das variáveis\n",
        "    importancia_variaveis = gradient_boosting_model.feature_importances_\n",
        "    print(\"Importância das Variáveis:\", importancia_variaveis)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "id": "NvfZ3qUAbCf5",
        "outputId": "8561b085-3724-4645-fb62-57ea96946de9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância das Variáveis: [5.11685604e-02 7.38190807e-01 3.69127899e-06 1.05669131e-05\n",
            " 2.01819172e-03 9.00774795e-05 1.30024565e-03 8.03000420e-05\n",
            " 3.54399154e-05 6.56350651e-06 1.30064257e-03 1.11007058e-02\n",
            " 8.11289157e-03 4.98291879e-02 1.33519973e-01 3.23215561e-03]\n",
            "Importância das Variáveis: [7.56287729e-02 6.90302991e-01 4.34376854e-05 1.40222931e-05\n",
            " 5.01654907e-03 5.40965750e-05 1.98896878e-05 1.55566069e-03\n",
            " 6.47595587e-05 6.24110710e-06 1.30589031e-03 3.71219140e-02\n",
            " 4.21847490e-03 3.34378014e-02 1.45385913e-01 5.82358573e-03]\n",
            "Importância das Variáveis: [1.15831358e-01 6.14302063e-01 1.85581969e-05 4.02031552e-06\n",
            " 1.00203324e-03 9.75300170e-05 2.35793027e-05 5.97986520e-02\n",
            " 9.53239563e-05 2.31550025e-06 4.87189674e-03 9.13518594e-03\n",
            " 3.95984703e-03 5.90477273e-03 1.71119382e-01 1.38334815e-02]\n",
            "Importância das Variáveis: [9.14617860e-02 8.16653426e-01 2.61408211e-05 9.15148168e-07\n",
            " 1.43998444e-03 1.02355934e-04 5.81621430e-04 4.87616880e-04\n",
            " 1.15592058e-04 4.62518736e-06 3.33407387e-03 1.84268145e-02\n",
            " 3.75339359e-03 2.88535991e-02 3.45256496e-02 2.32405015e-04]\n",
            "Importância das Variáveis: [5.28520486e-02 6.28934001e-01 5.55854438e-05 6.01761857e-07\n",
            " 2.69935569e-03 6.00287674e-05 5.92889249e-04 1.60173013e-03\n",
            " 2.34211346e-05 7.06454417e-06 1.24144776e-03 4.09794374e-02\n",
            " 6.98075872e-03 5.84484745e-02 2.00719731e-01 4.80342463e-03]\n",
            "Importância das Variáveis: [3.32140456e-02 3.21900021e-01 8.63624805e-06 4.96212324e-06\n",
            " 1.02955624e-04 5.84058812e-05 2.86220741e-03 4.07557971e-04\n",
            " 9.65659401e-05 1.31958597e-05 5.36023070e-03 3.42183860e-03\n",
            " 4.93924596e-03 1.23600967e-02 5.82023940e-01 3.32260936e-02]\n",
            "Importância das Variáveis: [1.24658056e-01 6.81605667e-01 5.07543802e-06 3.65011819e-06\n",
            " 3.28494510e-03 2.71566427e-05 2.39377074e-03 1.65614075e-03\n",
            " 7.31458107e-05 1.88303405e-06 1.32738513e-03 6.77497075e-03\n",
            " 4.26696470e-03 2.11166057e-02 1.45237640e-01 7.56694233e-03]\n",
            "Importância das Variáveis: [5.36988207e-02 8.05035131e-01 4.57335235e-05 3.10154139e-06\n",
            " 1.47264360e-03 1.05251372e-04 3.72843300e-02 1.58990923e-04\n",
            " 4.53049102e-05 2.06473998e-05 1.99860446e-03 1.43459708e-02\n",
            " 2.11530921e-02 7.45696488e-03 5.29111650e-02 4.26424751e-03]\n",
            "Importância das Variáveis: [7.67946950e-02 7.14172659e-01 2.26602725e-05 1.49506422e-06\n",
            " 4.99447155e-03 9.21105231e-05 2.75263913e-06 5.78009258e-04\n",
            " 6.66145569e-05 4.78278597e-06 1.13533710e-03 5.92382353e-03\n",
            " 1.22115635e-02 5.70231356e-02 1.19298640e-01 7.67724942e-03]\n",
            "Importância das Variáveis: [3.03051985e-01 2.49048217e-01 6.12010682e-05 1.70709795e-06\n",
            " 3.06269058e-03 3.20306184e-05 8.60942369e-03 2.14392612e-03\n",
            " 4.98361152e-05 9.46693600e-06 1.73566963e-03 1.48583463e-01\n",
            " 1.98605130e-03 1.62656748e-01 1.16406565e-01 2.56101959e-03]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 13.341104453945686\n",
            "Média do R²: 0.7533915362286872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GB-SIMPLES"
      ],
      "metadata": {
        "id": "nqnLHReIPr4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de Regressão Gradient Boosting com os parâmetros desejados\n",
        "    gradient_boosting_model = GradientBoostingRegressor(n_estimators=500, random_state=42)\n",
        "\n",
        "    gradient_boosting_model.fit(X_train, y_train)\n",
        "    y_pred = gradient_boosting_model.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "    # Visualizar a importância das variáveis\n",
        "    importancia_variaveis = gradient_boosting_model.feature_importances_\n",
        "    print(\"Importância das Variáveis:\", importancia_variaveis)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "outputId": "d6e3ba19-b466-4524-edf9-a7b1682ac76f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYfOHR_NPz63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Importância das Variáveis: [1.22486979e-01 8.57342657e-01 2.60251479e-04 5.00926953e-05\n",
            " 5.17114161e-03 3.08890958e-05 8.59360938e-03 5.98157575e-03\n",
            " 7.62790184e-05 6.52440298e-06]\n",
            "Importância das Variáveis: [9.25235879e-02 8.98729918e-01 2.25660079e-04 2.31454288e-05\n",
            " 5.00105918e-03 7.61562315e-05 2.30804942e-03 1.02685989e-03\n",
            " 8.05739417e-05 4.98996125e-06]\n",
            "Importância das Variáveis: [7.61690203e-02 8.28379994e-01 1.23463666e-04 2.18603930e-05\n",
            " 1.20798471e-02 3.81737371e-05 2.99713738e-05 8.30595768e-02\n",
            " 8.88154135e-05 9.27726494e-06]\n",
            "Importância das Variáveis: [8.25451447e-02 9.07169147e-01 2.03102789e-04 1.06464145e-05\n",
            " 2.12865558e-03 1.69658262e-04 3.91894653e-03 3.76936246e-03\n",
            " 8.17742816e-05 3.56217304e-06]\n",
            "Importância das Variáveis: [7.89982856e-02 9.00467211e-01 1.58309071e-04 1.80276654e-05\n",
            " 5.56638252e-03 2.37462239e-04 1.01289963e-02 4.35510838e-03\n",
            " 5.24730059e-05 1.77441810e-05]\n",
            "Importância das Variáveis: [7.37958361e-02 9.15695825e-01 1.39371817e-04 2.54882404e-05\n",
            " 1.61267829e-04 2.06177574e-05 5.06486627e-03 4.97738304e-03\n",
            " 1.11305427e-04 8.03838628e-06]\n",
            "Importância das Variáveis: [9.00511266e-02 8.92972527e-01 2.16555678e-04 2.26711012e-05\n",
            " 5.50781200e-03 1.49805982e-04 6.70480409e-03 4.30019004e-03\n",
            " 7.39735611e-05 5.33624022e-07]\n",
            "Importância das Variáveis: [6.55702287e-02 8.77464966e-01 5.11462696e-04 4.10807307e-05\n",
            " 5.06598018e-03 9.95397566e-05 5.08704619e-02 3.03094794e-04\n",
            " 6.10375286e-05 1.21478700e-05]\n",
            "Importância das Variáveis: [1.24227183e-01 8.54363135e-01 2.47890763e-04 2.21540382e-05\n",
            " 5.99024725e-03 9.69708533e-05 1.20541495e-02 2.90722770e-03\n",
            " 8.36976921e-05 7.34368219e-06]\n",
            "Importância das Variáveis: [3.32291956e-01 6.48653152e-01 4.06616931e-04 2.47537190e-05\n",
            " 7.06091374e-03 6.86761992e-05 6.04965595e-03 5.34744253e-03\n",
            " 8.85244671e-05 8.30854156e-06]\n",
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 11.033212056692873\n",
            "Média do R²: 0.8123781223518403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REDES NEURAIS"
      ],
      "metadata": {
        "id": "Gy8Aqujjc2rw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'INTANG2010',\n",
        "           'CAXEEQUIV2010', 'CREC2010', 'REC2010', 'CAXOP2010', 'ORA2010']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de regressão de rede neural com os parâmetros desejados\n",
        "    modelo_rede_neural = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
        "\n",
        "    modelo_rede_neural.fit(X_train, y_train)\n",
        "    y_pred = modelo_rede_neural.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "id": "yygOLB39c4OY",
        "outputId": "8a288bfc-4311-446c-b143-ab56cd2351b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 34.880632463725945\n",
            "Média do R²: -0.006022540221525175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7FEGQu5PQTiK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "NN_simples"
      ],
      "metadata": {
        "id": "i3Ep3oDeQXIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# Supondo que 'dados' seja o DataFrame com suas variáveis\n",
        "X = dados_log[['PL2010', 'LL2010', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8']]\n",
        "y = dados_log['VM30Abril2011']\n",
        "\n",
        "# Configurar a validação cruzada com 10 folds\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Listas para armazenar resultados\n",
        "medae_scores = []\n",
        "r2_scores = []\n",
        "\n",
        "# Treinar e avaliar o modelo dentro da amostra usando validação cruzada\n",
        "for train_index, test_index in kf.split(X):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Criar o modelo de regressão de rede neural com os parâmetros desejados\n",
        "    modelo_rede_neural = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=1000, random_state=42)\n",
        "\n",
        "    modelo_rede_neural.fit(X_train, y_train)\n",
        "    y_pred = modelo_rede_neural.predict(X_test)\n",
        "\n",
        "    # Calcular o MedAE escalado pelo valor (ou preço) em percentagem\n",
        "    medae = np.median(np.abs(y_test - y_pred))\n",
        "    valor_medio_y = np.mean(y_test)\n",
        "    medae_scaled = (medae / valor_medio_y) * 100  # Em percentagem\n",
        "    medae_scores.append(medae_scaled)\n",
        "\n",
        "    # Calcular o R²\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    r2_scores.append(r2)\n",
        "\n",
        "# Média do MedAE escalado pelo valor (ou preço) em percentagem\n",
        "mean_medae_scaled = np.mean(medae_scores)\n",
        "print(\"Média do MedAE escalado pelo valor (ou preço) em percentagem:\", mean_medae_scaled)\n",
        "\n",
        "# Média do R²\n",
        "mean_r2 = np.mean(r2_scores)\n",
        "print(\"Média do R²:\", mean_r2)\n"
      ],
      "metadata": {
        "outputId": "723bcd2f-03f2-4b53-fb47-a0be5625a295",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcBDiLVzQT5m"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Média do MedAE escalado pelo valor (ou preço) em percentagem: 14.796065460978616\n",
            "Média do R²: -0.1516691707421371\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    }
  ]
}